"""
Advanced Analytics Export Utilities
é«˜åº¦ãªåˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½

å…¨ã¦ã®é«˜åº¦ãªåˆ†æçµæœã‚’çµ±åˆã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆExcel/JSONå½¢å¼ï¼‰
"""

from typing import Any, Dict, List
from io import BytesIO
from datetime import datetime
import json

import pandas as pd
import numpy as np
import streamlit as st


class AdvancedAnalyticsExporter:
    """
    é«˜åº¦ãªåˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    
    å¯¾å¿œåˆ†æ:
    - Shapley Value
    - Transfer Entropy
    - Bootstrapçµ±è¨ˆæ¤œå®š
    - Causal Inference
    - Graph Embedding
    - Fisher Information
    - (å°†æ¥) Bayesian Inference
    """
    
    def __init__(self, analytics_results: Dict[str, Any]):
        """
        Args:
            analytics_results: st.session_state.advanced_analytics_results
        """
        self.results = analytics_results
    
    def export_to_excel(self) -> BytesIO:
        """
        Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        ã‚·ãƒ¼ãƒˆæ§‹æˆ:
        1. ã‚µãƒãƒªãƒ¼: å…¨åˆ†æã®æ¦‚è¦
        2. Shapley_Values: Shapleyå€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        3. Shapley_Cumulative: ç´¯ç©è²¢çŒ®åº¦
        4. Shapley_Categories: ã‚«ãƒ†ã‚´ãƒªåˆ¥è²¢çŒ®åº¦
        5. TE_Matrix: Transfer Entropyè¡Œåˆ—
        6. TE_Flows: æœ‰æ„ãªæƒ…å ±ãƒ•ãƒ­ãƒ¼
        7. TE_Comparison: å…ƒã®éš£æ¥è¡Œåˆ—ã¨ã®æ¯”è¼ƒ
        8. Bootstrap_CI: ä¿¡é ¼åŒºé–“
        9. Bootstrap_Groups: ã‚°ãƒ«ãƒ¼ãƒ—é–“æ¯”è¼ƒ
        10. CI_InterventionEffects: ä»‹å…¥åŠ¹æœ
        11. CI_TopTargets: æœ€é©ä»‹å…¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        12. CI_Confounders: äº¤çµ¡å› å­
        13. GE_Communities: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¡ãƒ³ãƒãƒ¼
        14. GE_Positions2D: 2Dåº§æ¨™
        15. GE_Similarity: é¡ä¼¼åº¦ä¸Šä½ãƒšã‚¢
        16. FI_SensitivityScores: æ„Ÿåº¦ã‚¹ã‚³ã‚¢
        17. FI_CramerRaoBounds: CRä¸‹é™
        
        Returns:
            BytesIO: Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒŠãƒªã‚¹ãƒˆãƒªãƒ¼ãƒ 
        """
        buffer = BytesIO()
        
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            # 1. ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆ
            summary_data = self._create_summary()
            if summary_data:
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='ã‚µãƒãƒªãƒ¼', index=False)
            else:
                # ç©ºã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
                dummy_df = pd.DataFrame({"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸": ["åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“"]})
                dummy_df.to_excel(writer, sheet_name='æƒ…å ±', index=False)
            
            # 2. Shapley Value
            if "shapley" in self.results:
                self._export_shapley_to_excel(writer)
            
            # 3. Transfer Entropy
            if "transfer_entropy" in self.results:
                self._export_te_to_excel(writer)
            
            # 4. Bootstrap
            if "bootstrap" in self.results:
                self._export_bootstrap_to_excel(writer)
            
            # 5. Causal Inference
            if "causal_inference" in self.results:
                self._export_causal_to_excel(writer)
            
            # 6. Graph Embedding
            if "graph_embedding" in self.results:
                self._export_graph_embedding_to_excel(writer)
            
            # 7. Fisher Information
            if "fisher_information" in self.results:
                self._export_fisher_to_excel(writer)
            
            # 8. Bayesian Inference
            if "bayesian_inference" in self.results:
                self._export_bayesian_to_excel(writer)
        
        buffer.seek(0)
        return buffer
    
    def _create_summary(self) -> List[Dict]:
        """ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’ä½œæˆ"""
        summary = []
        
        for analysis_name, data in self.results.items():
            result = data.get("result")
            params = data.get("parameters", {})
            timestamp = data.get("timestamp", "")
            
            summary.append({
                "åˆ†æå": self._translate_analysis_name(analysis_name),
                "å®Ÿè¡Œæ—¥æ™‚": timestamp,
                "è¨ˆç®—æ™‚é–“(ç§’)": getattr(result, "computation_time", 0),
                "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿": str(params)
            })
        
        return summary
    
    def _export_shapley_to_excel(self, writer):
        """Shapley Valueçµæœã‚’Excelã«"""
        shapley_data = self.results["shapley"]
        result = shapley_data["result"]
        
        # ã‚·ãƒ¼ãƒˆ1: Shapleyå€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        shapley_df = pd.DataFrame([
            {
                "é †ä½": i+1,
                "ãƒãƒ¼ãƒ‰å": name,
                "Shapleyå€¤": value,
                "è²¢çŒ®ç‡(%)": (value / result.total_value * 100) if result.total_value > 0 else 0
            }
            for i, (name, value) in enumerate(result.top_contributors)
        ])
        shapley_df.to_excel(writer, sheet_name='Shapley_Values', index=False)
        
        # ã‚·ãƒ¼ãƒˆ2: ç´¯ç©è²¢çŒ®åº¦
        if result.cumulative_contribution:
            cumulative_df = pd.DataFrame([
                {
                    "ä¸Šä½Nãƒãƒ¼ãƒ‰": n,
                    "ç´¯ç©è²¢çŒ®ç‡(%)": pct
                }
                for n, pct in result.cumulative_contribution
            ])
            cumulative_df.to_excel(writer, sheet_name='Shapley_Cumulative', index=False)
        
        # ã‚·ãƒ¼ãƒˆ3: ã‚«ãƒ†ã‚´ãƒªåˆ¥è²¢çŒ®åº¦
        if result.category_contributions:
            category_df = pd.DataFrame([
                {"ã‚«ãƒ†ã‚´ãƒª": cat, "å¹³å‡Shapleyå€¤": value}
                for cat, value in result.category_contributions.items()
            ])
            category_df.to_excel(writer, sheet_name='Shapley_Categories', index=False)
        
        # ã‚·ãƒ¼ãƒˆ4-5: é€£æºå®‰å®šæ€§åˆ†æï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        if "stability" in shapley_data:
            stability = shapley_data["stability"]
            
            # ã‚·ãƒ¼ãƒˆ4: ä¸Šä½è²¢çŒ®è€…
            top_nodes_data = []
            for i, node in enumerate(stability["top_contributors"], 1):
                top_nodes_data.append({
                    "é †ä½": i,
                    "ãƒãƒ¼ãƒ‰å": node,
                    "Shapleyå€¤": result.shapley_values.get(node, 0)
                })
            
            if top_nodes_data:
                top_nodes_df = pd.DataFrame(top_nodes_data)
                top_nodes_df.to_excel(writer, sheet_name='Shapley_TopContributors', index=False)
            
            # ã‚·ãƒ¼ãƒˆ5: å¯†çµåˆãƒšã‚¢
            dense_pairs_data = []
            for i, (node1, node2, strength) in enumerate(stability["dense_connections"], 1):
                dense_pairs_data.append({
                    "é †ä½": i,
                    "ãƒãƒ¼ãƒ‰1": node1,
                    "ãƒãƒ¼ãƒ‰2": node2,
                    "æ¥ç¶šå¼·åº¦": strength
                })
            
            if dense_pairs_data:
                dense_pairs_df = pd.DataFrame(dense_pairs_data)
                dense_pairs_df.to_excel(writer, sheet_name='Shapley_DensePairs', index=False)
    
    def _export_te_to_excel(self, writer):
        """Transfer Entropyçµæœã‚’Excelã«"""
        te_data = self.results["transfer_entropy"]
        result = te_data["result"]
        
        # ã‚·ãƒ¼ãƒˆ1: TEè¡Œåˆ—
        te_matrix = result.te_matrix
        if hasattr(te_matrix, 'shape'):
            # NumPyé…åˆ—ã®å ´åˆ
            n = te_matrix.shape[0]
            node_names = list(range(n))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
            # ãƒãƒ¼ãƒ‰åã‚’å–å¾—ã§ãã‚‹å ´åˆ
            if hasattr(result, 'node_names'):
                node_names = result.node_names
            
            te_matrix_df = pd.DataFrame(
                te_matrix,
                columns=node_names,
                index=node_names
            )
            te_matrix_df.to_excel(writer, sheet_name='TE_Matrix', index=True)
        
        # ã‚·ãƒ¼ãƒˆ2: æœ‰æ„ãªãƒ•ãƒ­ãƒ¼
        if result.significant_flows:
            flows_df = pd.DataFrame([
                {
                    "é †ä½": i+1,
                    "From": source,
                    "To": target,
                    "TE(bits)": te_value
                }
                for i, (source, target, te_value) in enumerate(result.significant_flows)
            ])
            flows_df.to_excel(writer, sheet_name='TE_Flows', index=False)
        
        # ã‚·ãƒ¼ãƒˆ3: æ¯”è¼ƒè¡¨
        if hasattr(result, 'comparison_with_original') and len(result.comparison_with_original) > 0:
            result.comparison_with_original.to_excel(writer, sheet_name='TE_Comparison', index=False)
    
    def _export_bootstrap_to_excel(self, writer):
        """Bootstrapçµæœã‚’Excelã«"""
        bs_data = self.results["bootstrap"]
        result = bs_data["result"]
        
        # ã‚·ãƒ¼ãƒˆ1: ä¿¡é ¼åŒºé–“
        ci_df = pd.DataFrame([
            {
                "ãƒãƒ¼ãƒ‰å": node,
                "å€¤": ci[0],
                "ä¸‹é™95%": ci[1],
                "ä¸Šé™95%": ci[2],
                "ç›¸å¯¾èª¤å·®(%)": ((ci[2] - ci[1]) / (2 * abs(ci[0])) * 100) if abs(ci[0]) > 1e-6 else 0
            }
            for node, ci in result.node_ci.items()
        ])
        ci_df.to_excel(writer, sheet_name='Bootstrap_CI', index=False)
        
        # ã‚·ãƒ¼ãƒˆ2: ã‚°ãƒ«ãƒ¼ãƒ—é–“æ¯”è¼ƒ
        if hasattr(result, 'group_comparison') and len(result.group_comparison) > 0:
            result.group_comparison.to_excel(writer, sheet_name='Bootstrap_Groups', index=False)
    
    def _export_causal_to_excel(self, writer):
        """Causal Inferenceçµæœã‚’Excelã«"""
        ci_data = self.results["causal_inference"]
        result = ci_data["result"]
        intervention_node = ci_data["parameters"].get("intervention_node")
        
        # ã‚·ãƒ¼ãƒˆ1: ä»‹å…¥åŠ¹æœ
        if intervention_node and intervention_node in result.intervention_effects:
            effects = result.intervention_effects[intervention_node]
            effects_df = pd.DataFrame([
                {
                    "ãƒãƒ¼ãƒ‰": node,
                    "å› æœåŠ¹æœ": effect,
                    "æ–¹å‘": "æ”¹å–„" if effect > 0 else "æ‚ªåŒ–"
                }
                for node, effect in sorted(effects.items(), key=lambda x: abs(x[1]), reverse=True)
            ])
            effects_df.to_excel(writer, sheet_name='CI_InterventionEffects', index=False)
        
        # ã‚·ãƒ¼ãƒˆ2: æœ€é©ä»‹å…¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        if result.top_intervention_targets:
            targets_df = pd.DataFrame([
                {
                    "é †ä½": i+1,
                    "ãƒãƒ¼ãƒ‰": node,
                    "ç·å½±éŸ¿åŠ›": impact
                }
                for i, (node, impact) in enumerate(result.top_intervention_targets)
            ])
            targets_df.to_excel(writer, sheet_name='CI_TopTargets', index=False)
        
        # ã‚·ãƒ¼ãƒˆ3: äº¤çµ¡å› å­
        if result.confounders:
            confounders_df = pd.DataFrame([
                {
                    "From": source,
                    "To": target,
                    "äº¤çµ¡å› å­": ", ".join(conf_list)
                }
                for source, target, conf_list in result.confounders
            ])
            confounders_df.to_excel(writer, sheet_name='CI_Confounders', index=False)
    
    def _export_graph_embedding_to_excel(self, writer):
        """Graph Embeddingçµæœã‚’Excelã«"""
        ge_data = self.results["graph_embedding"]
        result = ge_data["result"]
        
        # ã‚·ãƒ¼ãƒˆ1: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¡ãƒ³ãƒãƒ¼
        community_members = {}
        for node, comm_id in result.communities.items():
            if comm_id not in community_members:
                community_members[comm_id] = []
            community_members[comm_id].append(node)
        
        comm_data = []
        for comm_id in sorted(community_members.keys()):
            members = community_members[comm_id]
            label = result.community_labels.get(comm_id, f"ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£{comm_id+1}")
            comm_data.append({
                "ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ID": comm_id + 1,
                "åå‰": label,
                "ãƒãƒ¼ãƒ‰æ•°": len(members),
                "ãƒ¡ãƒ³ãƒãƒ¼": ", ".join(members)
            })
        
        comm_df = pd.DataFrame(comm_data)
        comm_df.to_excel(writer, sheet_name='GE_Communities', index=False)
        
        # ã‚·ãƒ¼ãƒˆ2: 2Dåº§æ¨™
        positions_data = []
        for node, (x, y) in result.node_positions_2d.items():
            comm_id = result.communities[node]
            positions_data.append({
                "ãƒãƒ¼ãƒ‰": node,
                "Xåº§æ¨™": x,
                "Yåº§æ¨™": y,
                "ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ID": comm_id + 1
            })
        
        positions_df = pd.DataFrame(positions_data)
        positions_df.to_excel(writer, sheet_name='GE_Positions2D', index=False)
        
        # ã‚·ãƒ¼ãƒˆ3: é¡ä¼¼åº¦ä¸Šä½ãƒšã‚¢
        similar_data = []
        for i, (node1, node2, sim) in enumerate(result.top_similar_pairs[:50], 1):
            similar_data.append({
                "é †ä½": i,
                "ãƒãƒ¼ãƒ‰1": node1,
                "ãƒãƒ¼ãƒ‰2": node2,
                "é¡ä¼¼åº¦": sim
            })
        
        similar_df = pd.DataFrame(similar_data)
        similar_df.to_excel(writer, sheet_name='GE_Similarity', index=False)
    
    def _export_fisher_to_excel(self, writer):
        """Fisher Informationçµæœã‚’Excelã«"""
        fi_data = self.results["fisher_information"]
        result = fi_data["result"]
        
        # ã‚·ãƒ¼ãƒˆ1: æ„Ÿåº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        sensitivity_data = []
        for i, (source, target, score) in enumerate(result.top_sensitive_edges, 1):
            sensitivity_data.append({
                "é †ä½": i,
                "From": source,
                "To": target,
                "æ„Ÿåº¦ã‚¹ã‚³ã‚¢": score
            })
        
        if sensitivity_data:
            sensitivity_df = pd.DataFrame(sensitivity_data)
            sensitivity_df.to_excel(writer, sheet_name='FI_SensitivityScores', index=False)
        
        # ã‚·ãƒ¼ãƒˆ2: CramÃ©r-Raoä¸‹é™
        if result.cramer_rao_bounds:
            cr_sorted = sorted(
                result.cramer_rao_bounds.items(),
                key=lambda x: x[1],
                reverse=True
            )[:50]  # ä¸Šä½50çµ„
            
            cr_data = []
            for (source, target), bound in cr_sorted:
                cr_data.append({
                    "From": source,
                    "To": target,
                    "CRä¸‹é™": bound
                })
            
            cr_df = pd.DataFrame(cr_data)
            cr_df.to_excel(writer, sheet_name='FI_CramerRaoBounds', index=False)
    
    def _export_bayesian_to_excel(self, writer):
        bi_data = self.results["bayesian_inference"]
        result = bi_data["result"]
        
        ci_data = []
        for source, target, uncertainty_score in result.high_uncertainty_edges:
            edge = (source, target)
            if edge in result.credible_intervals:
                mean_val, lower, upper = result.credible_intervals[edge]
                
                ci_data.append({
                    "From": source,
                    "To": target,
                    "äº‹å¾Œå¹³å‡": mean_val,
                    "ä¸‹é™": lower,
                    "ä¸Šé™": upper,
                    "ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢": uncertainty_score
                })
        
        if ci_data:
            ci_df = pd.DataFrame(ci_data)
            ci_df.to_excel(writer, sheet_name='BI_CredibleIntervals', index=False)
        
        high_uncertainty_data = []
        for i, (source, target, score) in enumerate(result.high_uncertainty_edges[:50], 1):
            high_uncertainty_data.append({
                "é †ä½": i,
                "From": source,
                "To": target,
                "ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢": score
            })
        
        if high_uncertainty_data:
            hu_df = pd.DataFrame(high_uncertainty_data)
            hu_df.to_excel(writer, sheet_name='BI_HighUncertainty', index=False)
    
    def export_to_json(self) -> str:
        """
        JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Returns:
            JSONæ–‡å­—åˆ—
        """
        export_data = {
            "export_version": "1.0.0",
            "export_timestamp": datetime.now().isoformat(),
            "analyses": {}
        }
        
        for analysis_name, data in self.results.items():
            result = data.get("result")
            
            # å„åˆ†æã”ã¨ã«ä¸»è¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if analysis_name == "shapley":
                export_data["analyses"]["shapley_value"] = {
                    "shapley_values": result.shapley_values,
                    "total_value": result.total_value,
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
                
                # é€£æºå®‰å®šæ€§ãƒ‡ãƒ¼ã‚¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
                if "stability" in data:
                    stability = data["stability"]
                    export_data["analyses"]["shapley_value"]["stability"] = {
                        "top_contributors": stability["top_contributors"],
                        "dense_connections": [(n1, n2, float(s)) for n1, n2, s in stability["dense_connections"]],
                        "recommendation": stability["recommendation"]
                    }
            
            elif analysis_name == "transfer_entropy":
                export_data["analyses"]["transfer_entropy"] = {
                    "te_matrix": result.te_matrix.tolist() if hasattr(result.te_matrix, 'tolist') else result.te_matrix,
                    "significant_flows": result.significant_flows,
                    "bottleneck_nodes": result.bottleneck_nodes,
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
            
            elif analysis_name == "bootstrap":
                export_data["analyses"]["bootstrap"] = {
                    "node_ci": {k: list(v) for k, v in result.node_ci.items()},
                    "stable_findings": result.stable_findings,
                    "unstable_findings": result.unstable_findings,
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
            
            elif analysis_name == "causal_inference":
                export_data["analyses"]["causal_inference"] = {
                    "direct_effects": {f"{k[0]}->{k[1]}": v for k, v in result.direct_effects.items()},
                    "indirect_effects": {f"{k[0]}->{k[1]}": v for k, v in result.indirect_effects.items()},
                    "total_effects": {f"{k[0]}->{k[1]}": v for k, v in result.total_effects.items()},
                    "top_intervention_targets": [(node, impact) for node, impact in result.top_intervention_targets],
                    "n_confounders": len(result.confounders),
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
            
            elif analysis_name == "graph_embedding":
                export_data["analyses"]["graph_embedding"] = {
                    "communities": result.communities,
                    "modularity": result.modularity,
                    "n_communities": result.n_communities,
                    "top_similar_pairs": [(n1, n2, sim) for n1, n2, sim in result.top_similar_pairs[:20]],
                    "node_positions_2d": {node: list(pos) for node, pos in result.node_positions_2d.items()},
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
            
            elif analysis_name == "fisher_information":
                export_data["analyses"]["fisher_information"] = {
                    "n_edges": result.n_edges,
                    "condition_number": result.condition_number,
                    "effective_rank": int(result.effective_rank),
                    "top_sensitive_edges": [(s, t, score) for s, t, score in result.top_sensitive_edges[:20]],
                    "eigenvalues": result.eigenvalues.tolist()[:10],  # ä¸Šä½10å›ºæœ‰å€¤
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
            
            elif analysis_name == "bayesian_inference":
                export_data["analyses"]["bayesian_inference"] = {
                    "n_edges": result.n_edges,
                    "credible_level": result.credible_level,
                    "n_bootstrap": result.n_bootstrap,
                    "high_uncertainty_edges": [(s, t, score) for s, t, score in result.high_uncertainty_edges[:20]],
                    "avg_uncertainty": float(np.mean(list(result.uncertainty_scores.values()))) if result.uncertainty_scores else 0.0,
                    "computation_time": result.computation_time,
                    "parameters": data.get("parameters", {})
                }
        
        return json.dumps(export_data, indent=2, ensure_ascii=False)
    
    def _translate_analysis_name(self, name: str) -> str:
        """åˆ†æåã®æ—¥æœ¬èªåŒ–"""
        translations = {
            "shapley": "Shapley Valueï¼ˆå”åŠ›è²¢çŒ®åº¦åˆ†æï¼‰",
            "transfer_entropy": "Transfer Entropyï¼ˆæƒ…å ±ãƒ•ãƒ­ãƒ¼åˆ†æï¼‰",
            "bootstrap": "Bootstrapçµ±è¨ˆæ¤œå®š",
            "causal_inference": "Causal Inferenceï¼ˆå› æœæ¨è«–ï¼‰",
            "graph_embedding": "Graph Embeddingï¼ˆæ½œåœ¨æ§‹é€ ç™ºè¦‹ï¼‰",
            "fisher_information": "Fisher Informationï¼ˆæ„Ÿåº¦åˆ†æï¼‰",
            "bayesian_inference": "Bayesian Inferenceï¼ˆä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–ï¼‰"
        }
        return translations.get(name, name)


def add_analytics_export_to_sidebar():
    """
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    
    app_tabs.py ã® render_sidebar() ã‹ã‚‰å‘¼ã³å‡ºã™
    """
    if "advanced_analytics_results" not in st.session_state or len(st.session_state.advanced_analytics_results) == 0:
        return
    
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“¤ é«˜åº¦ãªåˆ†æçµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    n_analyses = len(st.session_state.advanced_analytics_results)
    st.sidebar.info(f"å®Ÿè¡Œæ¸ˆã¿åˆ†æ: {n_analyses}ä»¶")
    
    # Excelã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if st.sidebar.button("ğŸ“Š Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="export_excel_adv", use_container_width=True):
        exporter = AdvancedAnalyticsExporter(st.session_state.advanced_analytics_results)
        excel_buffer = exporter.export_to_excel()
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        filename = f"advanced_analytics_{timestamp}.xlsx"
        
        st.sidebar.download_button(
            label="â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=excel_buffer,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
            key="download_excel_adv"
        )
    
    # JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if st.sidebar.button("ğŸ“„ JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key="export_json_adv", use_container_width=True):
        exporter = AdvancedAnalyticsExporter(st.session_state.advanced_analytics_results)
        json_data = exporter.export_to_json()
        
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        filename = f"advanced_analytics_{timestamp}.json"
        
        st.sidebar.download_button(
            label="â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json_data,
            file_name=filename,
            mime="application/json",
            use_container_width=True,
            key="download_json_adv"
        )
