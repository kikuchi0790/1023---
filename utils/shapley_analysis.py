"""
Shapley Value Analysis for Process Insight Modeler
å”åŠ›è²¢çŒ®åº¦åˆ†æï¼ˆShapley Valueï¼‰

å„ãƒãƒ¼ãƒ‰ã®çœŸã®é™ç•Œè²¢çŒ®åº¦ã‚’å…¬å¹³ã«è©•ä¾¡ã™ã‚‹ã€‚
å”åŠ›ã‚²ãƒ¼ãƒ ç†è«–ã«åŸºã¥ãã€ã€Œã“ã®ãƒãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ãŸã‚‰å…¨ä½“æ€§èƒ½ãŒã©ã‚Œã ã‘ä¸‹ãŒã‚‹ã‹ã€ã‚’æ•°å€¤åŒ–ã€‚
"""

from typing import List, Dict, Tuple, Any, Callable
import numpy as np
import networkx as nx
import logging
from dataclasses import dataclass
import time

logger = logging.getLogger(__name__)


@dataclass
class ShapleyResult:
    """Shapley Valueåˆ†æã®çµæœ"""
    shapley_values: Dict[str, float]  # ãƒãƒ¼ãƒ‰å â†’ Shapleyå€¤
    top_contributors: List[Tuple[str, float]]  # (ãƒãƒ¼ãƒ‰å, Shapleyå€¤)ã®ãƒªã‚¹ãƒˆï¼ˆé™é †ï¼‰
    cumulative_contribution: List[Tuple[int, float]]  # (ä¸Šä½N, ç´¯ç©è²¢çŒ®ç‡%)
    category_contributions: Dict[str, float]  # ã‚«ãƒ†ã‚´ãƒª â†’ å¹³å‡Shapleyå€¤
    total_value: float  # V(å…¨ãƒãƒ¼ãƒ‰)
    computation_time: float  # è¨ˆç®—æ™‚é–“ï¼ˆç§’ï¼‰
    n_samples: int  # ã‚µãƒ³ãƒ—ãƒ«æ•°
    interpretation: str  # å¹³æ˜“ãªè§£é‡ˆæ–‡


class ShapleyAnalyzer:
    """
    Shapley Valueåˆ†æã‚¯ãƒ©ã‚¹
    
    å”åŠ›ã‚²ãƒ¼ãƒ ç†è«–ã«åŸºã¥ãå…¬å¹³ãªè²¢çŒ®åº¦è©•ä¾¡:
    - Monte Carloè¿‘ä¼¼ã§è¨ˆç®—åŠ¹ç‡åŒ–ï¼ˆæ­£ç¢ºè§£ã¯2^Né€šã‚Šï¼‰
    - ä¾¡å€¤é–¢æ•°V: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®éƒ¨åˆ†é›†åˆã®æ€§èƒ½
    - é™ç•Œè²¢çŒ®: ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ãŸã¨ãã®æ€§èƒ½å‘ä¸Š
    """
    
    def __init__(
        self,
        adjacency_matrix: np.ndarray,
        node_names: List[str],
        node_categories: Dict[str, str] = None,
        value_function: str = "pagerank_sum"
    ):
        """
        Args:
            adjacency_matrix: éš£æ¥è¡Œåˆ—ï¼ˆNÃ—Nï¼‰
            node_names: ãƒãƒ¼ãƒ‰åãƒªã‚¹ãƒˆ
            node_categories: ãƒãƒ¼ãƒ‰å â†’ ã‚«ãƒ†ã‚´ãƒªåã®è¾æ›¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            value_function: ä¾¡å€¤é–¢æ•°ã‚¿ã‚¤ãƒ—ï¼ˆ"pagerank_sum", "efficiency", "connectivity"ï¼‰
        """
        self.matrix = adjacency_matrix.copy()
        self.node_names = node_names
        self.node_categories = node_categories or {}
        self.n = len(node_names)
        
        # ä¾¡å€¤é–¢æ•°ã®é¸æŠ
        if value_function == "pagerank_sum":
            self.value_func = self._value_pagerank_sum
        elif value_function == "efficiency":
            self.value_func = self._value_network_efficiency
        elif value_function == "connectivity":
            self.value_func = self._value_connectivity
        else:
            raise ValueError(f"æœªçŸ¥ã®ä¾¡å€¤é–¢æ•°: {value_function}")
        
        logger.info(f"ShapleyAnalyzeråˆæœŸåŒ–: {self.n}ãƒãƒ¼ãƒ‰, ä¾¡å€¤é–¢æ•°={value_function}")
    
    def compute_shapley_values(
        self,
        n_samples: int = 1000,
        random_seed: int = None,
        progress_callback: Callable[[int, int], None] = None
    ) -> ShapleyResult:
        """
        Monte Carloè¿‘ä¼¼ã§Shapley Valueã‚’è¨ˆç®—
        
        Args:
            n_samples: ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆå¤šã„ã»ã©ç²¾åº¦å‘ä¸Šã€è¨ˆç®—æ™‚é–“å¢—åŠ ï¼‰
            random_seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°(current, total)
        
        Returns:
            ShapleyResult
        """
        start_time = time.time()
        
        if random_seed is not None:
            np.random.seed(random_seed)
        
        # Shapleyå€¤ã‚’åˆæœŸåŒ–
        shapley_values = {name: 0.0 for name in self.node_names}
        
        logger.info(f"Shapley Valueè¨ˆç®—é–‹å§‹: {n_samples}ã‚µãƒ³ãƒ—ãƒ«")
        
        # Monte Carloã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        for sample in range(n_samples):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªé †åˆ—ã‚’ç”Ÿæˆ
            permutation = np.random.permutation(self.n)
            
            # å„ãƒãƒ¼ãƒ‰ã®é™ç•Œè²¢çŒ®ã‚’è¨ˆç®—
            for i, node_idx in enumerate(permutation):
                node_name = self.node_names[node_idx]
                
                # ã“ã®ãƒãƒ¼ãƒ‰ã‚ˆã‚Šå‰ã®ãƒãƒ¼ãƒ‰é›†åˆ
                S_before_indices = permutation[:i]
                S_after_indices = permutation[:i+1]
                
                # ä¾¡å€¤é–¢æ•°ã‚’è©•ä¾¡
                V_before = self._evaluate_coalition(S_before_indices)
                V_after = self._evaluate_coalition(S_after_indices)
                
                # é™ç•Œè²¢çŒ®
                marginal_contribution = V_after - V_before
                
                # Shapleyå€¤ã«åŠ ç®—
                shapley_values[node_name] += marginal_contribution
            
            # é€²æ—å ±å‘Š
            if progress_callback and (sample + 1) % 50 == 0:
                progress_callback(sample + 1, n_samples)
        
        # å¹³å‡åŒ–
        for name in shapley_values:
            shapley_values[name] /= n_samples
        
        # å…¨ä½“ã®ä¾¡å€¤
        total_value = self._evaluate_coalition(np.arange(self.n))
        
        computation_time = time.time() - start_time
        logger.info(f"Shapley Valueè¨ˆç®—å®Œäº†: {computation_time:.2f}ç§’")
        
        # çµæœã‚’æ•´å½¢
        result = self._format_result(shapley_values, total_value, n_samples, computation_time)
        
        return result
    
    def _evaluate_coalition(self, coalition_indices: np.ndarray) -> float:
        """
        é€£æºé›†åˆï¼ˆéƒ¨åˆ†ã‚°ãƒ©ãƒ•ï¼‰ã®ä¾¡å€¤ã‚’è©•ä¾¡
        
        Args:
            coalition_indices: é€£æºã«å«ã¾ã‚Œã‚‹ãƒãƒ¼ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        
        Returns:
            ä¾¡å€¤ã‚¹ã‚³ã‚¢
        """
        if len(coalition_indices) == 0:
            return 0.0
        
        # éƒ¨åˆ†ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡º
        submatrix = self.matrix[np.ix_(coalition_indices, coalition_indices)]
        
        # ä¾¡å€¤é–¢æ•°ã‚’é©ç”¨
        value = self.value_func(submatrix, len(coalition_indices))
        
        return value
    
    def _value_pagerank_sum(self, submatrix: np.ndarray, n_nodes: int) -> float:
        """
        ä¾¡å€¤é–¢æ•°: PageRankã®åˆè¨ˆ
        
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å½±éŸ¿åŠ›ã®ç·å’Œã‚’è©•ä¾¡
        """
        if n_nodes == 0:
            return 0.0
        
        try:
            # NetworkXã‚°ãƒ©ãƒ•ã«å¤‰æ›
            G = nx.from_numpy_array(submatrix, create_using=nx.DiGraph)
            
            # PageRankè¨ˆç®—
            if G.number_of_edges() == 0:
                # ã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆã¯å‡ç­‰
                return 1.0
            
            pagerank = nx.pagerank(G, weight='weight')
            
            # åˆè¨ˆï¼ˆæ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€å¹³å‡çš„ã«ã¯1/n_nodesï¼‰
            return sum(pagerank.values())
        
        except Exception as e:
            logger.warning(f"PageRankè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _value_network_efficiency(self, submatrix: np.ndarray, n_nodes: int) -> float:
        """
        ä¾¡å€¤é–¢æ•°: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹ç‡æ€§
        
        å¹³å‡æœ€çŸ­çµŒè·¯é•·ã®é€†æ•°ï¼ˆåŠ¹ç‡æ€§ï¼‰
        """
        if n_nodes <= 1:
            return 0.0
        
        try:
            G = nx.from_numpy_array(submatrix, create_using=nx.DiGraph)
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«åŠ¹ç‡æ€§ï¼ˆdisconnectedã§ã‚‚è¨ˆç®—å¯èƒ½ï¼‰
            efficiency = nx.global_efficiency(G)
            
            return efficiency
        
        except Exception as e:
            logger.warning(f"åŠ¹ç‡æ€§è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _value_connectivity(self, submatrix: np.ndarray, n_nodes: int) -> float:
        """
        ä¾¡å€¤é–¢æ•°: æ¥ç¶šæ€§
        
        ã‚¨ãƒƒã‚¸æ•°ã®æ­£è¦åŒ–å€¤
        """
        if n_nodes <= 1:
            return 0.0
        
        # éã‚¼ãƒ­è¦ç´ æ•°ï¼ˆã‚¨ãƒƒã‚¸æ•°ï¼‰
        n_edges = np.count_nonzero(submatrix)
        
        # å¯èƒ½ãªæœ€å¤§ã‚¨ãƒƒã‚¸æ•°ã§æ­£è¦åŒ–
        max_edges = n_nodes * (n_nodes - 1)
        
        if max_edges == 0:
            return 0.0
        
        return n_edges / max_edges
    
    def _format_result(
        self,
        shapley_values: Dict[str, float],
        total_value: float,
        n_samples: int,
        computation_time: float
    ) -> ShapleyResult:
        """
        çµæœã‚’æ•´å½¢ã—ã¦ShapleyResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆ
        """
        # é™é †ã‚½ãƒ¼ãƒˆ
        sorted_items = sorted(shapley_values.items(), key=lambda x: x[1], reverse=True)
        top_contributors = sorted_items
        
        # ç´¯ç©è²¢çŒ®åº¦
        cumulative_contribution = []
        cumulative_sum = 0.0
        total_shapley_sum = sum(shapley_values.values())
        
        for i, (name, value) in enumerate(sorted_items, 1):
            cumulative_sum += value
            if total_shapley_sum > 0:
                cumulative_pct = (cumulative_sum / total_shapley_sum) * 100
            else:
                cumulative_pct = 0.0
            cumulative_contribution.append((i, cumulative_pct))
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡è²¢çŒ®åº¦
        category_contributions = {}
        if self.node_categories:
            category_sums = {}
            category_counts = {}
            
            for name, value in shapley_values.items():
                category = self.node_categories.get(name, "Unknown")
                category_sums[category] = category_sums.get(category, 0.0) + value
                category_counts[category] = category_counts.get(category, 0) + 1
            
            for category, total in category_sums.items():
                count = category_counts[category]
                category_contributions[category] = total / count if count > 0 else 0.0
        
        # å¹³æ˜“ãªè§£é‡ˆæ–‡ã‚’ç”Ÿæˆ
        interpretation = self._generate_interpretation(
            top_contributors, cumulative_contribution, total_value
        )
        
        return ShapleyResult(
            shapley_values=shapley_values,
            top_contributors=top_contributors,
            cumulative_contribution=cumulative_contribution,
            category_contributions=category_contributions,
            total_value=total_value,
            computation_time=computation_time,
            n_samples=n_samples,
            interpretation=interpretation
        )
    
    def _generate_interpretation(
        self,
        top_contributors: List[Tuple[str, float]],
        cumulative_contribution: List[Tuple[int, float]],
        total_value: float
    ) -> str:
        """
        å¹³æ˜“ãªæ—¥æœ¬èªã®è§£é‡ˆæ–‡ã‚’ç”Ÿæˆ
        """
        if len(top_contributors) == 0:
            return "åˆ†æçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # æœ€ä¸Šä½ãƒãƒ¼ãƒ‰
        top_node, top_value = top_contributors[0]
        top_pct = (top_value / total_value * 100) if total_value > 0 else 0
        
        # 80%é”æˆã™ã‚‹ãƒãƒ¼ãƒ‰æ•°
        n_for_80_pct = next(
            (n for n, pct in cumulative_contribution if pct >= 80.0),
            len(top_contributors)
        )
        
        # è² ã®å€¤ã‚’æŒã¤ãƒãƒ¼ãƒ‰
        negative_nodes = [name for name, value in top_contributors if value < 0]
        
        interpretation = f"""
## ğŸ“Š Shapley Valueåˆ†æçµæœã®è§£é‡ˆ

### æœ€é‡è¦ãƒãƒ¼ãƒ‰
**ã€Œ{top_node}ã€**ãŒæœ€ã‚‚é«˜ã„è²¢çŒ®åº¦ã‚’ç¤ºã—ã¦ãŠã‚Šã€å…¨ä½“æ€§èƒ½ã®ç´„**{top_pct:.1f}%**ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚
ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®æŠ•è³‡ãŒæœ€ã‚‚åŠ¹æœçš„ã§ã™ã€‚

### é‡ç‚¹ç®¡ç†å¯¾è±¡
ä¸Šä½**{n_for_80_pct}ãƒãƒ¼ãƒ‰**ã§å…¨ä½“ã®**80%**ã®è²¢çŒ®ã‚’èª¬æ˜ã§ãã¾ã™ã€‚
ã“ã‚Œã‚‰ã®ãƒãƒ¼ãƒ‰ã‚’é‡ç‚¹çš„ã«ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ãªæ”¹å–„ãŒå¯èƒ½ã§ã™ã€‚

### è²¢çŒ®åº¦åˆ†å¸ƒ
- ç·ãƒãƒ¼ãƒ‰æ•°: {len(top_contributors)}
- å…¨ä½“ä¾¡å€¤: {total_value:.4f}
- å¹³å‡è²¢çŒ®åº¦: {total_value/len(top_contributors):.4f}
"""
        
        if negative_nodes:
            interpretation += f"""
### âš ï¸ è¦å†æ¤œè¨ãƒãƒ¼ãƒ‰
ä»¥ä¸‹ã®{len(negative_nodes)}ãƒãƒ¼ãƒ‰ã¯è² ã®è²¢çŒ®åº¦ã‚’ç¤ºã—ã¦ã„ã¾ã™:
{', '.join(f'ã€Œ{name}ã€' for name in negative_nodes[:3])}{'...' if len(negative_nodes) > 3 else ''}

ã“ã‚Œã‚‰ã¯å‰Šé™¤ã¾ãŸã¯å†è¨­è¨ˆã«ã‚ˆã‚Šã€å…¨ä½“æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
"""
        
        interpretation += """
### ğŸ’¡ æ´»ç”¨æ–¹æ³•
1. **æŠ•è³‡å„ªå…ˆé †ä½**: Shapleyå€¤ãŒé«˜ã„ãƒãƒ¼ãƒ‰ã‹ã‚‰æ”¹å–„
2. **ãƒªã‚½ãƒ¼ã‚¹é…åˆ†**: è²¢çŒ®åº¦ã«å¿œã˜ãŸäºˆç®—é…åˆ†
3. **ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç™ºè¦‹**: ã€Œç¸ã®ä¸‹ã®åŠ›æŒã¡ã€ã®å¯è¦–åŒ–
4. **ãƒ—ãƒ­ã‚»ã‚¹ç°¡ç´ åŒ–**: è² ã®å€¤ãƒãƒ¼ãƒ‰ã®å‰Šæ¸›æ¤œè¨
"""
        
        return interpretation.strip()


def compute_shapley_coalition_stability(
    shapley_values: Dict[str, float],
    adjacency_matrix: np.ndarray,
    node_names: List[str]
) -> Dict[str, Any]:
    """
    é€£æºã®å®‰å®šæ€§ã‚’åˆ†æ
    
    Shapleyå€¤ãŒé«˜ã„ãƒãƒ¼ãƒ‰åŒå£«ã¯å”åŠ›ã™ã¹ãã‹ï¼Ÿ
    
    Returns:
        stable_coalitions: å®‰å®šã—ãŸé€£æºå€™è£œ
    """
    n = len(node_names)
    
    # Shapleyå€¤ã®ä¸Šä½25%
    sorted_nodes = sorted(shapley_values.items(), key=lambda x: x[1], reverse=True)
    top_25_pct_count = max(1, n // 4)
    top_nodes = [name for name, _ in sorted_nodes[:top_25_pct_count]]
    
    # ä¸Šä½ãƒãƒ¼ãƒ‰é–“ã®æ¥ç¶šå¼·åº¦
    top_indices = [node_names.index(name) for name in top_nodes]
    top_submatrix = adjacency_matrix[np.ix_(top_indices, top_indices)]
    
    # å¯†çµåˆãƒšã‚¢
    dense_pairs = []
    for i, name_i in enumerate(top_nodes):
        for j, name_j in enumerate(top_nodes):
            if i < j and top_submatrix[i, j] != 0:
                strength = abs(top_submatrix[i, j])
                dense_pairs.append((name_i, name_j, strength))
    
    dense_pairs.sort(key=lambda x: x[2], reverse=True)
    
    return {
        "top_contributors": top_nodes,
        "dense_connections": dense_pairs[:10],
        "recommendation": f"ä¸Šä½{len(top_nodes)}ãƒãƒ¼ãƒ‰ã®é€£æºã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã§ã€ç›¸ä¹—åŠ¹æœãŒæœŸå¾…ã§ãã¾ã™ã€‚"
    }
