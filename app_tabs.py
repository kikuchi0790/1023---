"""
Process Insight Modeler (PIM) - ã‚¿ãƒ–å½¢å¼UI
ç”Ÿç”£ãƒ—ãƒ­ã‚»ã‚¹ã®æš—é»™çŸ¥ã‚’å½¢å¼çŸ¥ã«å¤‰æ›ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import json
import time
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st
from openai import OpenAIError
from config.settings import settings
from core.session_manager import SessionManager
from core.llm_client import LLMClient
from utils.matrix_evaluator import MatrixEvaluator
from core.data_models import (
    FunctionalCategory,
    CategoryGenerationOptions,
    CategorySet
)
from utils.analytics_progress import AnalyticsProgressTracker, create_simple_callback
from utils.analytics_export import add_analytics_export_to_sidebar


def render_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚µãƒãƒªãƒ¼"""
    with st.sidebar:
        st.header("ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±")
        
        process_name = SessionManager.get_process_name()
        if process_name:
            st.success(f"**ãƒ—ãƒ­ã‚»ã‚¹**: {process_name}")
        else:
            st.warning("ãƒ—ãƒ­ã‚»ã‚¹æœªå®šç¾©")
        
        categories = SessionManager.get_functional_categories()
        if categories:
            st.info(f"**ã‚«ãƒ†ã‚´ãƒªæ•°**: {len(categories)}")
        else:
            st.warning("ã‚«ãƒ†ã‚´ãƒªæœªå®šç¾©")
        
        nodes = SessionManager.get_nodes()
        if nodes:
            st.info(f"**ãƒãƒ¼ãƒ‰æ•°**: {len(nodes)}")
        else:
            st.warning("ãƒãƒ¼ãƒ‰æœªå®šç¾©")
        
        if st.session_state.get("adjacency_matrix") is not None:
            st.info("**éš£æ¥è¡Œåˆ—**: ç”Ÿæˆæ¸ˆã¿")
        else:
            st.warning("éš£æ¥è¡Œåˆ—æœªç”Ÿæˆ")
        
        st.divider()
        
        st.caption("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        with st.expander("ğŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", expanded=False):
            st.markdown("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™")
            
            export_format = st.radio(
                "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼",
                options=["Excel (.xlsx)", "JSON (.json)", "CSV (.csv)"],
                help="Excel: å…¨ãƒ‡ãƒ¼ã‚¿ã€JSON: å®Œå…¨ãªå¾©å…ƒç”¨ã€CSV: éš£æ¥è¡Œåˆ—ã®ã¿",
                key="export_format_radio"
            )
            
            if st.button("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ", use_container_width=True, type="primary", key="export_button"):
                try:
                    from utils.data_io import export_to_excel, export_to_json, export_adjacency_matrix_to_csv
                    from datetime import datetime
                    import json
                    
                    if export_format == "Excel (.xlsx)":
                        buffer = export_to_excel()
                        st.download_button(
                            label="ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=buffer,
                            file_name=f"pim_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            key="download_excel"
                        )
                        st.success("âœ… Excelã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
                    elif export_format == "JSON (.json)":
                        json_data = export_to_json()
                        json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ğŸ“¥ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_str,
                            file_name=f"pim_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            use_container_width=True,
                            key="download_json"
                        )
                        st.success("âœ… JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
                    else:
                        csv_str = export_adjacency_matrix_to_csv()
                        st.download_button(
                            label="ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=csv_str,
                            file_name=f"adjacency_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True,
                            key="download_csv"
                        )
                        st.success("âœ… CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
                except Exception as e:
                    st.error(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with st.expander("ğŸ“¥ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", expanded=False):
            st.markdown("ä¿å­˜ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™")
            st.warning("âš ï¸ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¸Šæ›¸ãã•ã‚Œã¾ã™")
            
            uploaded_file = st.file_uploader(
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                type=["json", "xlsx", "csv"],
                help="JSON, Excel, CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ",
                key="import_file_uploader"
            )
            
            if uploaded_file is not None:
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                st.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}")
                
                if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", use_container_width=True, type="primary", key="import_button"):
                    try:
                        from utils.data_io import import_from_json, import_from_excel, import_adjacency_matrix_from_csv
                        import json
                        
                        if file_extension == "json":
                            json_data = json.load(uploaded_file)
                            if import_from_json(json_data):
                                st.success("âœ… JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                                st.info("ğŸ”„ ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã„ã¾ã™...")
                                st.rerun()
                        elif file_extension == "xlsx":
                            if import_from_excel(uploaded_file):
                                st.success("âœ… Excelã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                                st.info("ğŸ”„ ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã„ã¾ã™...")
                                st.rerun()
                        elif file_extension == "csv":
                            if import_adjacency_matrix_from_csv(uploaded_file):
                                st.success("âœ… CSVï¼ˆéš£æ¥è¡Œåˆ—ï¼‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                                st.info("ğŸ”„ ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã„ã¾ã™...")
                                st.rerun()
                    except Exception as e:
                        st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                        import traceback
                        with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                            st.code(traceback.format_exc())
        
        # é«˜åº¦ãªåˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        add_analytics_export_to_sidebar()


def tab1_process_definition():
    """ã‚¿ãƒ–1: ãƒ—ãƒ­ã‚»ã‚¹å®šç¾©"""
    st.header("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ—ãƒ­ã‚»ã‚¹å®šç¾©")
    
    st.markdown("""
    åˆ†æå¯¾è±¡ã®ç”Ÿç”£ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®šç¾©ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹åã¨è©³ç´°ãªæ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
    """)
    
    process_name = st.text_input(
        "ç”Ÿç”£ãƒ—ãƒ­ã‚»ã‚¹å",
        value=SessionManager.get_process_name(),
        placeholder="ä¾‹: è‡ªå‹•è»Šã‚¨ãƒ³ã‚¸ãƒ³çµ„ç«‹å·¥ç¨‹",
        help="åˆ†æå¯¾è±¡ã®ç”Ÿç”£ãƒ—ãƒ­ã‚»ã‚¹ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    )
    
    process_description = st.text_area(
        "ãƒ—ãƒ­ã‚»ã‚¹ã®æ¦‚è¦",
        value=SessionManager.get_process_description(),
        height=300,
        placeholder="ãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ãªèª¬æ˜ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„...",
        help="ãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°ã€ä¸»è¦ãªå·¥ç¨‹ã€ä½¿ç”¨ã™ã‚‹è¨­å‚™ãªã©ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„",
    )
    
    SessionManager.update_process_info(process_name, process_description)
    
    st.divider()
    
    if process_name and process_description:
        st.success("âœ… ãƒ—ãƒ­ã‚»ã‚¹å®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸ")
        st.info("æ¬¡ã®ã‚¿ãƒ–ã€Œæ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã€ã«é€²ã‚“ã§ãã ã•ã„")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ãƒ—ãƒ­ã‚»ã‚¹å")
            st.info(process_name)
        with col2:
            st.subheader("ãƒ—ãƒ­ã‚»ã‚¹æ¦‚è¦")
            st.text_area(
                "æ¦‚è¦",
                value=process_description,
                height=150,
                disabled=True,
                label_visibility="collapsed",
            )
    else:
        st.warning("âš ï¸ ãƒ—ãƒ­ã‚»ã‚¹åã¨æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")


def tab2_functional_categories():
    """ã‚¿ãƒ–2: æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªå®šç¾©"""
    st.header("ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—2: æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªå®šç¾©")
    
    process_name = SessionManager.get_process_name()
    process_description = SessionManager.get_process_description()
    
    if not (process_name and process_description):
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–1ã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ§‹æˆã™ã‚‹ã€Œæ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã€ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã¨ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹ã®å‹•çš„ãªå¤‰æ›æ©Ÿèƒ½ï¼ˆã‚¤ãƒ³ãƒ—ãƒƒãƒˆâ†’å¤‰æ›â†’ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆï¼‰ã§ã™ã€‚
    """)
    
    with st.expander("ğŸ¯ ãƒ—ãƒ­ã‚»ã‚¹æ©Ÿèƒ½ã®æŠ½å‡ºè¨­å®š", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            analysis_focus = st.selectbox(
                "åˆ†æã®è¦–ç‚¹",
                [
                    "balanced",
                    "material_flow",
                    "information_flow",
                    "quality_gates"
                ],
                format_func=lambda x: {
                    "balanced": "ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆæ¨å¥¨ï¼‰",
                    "material_flow": "ãƒ¢ãƒã®æµã‚Œé‡è¦–",
                    "information_flow": "æƒ…å ±ã®æµã‚Œé‡è¦–",
                    "quality_gates": "å“è³ªã‚²ãƒ¼ãƒˆé‡è¦–"
                }[x],
                help="ãƒ—ãƒ­ã‚»ã‚¹åˆ†æã®è¦–ç‚¹ã‚’é¸æŠã—ã¾ã™"
            )
        
        with col2:
            granularity = st.selectbox(
                "ãƒ—ãƒ­ã‚»ã‚¹ã®åˆ†è§£ãƒ¬ãƒ™ãƒ«",
                ["standard", "high_level", "detailed"],
                format_func=lambda x: {
                    "high_level": "é«˜ãƒ¬ãƒ™ãƒ«ï¼ˆ4-5å€‹ã®å¤§å·¥ç¨‹ï¼‰",
                    "standard": "æ¨™æº–ï¼ˆ6-8å€‹ã®ä¸­å·¥ç¨‹ï¼‰",
                    "detailed": "è©³ç´°ï¼ˆ10-12å€‹ã®ä½œæ¥­å·¥ç¨‹ï¼‰"
                }[x],
                help="ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã©ã®ãƒ¬ãƒ™ãƒ«ã¾ã§åˆ†è§£ã™ã‚‹ã‹"
            )
        
        with col3:
            use_verbalized_sampling = st.checkbox(
                "å¤šæ§˜æ€§ç”Ÿæˆï¼ˆVerbalized Samplingï¼‰",
                value=False,
                help="5ã¤ã®ç•°ãªã‚‹åˆ†æå“²å­¦ã‹ã‚‰ç”Ÿæˆã—ã€æ¯”è¼ƒã§ãã¾ã™ï¼ˆæ¨å¥¨ï¼‰"
            )
    
    col_btn1, col_btn2 = st.columns([2, 1])
    
    with col_btn1:
        if st.button(
            "ğŸ¯ ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•æŠ½å‡º",
            type="primary",
            use_container_width=True,
            help="AIãŒæ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•çš„ã«æŠ½å‡ºã—ã¾ã™"
        ):
            try:
                llm_client = LLMClient()
                options = CategoryGenerationOptions(
                    analysis_focus=analysis_focus,
                    granularity=granularity
                )
                
                if use_verbalized_sampling:
                    with st.spinner("ğŸ¯ å¤šæ§˜ãªè¦–ç‚¹ã‹ã‚‰ç”Ÿæˆä¸­..."):
                        alternatives = llm_client.generate_diverse_category_sets(
                            process_name, process_description, num_perspectives=5
                        )
                        st.session_state["category_alternatives"] = alternatives
                        if alternatives:
                            st.success(f"âœ… {len(alternatives)}ã¤ã®ä»£æ›¿æ¡ˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                        else:
                            st.error("âŒ ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                else:
                    with st.spinner("ğŸ¯ æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºä¸­..."):
                        categories = llm_client.extract_categories_advanced(
                            process_name, process_description, options
                        )
                        
                        if categories:
                            SessionManager.set_functional_categories(
                                [cat.name for cat in categories]
                            )
                            
                            categories_metadata = {}
                            for cat in categories:
                                categories_metadata[cat.name] = {
                                    "description": cat.description,
                                    "inputs": cat.inputs,
                                    "outputs": cat.outputs,
                                    "examples": cat.examples,
                                    "importance": cat.importance
                                }
                            st.session_state["categories_metadata"] = categories_metadata
                            
                            st.success(f"âœ… {len(categories)}å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼")
                        else:
                            st.error("âŒ ã‚«ãƒ†ã‚´ãƒªã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                
            except OpenAIError as e:
                st.error(f"âŒ OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    with col_btn2:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            SessionManager.set_functional_categories([])
            st.session_state.pop("categories_metadata", None)
            st.session_state.pop("category_alternatives", None)
            st.rerun()
    
    if use_verbalized_sampling and "category_alternatives" in st.session_state:
        st.divider()
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸæ¡ˆã®æ¯”è¼ƒ")
        
        alternatives = st.session_state["category_alternatives"]
        for idx, alt in enumerate(alternatives, 1):
            with st.expander(f"ğŸ“‹ æ¡ˆ{idx}: {alt['perspective']}", expanded=(idx == 1)):
                st.markdown(f"**å“²å­¦**: {alt['philosophy']}")
                st.markdown(f"**ã‚«ãƒ†ã‚´ãƒªæ•°**: {len(alt['categories'])}")
                st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª**: {', '.join(alt['categories'])}")
                
                if st.button(f"ã“ã®æ¡ˆã‚’æ¡ç”¨", key=f"adopt_alt_{idx}"):
                    SessionManager.set_functional_categories(alt['categories'])
                    st.success("ã‚«ãƒ†ã‚´ãƒªã‚’è¨­å®šã—ã¾ã—ãŸï¼")
                    st.rerun()
    
    st.divider()
    
    categories = SessionManager.get_functional_categories()
    if categories:
        st.header("æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªä¸€è¦§")
        
        categories_metadata = st.session_state.get("categories_metadata", {})
        
        if categories_metadata:
            st.info(
                f"æŠ½å‡ºã•ã‚ŒãŸ{len(categories)}å€‹ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆè©³ç´°æƒ…å ±ä»˜ãï¼‰ã‚’ç¢ºèªã§ãã¾ã™ã€‚"
            )
            
            with st.expander("ğŸ“‹ ãƒ—ãƒ­ã‚»ã‚¹æ©Ÿèƒ½ã®è©³ç´°æƒ…å ±", expanded=False):
                for cat_name in categories:
                    if cat_name in categories_metadata:
                        meta = categories_metadata[cat_name]
                        with st.container():
                            col_name, col_imp = st.columns([3, 1])
                            with col_name:
                                st.markdown(f"### {cat_name}")
                            with col_imp:
                                importance = meta.get("importance", 3)
                                st.markdown(f"é‡è¦åº¦: {'â­' * importance}")
                            
                            if meta.get("description"):
                                st.markdown(f"**èª¬æ˜:** {meta['description']}")
                            
                            if meta.get("inputs") or meta.get("outputs"):
                                col_in, col_out = st.columns(2)
                                with col_in:
                                    if meta.get("inputs"):
                                        inputs_str = "ã€".join(meta["inputs"][:3])
                                        st.caption(f"ğŸ“¥ **ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ:** {inputs_str}")
                                with col_out:
                                    if meta.get("outputs"):
                                        outputs_str = "ã€".join(meta["outputs"][:2])
                                        st.caption(f"ğŸ“¤ **ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆ:** {outputs_str}")
                            
                            if meta.get("examples"):
                                examples_str = "ã€".join(meta["examples"][:3])
                                st.caption(f"ğŸ”§ **å…·ä½“ä¾‹:** {examples_str}")
                            
                            st.divider()
                    else:
                        st.markdown(f"### {cat_name}")
                        st.caption("ï¼ˆè©³ç´°æƒ…å ±ãªã—ï¼‰")
                        st.divider()
        
        st.subheader("ã‚«ãƒ†ã‚´ãƒªã®ç·¨é›†")
        st.info("è¡Œã®è¿½åŠ ãƒ»å‰Šé™¤ãƒ»ç·¨é›†ãŒå¯èƒ½ã§ã™ã€‚")
        
        df = pd.DataFrame({"ã‚«ãƒ†ã‚´ãƒªå": categories})
        
        edited_df = st.data_editor(
            df,
            num_rows="dynamic",
            use_container_width=True,
            hide_index=True,
            column_config={
                "ã‚«ãƒ†ã‚´ãƒªå": st.column_config.TextColumn(
                    "ã‚«ãƒ†ã‚´ãƒªå",
                    help="ãƒ—ãƒ­ã‚»ã‚¹ã®æ©Ÿèƒ½çš„ãªå´é¢ã‚’è¡¨ã™ã‚«ãƒ†ã‚´ãƒª",
                    max_chars=50,
                    required=True,
                )
            },
        )
        
        updated_categories = edited_df["ã‚«ãƒ†ã‚´ãƒªå"].dropna().tolist()
        updated_categories = [cat.strip() for cat in updated_categories if cat.strip()]
        
        if updated_categories != categories:
            SessionManager.set_functional_categories(updated_categories)
        
        if updated_categories:
            st.success(f"âœ… ç¾åœ¨ã®ã‚«ãƒ†ã‚´ãƒªæ•°: {len(updated_categories)}")
            st.info("æ¬¡ã®ã‚¿ãƒ–ã€Œãƒãƒ¼ãƒ‰å®šç¾©ã€ã«é€²ã‚“ã§ãã ã•ã„")
    else:
        st.warning("âš ï¸ ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã—ã¦ãã ã•ã„")


def tab3_node_definition():
    """ã‚¿ãƒ–3: ãƒãƒ¼ãƒ‰å®šç¾©ï¼ˆIDEF0ï¼‰"""
    st.header("ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ¼ãƒ‰å®šç¾©ï¼ˆIDEF0å½¢å¼ï¼‰")
    
    categories = SessionManager.get_functional_categories()
    
    if not categories:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–2ã§æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã‚’å®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    å„æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦ã€å…·ä½“çš„ãªãƒãƒ¼ãƒ‰ï¼ˆå·¥ç¨‹ã€é“å…·ã€ææ–™ã€ã‚¹ã‚­ãƒ«ãªã©ï¼‰ã‚’å®šç¾©ã—ã¾ã™ã€‚
    IDEF0å½¢å¼: **Inputï¼ˆææ–™ãƒ»æƒ…å ±ï¼‰** â†’ **Mechanismï¼ˆæ‰‹æ®µï¼‰** â†’ **Outputï¼ˆæˆæœç‰©ï¼‰**
    """)
    
    generation_mode = st.radio(
        "ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰",
        ["AIä¸»å°å¯¾è©±", "å¤šæ§˜æ€§ç”Ÿæˆï¼ˆVerbalized Samplingï¼‰", "Zigzaggingç²’åº¦èª¿æ•´"],
        horizontal=True,
        help="AIä¸»å°å¯¾è©±ï¼šå…¨ã‚«ãƒ†ã‚´ãƒªã‚’ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼å¯¾è©±ã§ç”Ÿæˆ / å¤šæ§˜æ€§ç”Ÿæˆï¼šè¤‡æ•°ã®ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ä¸€åº¦ã«ç”Ÿæˆ / Zigzaggingç²’åº¦èª¿æ•´ï¼šæ—¢å­˜ãƒãƒ¼ãƒ‰ã‚’æ®µéšçš„ã«ç´°åˆ†åŒ–"
    )
    
    st.divider()
    
    col_main, col_nodes = st.columns([2, 1])
    
    with col_nodes:
        st.subheader("ğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸãƒãƒ¼ãƒ‰ (IDEF0å½¢å¼)")
        
        all_idef0 = SessionManager.get_all_idef0_nodes()
        
        if all_idef0:
            selected_cat = st.selectbox(
                "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                options=list(all_idef0.keys()),
                key="idef0_category_selector"
            )
            
            if selected_cat and selected_cat in all_idef0:
                idef0_data = all_idef0[selected_cat]
                with st.container(border=True):
                    st.markdown(f"**{selected_cat}**")
                    
                    if idef0_data.get("inputs"):
                        st.markdown("**ğŸ“¥ Input:**")
                        for inp in idef0_data["inputs"]:
                            st.write(f"  â€¢ {inp}")
                    
                    if idef0_data.get("mechanisms"):
                        st.markdown("**ğŸ”§ Mechanism:**")
                        for mech in idef0_data["mechanisms"]:
                            st.write(f"  â€¢ {mech}")
                    
                    if idef0_data.get("outputs"):
                        st.markdown("**ğŸ“¤ Output:**")
                        for out in idef0_data["outputs"]:
                            st.write(f"  â€¢ {out}")
                    
                    if not any([idef0_data.get("inputs"), idef0_data.get("mechanisms"), idef0_data.get("outputs")]):
                        st.caption("ã¾ã æŠ½å‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            st.info("ä¼šè©±ãŒé€²ã‚€ã¨ã€IDEF0å½¢å¼ã§ãƒãƒ¼ãƒ‰ãŒè‡ªå‹•çš„ã«æŠ½å‡ºã•ã‚Œã¾ã™")
    
    with col_main:
        st.info(f"ğŸ’¡ å…¨{len(categories)}å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’ä¸€æ‹¬ã§è­°è«–ãƒ»ç”Ÿæˆã—ã¾ã™")
        
        if generation_mode == "AIä¸»å°å¯¾è©±":
            st.caption("ğŸ¯ğŸ”¬ğŸ‘¤ ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼AIå¯¾è©±ï¼ˆå…¨ã‚«ãƒ†ã‚´ãƒªä¸€æ‹¬ï¼‰")
            
            messages = SessionManager.get_messages()

            if not messages:
                llm_client = LLMClient()
                initial_message = llm_client.generate_initial_facilitator_message(
                    SessionManager.get_process_name(), categories
                )
                SessionManager.add_message("facilitator", initial_message)
                st.rerun()

            with st.container(height=400):
                for message in messages:
                    role = message["role"]
                    
                    if role == "facilitator":
                        with st.chat_message("assistant", avatar="ğŸ¯"):
                            st.markdown(f"**[ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼]**\n\n{message['content']}")
                    elif role == "expert":
                        with st.chat_message("assistant", avatar="ğŸ”¬"):
                            st.markdown(f"**[ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ]**\n\n{message['content']}")
                    else:
                        with st.chat_message("user", avatar="ğŸ‘¤"):
                            st.markdown(message['content'])

            st.divider()
            
            col_btn1, col_btn2 = st.columns([3, 1])
            
            with col_btn1:
                if st.button("ğŸ’­ ä¼šè©±ã‚’é€²ã‚ã‚‹", type="primary", use_container_width=True, help="AIãŸã¡ãŒå…¨ã‚«ãƒ†ã‚´ãƒªã‚’è­°è«–ã—ã¾ã™"):
                    try:
                        llm_client = LLMClient()
                        
                        with st.spinner("ğŸ¯ğŸ”¬ AIãŸã¡ãŒè­°è«–ä¸­..."):
                            discussion = llm_client.generate_ai_discussion(
                                process_name=SessionManager.get_process_name(),
                                categories=categories,
                                chat_history=messages,
                            )
                        
                        for msg in discussion:
                            SessionManager.add_message(msg["role"], msg["content"])
                        
                        with st.spinner("ğŸ“‹ IDEF0å½¢å¼ã§ãƒãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡ºä¸­..."):
                            all_idef0_nodes = llm_client.extract_all_idef0_nodes_from_chat(
                                process_name=SessionManager.get_process_name(),
                                process_description=SessionManager.get_process_description(),
                                categories=categories,
                                chat_history=SessionManager.get_messages(),
                            )
                            
                            for cat_name, idef0_node in all_idef0_nodes.items():
                                SessionManager.set_idef0_node(cat_name, idef0_node.model_dump())
                        
                        st.rerun()
                    
                    except OpenAIError as e:
                        st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            with col_btn2:
                if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True, help="å¯¾è©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
                    SessionManager.clear_messages()
                    if "categories_changed" in st.session_state:
                        st.session_state.categories_changed = False
                    st.rerun()
            
            user_input = st.chat_input("ğŸ’¬ ã‚ãªãŸã®çŸ¥è­˜ã‚„æ„è¦‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰...")
            
            if user_input:
                SessionManager.add_message("user", user_input)

                try:
                    llm_client = LLMClient()
                    
                    with st.spinner("ğŸ”¬ ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAIãŒå¿œç­”ä¸­..."):
                        expert_response = llm_client.generate_expert_response(
                            process_name=SessionManager.get_process_name(),
                            categories=categories,
                            chat_history=messages,
                            user_message=user_input,
                        )

                    SessionManager.add_message("expert", expert_response)

                    messages_with_expert = SessionManager.get_messages()

                    with st.spinner("ğŸ¯ ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ãƒ¼AIãŒå¿œç­”ä¸­..."):
                        facilitator_response = llm_client.generate_facilitator_response(
                            process_name=SessionManager.get_process_name(),
                            categories=categories,
                            chat_history=messages_with_expert,
                        )

                    SessionManager.add_message("facilitator", facilitator_response)
                    
                    with st.spinner("ğŸ“‹ IDEF0å½¢å¼ã§ãƒãƒ¼ãƒ‰ã‚’è‡ªå‹•æŠ½å‡ºä¸­..."):
                        all_idef0_nodes = llm_client.extract_all_idef0_nodes_from_chat(
                            process_name=SessionManager.get_process_name(),
                            process_description=SessionManager.get_process_description(),
                            categories=categories,
                            chat_history=SessionManager.get_messages(),
                        )
                        
                        for cat_name, idef0_node in all_idef0_nodes.items():
                            SessionManager.set_idef0_node(cat_name, idef0_node.model_dump())

                    st.rerun()

                except OpenAIError as e:
                    st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        elif generation_mode == "å¤šæ§˜æ€§ç”Ÿæˆï¼ˆVerbalized Samplingï¼‰":
            st.caption("ğŸ² Verbalized Sampling - å…¨ã‚«ãƒ†ã‚´ãƒªä¸€æ‹¬ç”Ÿæˆï¼ˆæ®µéšçš„ç”Ÿæˆï¼‰")
            
            # è¦–ç‚¹æ•°é¸æŠã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
            num_perspectives = st.slider(
                "ç”Ÿæˆã™ã‚‹è¦–ç‚¹ã®æ•°",
                min_value=1,
                max_value=5,
                value=3,
                help="1è¦–ç‚¹: æœ€é€Ÿï¼ˆç´„30ç§’ï¼‰ã€3è¦–ç‚¹: æ¨å¥¨ãƒãƒ©ãƒ³ã‚¹ã€5è¦–ç‚¹: æœ€å¤§å¤šæ§˜æ€§"
            )
            
            st.info(f"ğŸ’¡ {num_perspectives}ã¤ã®è¦–ç‚¹ã‚’é †æ¬¡ç”Ÿæˆã—ã¾ã™ã€‚å„è¦–ç‚¹ã®é€²æ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            
            if st.button("ğŸ² å¤šæ§˜ãªè¦–ç‚¹ã§ç”Ÿæˆ", type="primary", use_container_width=True, help=f"{num_perspectives}ã¤ã®ç•°ãªã‚‹æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã‹ã‚‰å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ç”Ÿæˆ"):
                try:
                    llm_client = LLMClient()
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                    progress_bar = st.progress(0.0)
                    status_text = st.empty()
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                    def update_progress(current, total, perspective_name):
                        progress = (current + 1) / total
                        progress_bar.progress(progress)
                        status_text.text(f"ğŸ² è¦–ç‚¹ {current + 1}/{total} ({perspective_name}) ã‚’ç”Ÿæˆä¸­...")
                    
                    # æ®µéšçš„ç”Ÿæˆ
                    perspectives = llm_client.generate_diverse_idef0_nodes_all_categories(
                        process_name=SessionManager.get_process_name(),
                        process_description=SessionManager.get_process_description(),
                        categories=categories,
                        num_perspectives=num_perspectives,
                        progress_callback=update_progress,
                    )
                    
                    # å®Œäº†
                    progress_bar.progress(1.0)
                    status_text.text(f"âœ… {num_perspectives}ã¤ã®è¦–ç‚¹ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
                    
                    if perspectives:
                        st.session_state.diverse_perspectives_all = perspectives
                        st.success(f"{len(perspectives)}ã¤ã®ç•°ãªã‚‹è¦–ç‚¹ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")
                    else:
                        st.error("è¦–ç‚¹ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        st.warning("ğŸ’¡ ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                        with st.expander("ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"):
                            st.markdown("""
                            **è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :**
                            1. LLMãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹JSONå½¢å¼ã§å¿œç­”ã—ã¦ã„ãªã„
                            2. ãƒ—ãƒ­ã‚»ã‚¹æ¦‚è¦ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€ã¾ãŸã¯è¤‡é›‘ã™ãã‚‹
                            3. ã‚«ãƒ†ã‚´ãƒªæ•°ãŒå¤šã™ãã‚‹ï¼ˆæ¨å¥¨: 5-8å€‹ï¼‰
                            
                            **å¯¾å‡¦æ–¹æ³•:**
                            - ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§Streamlitã‚’èµ·å‹•ã—ãŸå ´æ‰€ã§è©³ç´°ãƒ­ã‚°ã‚’ç¢ºèª
                            - ãƒ—ãƒ­ã‚»ã‚¹æ¦‚è¦ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«è¨˜è¿°
                            - ã‚«ãƒ†ã‚´ãƒªæ•°ã‚’æ¸›ã‚‰ã™
                            - ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ï¼ˆgpt-4oã€gpt-4-turboãªã©ï¼‰
                            """)
                
                except OpenAIError as e:
                    st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                        st.exception(e)
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                        st.exception(e)
            
            if "diverse_perspectives_all" in st.session_state and st.session_state.diverse_perspectives_all:
                st.markdown("### ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸè¦–ç‚¹ã®æ¯”è¼ƒ")
                
                perspectives = st.session_state.diverse_perspectives_all
                
                tabs = st.tabs([f"{p['perspective']} ({p['probability']:.2f})" for p in perspectives])
                
                for idx, (tab, persp) in enumerate(zip(tabs, perspectives)):
                    with tab:
                        st.info(persp['description'])
                        
                        if 'idef0_nodes' in persp:
                            cat_tabs = st.tabs(list(persp['idef0_nodes'].keys()))
                            
                            for cat_tab, (cat_name, idef0_data) in zip(cat_tabs, persp['idef0_nodes'].items()):
                                with cat_tab:
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.markdown("**ğŸ“¥ Input:**")
                                        for inp in idef0_data.get('inputs', []):
                                            st.write(f"â€¢ {inp}")
                                    
                                    with col2:
                                        st.markdown("**ğŸ”§ Mechanism:**")
                                        for mech in idef0_data.get('mechanisms', []):
                                            st.write(f"â€¢ {mech}")
                                    
                                    with col3:
                                        st.markdown("**ğŸ“¤ Output:**")
                                        for out in idef0_data.get('outputs', []):
                                            st.write(f"â€¢ {out}")
                        
                        if st.button(f"ã“ã®è¦–ç‚¹ã‚’æ¡ç”¨", key=f"adopt_all_{idx}", type="primary", use_container_width=True):
                            if 'idef0_nodes' in persp:
                                for cat_name, idef0_data in persp['idef0_nodes'].items():
                                    SessionManager.set_idef0_node(cat_name, idef0_data)
                            st.success(f"âœ… ã€{persp['perspective']}ã€ã‚’æ¡ç”¨ã—ã¾ã—ãŸï¼ãƒãƒ¼ãƒ‰ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚")
                            st.info("ğŸ’¡ ã‚¹ãƒ†ãƒƒãƒ—4ã§ãƒãƒ¼ãƒ‰å½±éŸ¿è©•ä¾¡ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
        
        elif generation_mode == "Zigzaggingç²’åº¦èª¿æ•´":
            st.caption("ğŸ” æ—¢å­˜ã®IDEF0ãƒãƒ¼ãƒ‰ã‚’æ®µéšçš„ã«ç´°åˆ†åŒ–")
            
            all_idef0 = SessionManager.get_all_idef0_nodes()
            
            if not all_idef0:
                st.warning("âš ï¸ ã¾ãšã€ŒAIä¸»å°å¯¾è©±ã€ã¾ãŸã¯ã€Œå¤šæ§˜æ€§ç”Ÿæˆã€ã§ãƒãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
                st.info("""
                **Zigzaggingç²’åº¦èª¿æ•´ã®ä½¿ã„æ–¹:**
                1. æœ€åˆã«ã€ŒAIä¸»å°å¯¾è©±ã€ã¾ãŸã¯ã€Œå¤šæ§˜æ€§ç”Ÿæˆã€ã§IDEF0ãƒãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
                2. åˆ†æçµæœã‚’è¦‹ã¦ã€Œç²’åº¦ãŒç²—ã„ã€ã¨æ„Ÿã˜ãŸã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ
                3. Zigzaggingæ‰‹æ³•ã§æ®µéšçš„ã«ç´°åˆ†åŒ–
                4. ç´°åˆ†åŒ–å¾Œã®ãƒãƒ¼ãƒ‰ã§å†è©•ä¾¡ãƒ»å†åˆ†æ
                """)
                return
            
            if "selected_refinement_node" in st.session_state and st.session_state.selected_refinement_node:
                selected_node = st.session_state.selected_refinement_node
                
                found_category = None
                for cat_name, idef0_data in all_idef0.items():
                    if selected_node in idef0_data.get("inputs", []) or \
                       selected_node in idef0_data.get("mechanisms", []) or \
                       selected_node in idef0_data.get("outputs", []):
                        found_category = cat_name
                        break
                
                if found_category:
                    st.success(f"ğŸ’¡ ã‚¿ãƒ–5ã‹ã‚‰ã€Œ{selected_node}ã€ã®ç´°åˆ†åŒ–ãŒææ¡ˆã•ã‚Œã¾ã—ãŸ")
                    st.info(f"ğŸ“ è©²å½“ã‚«ãƒ†ã‚´ãƒª: **{found_category}**")
                    st.markdown("---")
            
            st.markdown("""
            **åå¾©çš„ãªçŸ¥è­˜ç²¾ç·»åŒ–ãƒ—ãƒ­ã‚»ã‚¹**
            
            åˆ†æçµæœï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã€PageRankã€DSMæœ€é©åŒ–ãªã©ï¼‰ã‚’è¦‹ã¦ç²’åº¦ãŒç²—ã„ã¨æ„Ÿã˜ãŸå ´åˆã€
            ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§æ®µéšçš„ã«ç´°åˆ†åŒ–ã§ãã¾ã™ã€‚
            
            - **Output**: ã‚ˆã‚Šç´°ã‹ã„æ€§èƒ½æŒ‡æ¨™ãƒ»å“è³ªè¦ç´ ã«åˆ†è§£
            - **Mechanism**: ã‚ˆã‚Šç´°ã‹ã„ä½œæ¥­æ‰‹é †ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£
            - **Input**: ã‚ˆã‚Šç´°ã‹ã„æ§‹æˆè¦ç´ ã«åˆ†è§£
            """)
            
            default_index = 0
            if "selected_refinement_node" in st.session_state and st.session_state.selected_refinement_node:
                selected_node = st.session_state.selected_refinement_node
                for i, cat_name in enumerate(all_idef0.keys()):
                    idef0_data = all_idef0[cat_name]
                    if selected_node in idef0_data.get("inputs", []) or \
                       selected_node in idef0_data.get("mechanisms", []) or \
                       selected_node in idef0_data.get("outputs", []):
                        default_index = i
                        break
            
            selected_category = st.selectbox(
                "ç´°åˆ†åŒ–ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                options=list(all_idef0.keys()),
                index=default_index,
                key="zigzag_category_select"
            )
            
            current_idef0 = all_idef0.get(selected_category, {})
            
            st.markdown(f"### ğŸ“‹ ç¾åœ¨ã®IDEF0ãƒãƒ¼ãƒ‰: **{selected_category}**")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸ“¥ Inputï¼ˆææ–™ãƒ»æƒ…å ±ï¼‰:**")
                inputs = current_idef0.get("inputs", [])
                if inputs:
                    for inp in inputs:
                        st.write(f"â€¢ {inp}")
                else:
                    st.caption("ï¼ˆãªã—ï¼‰")
                st.metric("è¦ç´ æ•°", len(inputs))
            
            with col2:
                st.markdown("**ğŸ”§ Mechanismï¼ˆæ‰‹æ®µãƒ»æ‰‹é †ï¼‰:**")
                mechanisms = current_idef0.get("mechanisms", [])
                if mechanisms:
                    for mech in mechanisms:
                        st.write(f"â€¢ {mech}")
                else:
                    st.caption("ï¼ˆãªã—ï¼‰")
                st.metric("è¦ç´ æ•°", len(mechanisms))
            
            with col3:
                st.markdown("**ğŸ“¤ Outputï¼ˆæ€§èƒ½ãƒ»æˆæœç‰©ï¼‰:**")
                outputs = current_idef0.get("outputs", [])
                if outputs:
                    for out in outputs:
                        st.write(f"â€¢ {out}")
                else:
                    st.caption("ï¼ˆãªã—ï¼‰")
                st.metric("è¦ç´ æ•°", len(outputs))
            
            st.divider()
            
            refinement_depth = st.slider(
                "ç´°åˆ†åŒ–ã®æ·±ã•",
                min_value=1,
                max_value=3,
                value=1,
                help="1: è»½åº¦ï¼ˆå„è¦ç´ ã‚’2-3å€‹ã«åˆ†è§£ï¼‰ / 2: ä¸­ç¨‹åº¦ï¼ˆ3-5å€‹ã«åˆ†è§£ï¼‰ / 3: è©³ç´°ï¼ˆ5-7å€‹ã«åˆ†è§£ï¼‰"
            )
            
            depth_labels = {
                1: "ğŸŒ± è»½åº¦ï¼šå„è¦ç´ ã‚’2-3å€‹ã®ä¸‹ä½è¦ç´ ã«åˆ†è§£",
                2: "ğŸŒ¿ ä¸­ç¨‹åº¦ï¼šå„è¦ç´ ã‚’3-5å€‹ã®ä¸‹ä½è¦ç´ ã«è©³ç´°åˆ†è§£",
                3: "ğŸŒ³ è©³ç´°ï¼šå„è¦ç´ ã‚’5-7å€‹ã®ä¸‹ä½è¦ç´ ã«å¾¹åº•çš„ã«åˆ†è§£"
            }
            st.info(depth_labels[refinement_depth])
            
            if st.button("ğŸ”„ Zigzaggingã§ç´°åˆ†åŒ–", type="primary", use_container_width=True):
                try:
                    llm_client = LLMClient()
                    
                    with st.spinner(f"ğŸ¤– AIãŒã€Œ{selected_category}ã€ã‚’ç´°åˆ†åŒ–ä¸­..."):
                        refined_idef0 = llm_client.refine_idef0_with_zigzagging(
                            process_name=SessionManager.get_process_name(),
                            category=selected_category,
                            current_idef0=current_idef0,
                            refinement_depth=refinement_depth
                        )
                    
                    st.session_state.refined_idef0_preview = refined_idef0
                    st.success("âœ… ç´°åˆ†åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    
                except OpenAIError as e:
                    st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                        st.exception(e)
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                        st.exception(e)
            
            if "refined_idef0_preview" in st.session_state and st.session_state.refined_idef0_preview:
                refined = st.session_state.refined_idef0_preview
                
                st.divider()
                st.markdown(f"### ğŸ“Š ç´°åˆ†åŒ–å¾Œã®IDEF0ãƒãƒ¼ãƒ‰: **{refined.get('category', selected_category)}**")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**ğŸ“¥ Inputï¼ˆç´°åˆ†åŒ–å¾Œï¼‰:**")
                    refined_inputs = refined.get("inputs", [])
                    for inp in refined_inputs:
                        st.write(f"â€¢ {inp}")
                    
                    original_count = len(current_idef0.get("inputs", []))
                    new_count = len(refined_inputs)
                    delta = new_count - original_count
                    st.metric("è¦ç´ æ•°", new_count, delta=delta)
                
                with col2:
                    st.markdown("**ğŸ”§ Mechanismï¼ˆç´°åˆ†åŒ–å¾Œï¼‰:**")
                    refined_mechs = refined.get("mechanisms", [])
                    for mech in refined_mechs:
                        st.write(f"â€¢ {mech}")
                    
                    original_count = len(current_idef0.get("mechanisms", []))
                    new_count = len(refined_mechs)
                    delta = new_count - original_count
                    st.metric("è¦ç´ æ•°", new_count, delta=delta)
                
                with col3:
                    st.markdown("**ğŸ“¤ Outputï¼ˆç´°åˆ†åŒ–å¾Œï¼‰:**")
                    refined_outputs = refined.get("outputs", [])
                    for out in refined_outputs:
                        st.write(f"â€¢ {out}")
                    
                    original_count = len(current_idef0.get("outputs", []))
                    new_count = len(refined_outputs)
                    delta = new_count - original_count
                    st.metric("è¦ç´ æ•°", new_count, delta=delta)
                
                st.markdown("---")
                
                col_apply, col_cancel = st.columns([1, 1])
                
                with col_apply:
                    if st.button("âœ… ã“ã®ç´°åˆ†åŒ–ã‚’é©ç”¨", type="primary", use_container_width=True):
                        SessionManager.set_idef0_node(refined['category'], refined)
                        del st.session_state.refined_idef0_preview
                        st.success(f"âœ… ã€Œ{refined['category']}ã€ã‚’ç´°åˆ†åŒ–ã—ã¾ã—ãŸï¼ãƒãƒ¼ãƒ‰ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚")
                        st.info("ğŸ’¡ ã‚¹ãƒ†ãƒƒãƒ—4ã§ãƒãƒ¼ãƒ‰å½±éŸ¿è©•ä¾¡ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                
                with col_cancel:
                    if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                        del st.session_state.refined_idef0_preview
                        st.info("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")

    nodes = SessionManager.get_nodes()
    if nodes:
        st.divider()
        st.header("å®šç¾©ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ä¸€è¦§")
        st.info(
            f"æŠ½å‡ºã•ã‚ŒãŸ{len(nodes)}å€‹ã®ãƒãƒ¼ãƒ‰ã‚’ç¢ºèªãƒ»ç·¨é›†ã§ãã¾ã™ã€‚"
            "è¡Œã®è¿½åŠ ãƒ»å‰Šé™¤ãƒ»ç·¨é›†ãŒå¯èƒ½ã§ã™ã€‚"
        )

        df_nodes = pd.DataFrame({"ãƒãƒ¼ãƒ‰å": nodes})

        edited_nodes_df = st.data_editor(
            df_nodes,
            num_rows="dynamic",
            use_container_width=True,
            hide_index=True,
            column_config={
                "ãƒãƒ¼ãƒ‰å": st.column_config.TextColumn(
                    "ãƒãƒ¼ãƒ‰å",
                    help="ãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹æˆè¦ç´ ï¼ˆå·¥ç¨‹ã€é“å…·ã€ææ–™ãªã©ï¼‰",
                    max_chars=100,
                    required=True,
                )
            },
        )

        updated_nodes = edited_nodes_df["ãƒãƒ¼ãƒ‰å"].dropna().tolist()
        updated_nodes = [node.strip() for node in updated_nodes if node.strip()]

        if updated_nodes != nodes:
            SessionManager.set_nodes(updated_nodes)

        if updated_nodes:
            st.caption(f"ç¾åœ¨ã®ãƒãƒ¼ãƒ‰æ•°: {len(updated_nodes)}")
            st.success("âœ… ãƒãƒ¼ãƒ‰å®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸ")
            st.info("æ¬¡ã®ã‚¿ãƒ–ã€Œãƒãƒ¼ãƒ‰å½±éŸ¿è©•ä¾¡ã€ã«é€²ã‚“ã§ãã ã•ã„")




def tab4_node_evaluation():
    """ã‚¿ãƒ–4: ãƒãƒ¼ãƒ‰å½±éŸ¿è©•ä¾¡ï¼ˆæ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹è¡Œåˆ—è©•ä¾¡ï¼‰"""
    
    st.header("âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—4: ãƒãƒ¼ãƒ‰é–“å½±éŸ¿è©•ä¾¡ï¼ˆæ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹è¡Œåˆ—è©•ä¾¡ï¼‰")
    
    nodes = SessionManager.get_nodes()
    idef0_nodes = SessionManager.get_all_idef0_nodes()
    process_name = SessionManager.get_process_name()
    categories = SessionManager.get_functional_categories()
    
    if not nodes or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–3ã§ãƒãƒ¼ãƒ‰ã‚’2ã¤ä»¥ä¸Šå®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    if not idef0_nodes:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–3ã§IDEF0ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    ## ğŸ“ è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
    
    **æ™‚ç³»åˆ—é †ã‚«ãƒ†ã‚´ãƒªã‚’æ´»ç”¨ã—ãŸ3ãƒ•ã‚§ãƒ¼ã‚ºæ®µéšçš„è©•ä¾¡**
    
    ### ãƒ•ã‚§ãƒ¼ã‚º1: åŒä¸€ã‚«ãƒ†ã‚´ãƒªå†…è©•ä¾¡ï¼ˆè·é›¢0ï¼‰
    - **ç›®çš„**: å„ã‚«ãƒ†ã‚´ãƒªå†…éƒ¨ã®nÃ—nè¡Œåˆ—ã‚’è©•ä¾¡
    - **ç‰¹å¾´**: ãƒŠãƒ¬ãƒƒã‚¸ãªã—ï¼ˆåˆå›è©•ä¾¡ï¼‰ã€å¯¾è§’ç·š=0
    - **è©•ä¾¡å¯¾è±¡**: å†…éƒ¨ä¾å­˜é–¢ä¿‚ã®ã¿
    
    ### ãƒ•ã‚§ãƒ¼ã‚º2: éš£æ¥ã‚«ãƒ†ã‚´ãƒªé–“è©•ä¾¡ï¼ˆè·é›¢1ï¼‰
    - **ç›®çš„**: ã‚«ãƒ†ã‚´ãƒªAâ†’Bã®nÃ—mè¡Œåˆ—ã‚’è©•ä¾¡
    - **ç‰¹å¾´**: ãƒ•ã‚§ãƒ¼ã‚º1ã®éã‚¼ãƒ­è©•ä¾¡ã‚’ãƒŠãƒ¬ãƒƒã‚¸ã¨ã—ã¦æ´»ç”¨
    - **è©•ä¾¡å¯¾è±¡**: å‰å·¥ç¨‹ã®æˆæœç‰©ãŒæ¬¡å·¥ç¨‹ã«ä¸ãˆã‚‹å½±éŸ¿
    
    ### ãƒ•ã‚§ãƒ¼ã‚º3: é è·é›¢è©•ä¾¡ï¼ˆè·é›¢2+ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - **ç›®çš„**: ã‚«ãƒ†ã‚´ãƒªAâ†’Cã®nÃ—mè¡Œåˆ—ã‚’è©•ä¾¡
    - **ç‰¹å¾´**: Aâ†’Bâ†’Cã®ä¸­é–“ãƒ‘ã‚¹ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ´»ç”¨
    - **è©•ä¾¡å¯¾è±¡**: æ¨ç§»çš„å½±éŸ¿ã®è«–ç†çš„è©•ä¾¡
    
    **è©•ä¾¡ã‚¹ã‚±ãƒ¼ãƒ«**: Â±0, Â±1, Â±3, Â±9ï¼ˆæ˜ç¢ºãªåˆ¤æ–­ã®ãŸã‚ä¸­é–“å€¤å‰Šé™¤ï¼‰
    
    **ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›åŠ¹æœ**: è¡Œåˆ—å½¢å¼ã«ã‚ˆã‚Š60-80%å‰Šæ¸›
    """)
    
    if "matrix_evaluator" not in st.session_state:
        st.session_state.matrix_evaluator = None
    if "evaluation_plans" not in st.session_state:
        st.session_state.evaluation_plans = []
    if "current_phase" not in st.session_state:
        st.session_state.current_phase = 0
    if "completed_plans" not in st.session_state:
        st.session_state.completed_plans = set()
    
    st.markdown("---")
    st.subheader("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: è©•ä¾¡è¨ˆç”»ã®ä½œæˆ")
    
    st.markdown(f"""
    **ç¾åœ¨ã®ãƒãƒ¼ãƒ‰æ•°**: {len(nodes)}å€‹
    **ã‚«ãƒ†ã‚´ãƒªæ•°**: {len(categories)}å€‹
    **ã‚«ãƒ†ã‚´ãƒª**: {', '.join(categories)}
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        max_distance = st.selectbox(
            "è©•ä¾¡ã™ã‚‹æœ€å¤§ã‚«ãƒ†ã‚´ãƒªé–“è·é›¢",
            options=[0, 1, 2],
            index=1,
            help="0=åŒä¸€ã‚«ãƒ†ã‚´ãƒªã®ã¿ã€1=éš£æ¥ã¾ã§ï¼ˆæ¨å¥¨ï¼‰ã€2=é è·é›¢ã‚’å«ã‚€"
        )
    with col2:
        enable_distant = st.checkbox(
            "é è·é›¢è©•ä¾¡ã‚’æœ‰åŠ¹åŒ–ï¼ˆè·é›¢2+ï¼‰",
            value=False,
            help="ãƒ•ã‚§ãƒ¼ã‚º3ã‚’å®Ÿè¡Œï¼ˆLLMå‘¼ã³å‡ºã—ãŒå¤§å¹…ã«å¢—åŠ ï¼‰",
            disabled=(max_distance < 2)
        )
    
    if st.button("ğŸ”„ è©•ä¾¡è¨ˆç”»ã‚’ä½œæˆ", type="primary", key="create_plan_btn"):
        try:
            evaluator = MatrixEvaluator(categories, idef0_nodes, nodes)
            plans = evaluator.plan_evaluation_phases(
                max_distance=max_distance,
                enable_distant=enable_distant
            )
            
            st.session_state.matrix_evaluator = evaluator
            st.session_state.evaluation_plans = plans
            st.session_state.current_phase = 0
            st.session_state.completed_plans = set()
            
            SessionManager.get_project_data()["evaluations"] = []
            
            summary = evaluator.get_phase_summary(plans)
            
            st.success(f"âœ… è©•ä¾¡è¨ˆç”»ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆå…¨{summary['total_plans']}ä»¶ï¼‰")
            
            col_s1, col_s2, col_s3 = st.columns(3)
            with col_s1:
                phase1 = summary["phase_1_same"]
                st.metric(
                    "ãƒ•ã‚§ãƒ¼ã‚º1ï¼ˆåŒä¸€ã‚«ãƒ†ã‚´ãƒªï¼‰",
                    f"{phase1['count']}ä»¶",
                    delta=f"{phase1['total_pairs']}ãƒšã‚¢"
                )
            with col_s2:
                phase2 = summary["phase_2_adjacent"]
                st.metric(
                    "ãƒ•ã‚§ãƒ¼ã‚º2ï¼ˆéš£æ¥ã‚«ãƒ†ã‚´ãƒªï¼‰",
                    f"{phase2['count']}ä»¶",
                    delta=f"{phase2['total_pairs']}ãƒšã‚¢"
                )
            with col_s3:
                phase3 = summary["phase_3_distant"]
                st.metric(
                    "ãƒ•ã‚§ãƒ¼ã‚º3ï¼ˆé è·é›¢ï¼‰",
                    f"{phase3['count']}ä»¶",
                    delta=f"{phase3['total_pairs']}ãƒšã‚¢"
                )
            
            st.info("ğŸ’¡ æ¬¡ã¯ã€Œã‚¹ãƒ†ãƒƒãƒ—2: æ®µéšçš„è©•ä¾¡å®Ÿè¡Œã€ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
            
        except Exception as e:
            st.error(f"âŒ è©•ä¾¡è¨ˆç”»ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
    
    if not st.session_state.evaluation_plans:
        st.info("â„¹ï¸ è©•ä¾¡è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    
    st.markdown("---")
    st.subheader("ğŸš€ ã‚¹ãƒ†ãƒƒãƒ—2: æ®µéšçš„è©•ä¾¡å®Ÿè¡Œ")
    
    plans = st.session_state.evaluation_plans
    evaluator = st.session_state.matrix_evaluator
    completed = st.session_state.completed_plans
    
    remaining_plans = [p for i, p in enumerate(plans) if i not in completed]
    
    if not remaining_plans:
        st.success("âœ… å…¨ã¦ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.info("ğŸ‘‰ ä¸‹ã®ã€Œã‚¹ãƒ†ãƒƒãƒ—3: è©•ä¾¡çµæœç¢ºèªã€ã§è©³ç´°ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    else:
        st.markdown(f"""
        **é€²æ—**: {len(completed)} / {len(plans)} å®Œäº†
        
        æ¬¡ã«è©•ä¾¡ã™ã‚‹è¡Œåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
        """)
        
        phase_groups = {}
        for i, plan in enumerate(plans):
            if i in completed:
                continue
            phase_idx = plan["phase_index"]
            if phase_idx not in phase_groups:
                phase_groups[phase_idx] = []
            phase_groups[phase_idx].append((i, plan))
        
        first_uncompleted_phase = min(phase_groups.keys()) if phase_groups else 1
        
        for phase_idx in sorted(phase_groups.keys()):
            phase_plans = phase_groups[phase_idx]
            phase_name = {
                1: "ãƒ•ã‚§ãƒ¼ã‚º1: åŒä¸€ã‚«ãƒ†ã‚´ãƒªå†…",
                2: "ãƒ•ã‚§ãƒ¼ã‚º2: éš£æ¥ã‚«ãƒ†ã‚´ãƒªé–“",
                3: "ãƒ•ã‚§ãƒ¼ã‚º3: é è·é›¢"
            }[phase_idx]
            
            st.markdown(f"### ğŸ“Š {phase_name} ({len(phase_plans)}ä»¶)")
            
            st.info(f"ğŸ’¡ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹: {len(evaluator.knowledge_base)}ä»¶ã®éã‚¼ãƒ­è©•ä¾¡ã‚’å‚ç…§å¯èƒ½")
            
            if st.button(f"ğŸš€ {phase_name}ã‚’å…¨ã¦è©•ä¾¡", type="primary", key=f"batch_eval_phase_{phase_idx}"):
                    progress_bar = st.progress(0.0)
                    status_text = st.empty()
                    
                    total = len(phase_plans)
                    success_count = 0
                    
                    for idx, (plan_idx, plan) in enumerate(phase_plans):
                        status_text.text(f"è©•ä¾¡ä¸­: {idx + 1}/{total} - {plan['from_category']} â†’ {plan['to_category']}")
                        
                        try:
                            _execute_matrix_evaluation(
                                plan_idx,
                                plan,
                                evaluator,
                                idef0_nodes,
                                process_name
                            )
                            success_count += 1
                        except Exception as e:
                            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {plan['from_category']} â†’ {plan['to_category']}: {str(e)}")
                        
                        progress_bar.progress((idx + 1) / total)
                    
                    status_text.text("")
                    progress_bar.empty()
                    
                    st.success(f"âœ… {phase_name}ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆ{success_count}/{total}ä»¶æˆåŠŸï¼‰")
                    st.rerun()
            
            with st.expander(f"ğŸ“‹ å€‹åˆ¥è©•ä¾¡ ({len(phase_plans)}ä»¶)", expanded=(phase_idx == first_uncompleted_phase)):
                for plan_idx, plan in phase_plans:
                    col_info, col_action = st.columns([3, 1])
                    
                    with col_info:
                        n, m = plan["matrix_size"]
                        total_pairs = n * (n - 1) if plan["distance"] == 0 else n * m
                        
                        st.markdown(f"""
                        **{plan['from_category']} â†’ {plan['to_category']}**  
                        è¡Œåˆ—ã‚µã‚¤ã‚º: {n}Ã—{m} ({total_pairs}ãƒšã‚¢)  
                        ã‚«ãƒ†ã‚´ãƒªé–“è·é›¢: {plan['distance']}
                        """)
                    
                    with col_action:
                        if st.button("è©•ä¾¡", key=f"eval_plan_{plan_idx}"):
                            _execute_matrix_evaluation(
                                plan_idx,
                                plan,
                                evaluator,
                                idef0_nodes,
                                process_name
                            )
                            st.rerun()
    
    st.markdown("---")
    st.subheader("âœ… ã‚¹ãƒ†ãƒƒãƒ—3: è©•ä¾¡çµæœç¢ºèª")
    
    evaluations = SessionManager.get_evaluations()
    
    if not evaluations:
        st.warning("âš ï¸ è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    st.success(f"ğŸ‰ å…¨{len(evaluations)}ä»¶ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    non_zero_evals = [e for e in evaluations if e.get("score", 0) != 0]
    
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        st.metric("éã‚¼ãƒ­è©•ä¾¡ãƒšã‚¢", f"{len(non_zero_evals)} / {len(evaluations)}")
    with col_m2:
        sparsity = 100 * (1 - len(non_zero_evals) / len(evaluations)) if evaluations else 0
        st.metric("ç–è¡Œåˆ—ç‡", f"{sparsity:.1f}%")
    
    if non_zero_evals:
        with st.expander("ğŸ”¥ é«˜ã‚¹ã‚³ã‚¢ãƒšã‚¢ï¼ˆ|score| â‰¥ 5ï¼‰", expanded=True):
            high_score_evals = [e for e in non_zero_evals if abs(e.get("score", 0)) >= 5]
            
            if high_score_evals:
                high_score_evals_sorted = sorted(
                    high_score_evals,
                    key=lambda x: abs(x.get("score", 0)),
                    reverse=True
                )
                
                for eval_item in high_score_evals_sorted[:20]:
                    score = eval_item.get("score", 0)
                    score_color = "green" if score > 0 else "red"
                    
                    st.markdown(
                        f"**{eval_item['from_node']}** â†’ **{eval_item['to_node']}**: "
                        f":{score_color}[{score:+d}]"
                    )
            else:
                st.info("ã‚¹ã‚³ã‚¢çµ¶å¯¾å€¤5ä»¥ä¸Šã®ãƒšã‚¢ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    st.markdown("---")
    st.markdown("### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—")
    st.info("ğŸ‘‰ **ã‚¿ãƒ–5** ã§éš£æ¥è¡Œåˆ—ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    
    st.markdown("---")
    st.subheader("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ")
    
    if st.button("ğŸ”„ è©•ä¾¡è¨ˆç”»ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_plan_btn"):
        st.session_state.matrix_evaluator = None
        st.session_state.evaluation_plans = []
        st.session_state.current_phase = 0
        st.session_state.completed_plans = set()
        SessionManager.get_project_data()["evaluations"] = []
        st.info("ğŸ”„ è©•ä¾¡è¨ˆç”»ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚ã€Œã‚¹ãƒ†ãƒƒãƒ—1ã€ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.rerun()


def _execute_matrix_evaluation(
    plan_idx: int,
    plan: dict,
    evaluator: MatrixEvaluator,
    idef0_nodes: dict,
    process_name: str
):
    """
    è¡Œåˆ—è©•ä¾¡ã‚’å®Ÿè¡Œ
    
    Args:
        plan_idx: è©•ä¾¡è¨ˆç”»ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        plan: è©•ä¾¡è¨ˆç”»
        evaluator: MatrixEvaluatorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        idef0_nodes: IDEF0ãƒãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        process_name: ãƒ—ãƒ­ã‚»ã‚¹å
    """
    try:
        from_category = plan["from_category"]
        to_category = plan["to_category"]
        from_nodes = plan["from_nodes"]
        to_nodes = plan["to_nodes"]
        distance = plan["distance"]
        
        idef0_from = idef0_nodes.get(from_category, {})
        idef0_to = idef0_nodes.get(to_category, {})
        
        knowledge = evaluator.extract_knowledge_for_plan(plan, top_k=10)
        
        with st.spinner(f"ğŸ¤– LLMãŒ{plan['matrix_size'][0]}Ã—{plan['matrix_size'][1]}è¡Œåˆ—ã‚’è©•ä¾¡ä¸­..."):
            st.caption(f"å‚è€ƒè©•ä¾¡: {len(knowledge)}ä»¶")
            
            if knowledge:
                with st.expander("å‚è€ƒã«ã—ãŸè©•ä¾¡", expanded=False):
                    for k in knowledge:
                        sign = "+" if k["score"] > 0 else ""
                        st.caption(f"{k['from_node']} â†’ {k['to_node']}: {sign}{k['score']}")
            
            llm_client = LLMClient()
            
            matrix = llm_client.evaluate_matrix_with_knowledge(
                from_category=from_category,
                to_category=to_category,
                from_nodes=from_nodes,
                to_nodes=to_nodes,
                idef0_from=idef0_from,
                idef0_to=idef0_to,
                process_name=process_name,
                knowledge=knowledge,
                distance=distance,
                categories=evaluator.categories
            )
        
        # è¡Œåˆ—å½¢å¼ã§ä¸€æ‹¬ä¿å­˜ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡å‘ä¸Šï¼‰
        SessionManager.save_evaluation_matrix(
            from_nodes=from_nodes,
            to_nodes=to_nodes,
            matrix=matrix,
            from_category=from_category,
            to_category=to_category
        )
        
        # evaluatorã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ›´æ–°ï¼ˆéã‚¼ãƒ­ã®ã¿ï¼‰
        for i, from_node in enumerate(from_nodes):
            for j, to_node in enumerate(to_nodes):
                score = matrix[i][j]
                if score != 0:  # éã‚¼ãƒ­ã®ã¿ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
                    evaluator.add_evaluation_result(from_node, to_node, score)
        
        st.session_state.completed_plans.add(plan_idx)
        
        non_zero_count = sum(1 for row in matrix for val in row if val != 0)
        total_count = len(from_nodes) * len(to_nodes)
        
        st.success(
            f"âœ… è©•ä¾¡å®Œäº†ï¼éã‚¼ãƒ­: {non_zero_count}/{total_count}ãƒšã‚¢ "
            f"({100 * non_zero_count / total_count:.1f}%)"
        )
        
    except Exception as e:
        st.error(f"âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
def tab5_matrix_analysis():
    """ã‚¿ãƒ–5: è¡Œåˆ—åˆ†æã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–"""
    import pandas as pd
    import numpy as np
    import seaborn as sns
    import matplotlib.pyplot as plt
    
    st.header("ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: éš£æ¥è¡Œåˆ—ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    
    nodes = SessionManager.get_nodes()
    evaluations = SessionManager.get_evaluations()
    
    if not nodes or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–3ã§ãƒãƒ¼ãƒ‰ã‚’2ã¤ä»¥ä¸Šå®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    if not evaluations:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–4ã§ãƒãƒ¼ãƒ‰é–“ã®è©•ä¾¡ã‚’å®Œäº†ã—ã¦ãã ã•ã„")
        st.info("""
        **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:**
        1. ã‚¿ãƒ–4ã§è©•ä¾¡ãƒšã‚¢ã‚’ç”Ÿæˆ
        2. å„ãƒšã‚¢ã‚’LLMã§è©•ä¾¡
        3. ã“ã®ã‚¿ãƒ–ã§è¡Œåˆ—ã‚’ç”Ÿæˆãƒ»å¯è¦–åŒ–
        """)
        return
    
    st.markdown("""
    è©•ä¾¡çµæœã‚’éš£æ¥è¡Œåˆ—ã«å¤‰æ›ã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–ã—ã¾ã™ã€‚
    
    - **è¡Œ**: è©•ä¾¡å…ƒãƒãƒ¼ãƒ‰ï¼ˆFromï¼‰
    - **åˆ—**: è©•ä¾¡å…ˆãƒãƒ¼ãƒ‰ï¼ˆToï¼‰
    - **ã‚»ãƒ«å€¤**: å½±éŸ¿ã‚¹ã‚³ã‚¢ï¼ˆ-9ï½+9ï¼‰
    """)
    
    st.subheader("ğŸ“Š éš£æ¥è¡Œåˆ—ã®ç”Ÿæˆ")
    
    if st.button("ğŸ”„ è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦å¯è¦–åŒ–", type="primary", use_container_width=True):
        try:
            df_evals = pd.DataFrame(evaluations)
            
            pivot_matrix = df_evals.pivot_table(
                index='from_node',
                columns='to_node',
                values='score',
                fill_value=0
            )
            
            adj_matrix_df = pivot_matrix.reindex(
                index=nodes,
                columns=nodes,
                fill_value=0
            )
            
            adj_matrix_np = adj_matrix_df.values
            
            SessionManager.set_adjacency_matrix(adj_matrix_np)
            
            st.session_state.adj_matrix_df = adj_matrix_df
            
            st.success(f"âœ… {len(nodes)}Ã—{len(nodes)}ã®éš£æ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            st.info("ğŸ’¡ ä¸‹ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒƒãƒ—6ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
            
        except Exception as e:
            st.error(f"âŒ è¡Œåˆ—ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("è©³ç´°ã‚’è¡¨ç¤º"):
                st.exception(e)
    
    if "adj_matrix_df" in st.session_state and st.session_state.adj_matrix_df is not None:
        adj_matrix_df = st.session_state.adj_matrix_df
        
        st.divider()
        st.subheader("ğŸ¨ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–")
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæ–‡å­—åŒ–ã‘é˜²æ­¢ï¼‰
        import japanize_matplotlib
        japanize_matplotlib.japanize()
        
        fig, ax = plt.subplots(figsize=(12, 10))
        
        sns.heatmap(
            adj_matrix_df,
            annot=True,
            fmt='.0f',
            cmap='coolwarm',
            center=0,
            vmin=-9,
            vmax=9,
            linewidths=0.5,
            cbar_kws={'label': 'Influence Score'},
            ax=ax
        )
        
        ax.set_title('Node Influence Heatmap', fontsize=16, pad=20)
        ax.set_xlabel('To Node', fontsize=12)
        ax.set_ylabel('From Node', fontsize=12)
        
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        st.pyplot(fig)
        plt.close()
        
        # adjacency_matrixã‚’numpyé…åˆ—ã¨ã—ã¦ã‚‚ä¿å­˜ï¼ˆã‚¹ãƒ†ãƒƒãƒ—6ã§ä½¿ç”¨ï¼‰
        st.session_state.adjacency_matrix = adj_matrix_df.values
        
        st.divider()
        st.subheader("ğŸ“‹ éš£æ¥è¡Œåˆ—ãƒ‡ãƒ¼ã‚¿")
        
        st.dataframe(
            adj_matrix_df,
            use_container_width=True,
            height=400
        )
        
        non_zero_count = np.count_nonzero(adj_matrix_df.values)
        total_count = adj_matrix_df.shape[0] * adj_matrix_df.shape[1]
        density = non_zero_count / total_count if total_count > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("éã‚¼ãƒ­è¦ç´ æ•°", non_zero_count)
        with col2:
            st.metric("ç·è¦ç´ æ•°", total_count)
        with col3:
            st.metric("è¡Œåˆ—å¯†åº¦", f"{density:.2%}")
        
        st.divider()
        st.subheader("ğŸ” ç²’åº¦èª¿æ•´ã®ææ¡ˆ")
        
        st.markdown("""
        **åå¾©çš„çŸ¥è­˜ç²¾ç·»åŒ–ãƒ—ãƒ­ã‚»ã‚¹**
        
        ä»¥ä¸‹ã®ãƒãƒ¼ãƒ‰ã¯å¤šãã®ãƒãƒ¼ãƒ‰ã¨é–¢ä¿‚ã—ã¦ã„ã‚‹ãŸã‚ã€ç²’åº¦ãŒç²—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        Zigzaggingæ‰‹æ³•ã§ç´°åˆ†åŒ–ã™ã‚‹ã“ã¨ã§ã€çŸ¥è­˜ã®è§£åƒåº¦ã‚’å‘ä¸Šã§ãã¾ã™ã€‚
        """)
        
        in_degrees = adj_matrix_df.sum(axis=0)
        out_degrees = adj_matrix_df.sum(axis=1)
        total_degrees = in_degrees + out_degrees
        
        degree_df = pd.DataFrame({
            'ãƒãƒ¼ãƒ‰å': nodes,
            'å…¥æ¬¡æ•°ï¼ˆå—ã‘ã‚‹å½±éŸ¿ã®åˆè¨ˆï¼‰': in_degrees.values,
            'å‡ºæ¬¡æ•°ï¼ˆä¸ãˆã‚‹å½±éŸ¿ã®åˆè¨ˆï¼‰': out_degrees.values,
            'ç·æ¬¡æ•°': total_degrees.values
        })
        
        degree_df = degree_df.sort_values('ç·æ¬¡æ•°', ascending=False, key=lambda x: abs(x))
        
        top_5 = degree_df.head(5)
        
        st.markdown("### ğŸ“Š ç²’åº¦ãŒç²—ã„å¯èƒ½æ€§ã®ã‚ã‚‹ãƒãƒ¼ãƒ‰ï¼ˆãƒˆãƒƒãƒ—5ï¼‰")
        
        for idx, row in top_5.iterrows():
            node_name = row['ãƒãƒ¼ãƒ‰å']
            total_deg = row['ç·æ¬¡æ•°']
            in_deg = row['å…¥æ¬¡æ•°ï¼ˆå—ã‘ã‚‹å½±éŸ¿ã®åˆè¨ˆï¼‰']
            out_deg = row['å‡ºæ¬¡æ•°ï¼ˆä¸ãˆã‚‹å½±éŸ¿ã®åˆè¨ˆï¼‰']
            
            with st.container(border=True):
                col_info, col_btn = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"**{node_name}**")
                    st.caption(f"ç·æ¬¡æ•°: {total_deg:.1f} (å…¥: {in_deg:.1f}, å‡º: {out_deg:.1f})")
                    
                    if abs(total_deg) > 10:
                        st.warning("âš ï¸ éå¸¸ã«å¤šãã®ãƒãƒ¼ãƒ‰ã¨é–¢ä¿‚ â†’ ç²’åº¦ãŒç²—ã„å¯èƒ½æ€§ãŒé«˜ã„")
                    elif abs(total_deg) > 5:
                        st.info("ğŸ’¡ è¤‡æ•°ã®ãƒãƒ¼ãƒ‰ã¨é–¢ä¿‚ â†’ ç´°åˆ†åŒ–ã‚’æ¤œè¨")
                
                with col_btn:
                    if st.button("ğŸ”„ ç´°åˆ†åŒ–", key=f"refine_{node_name}", use_container_width=True):
                        st.session_state.selected_refinement_node = node_name
                        st.info(f"ğŸ’¡ ã€Œã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ¼ãƒ‰å®šç¾©ã€ã‚¿ãƒ–ã«ç§»å‹•ã—ã¦ã€ã€Œ{node_name}ã€ã‚’å«ã‚€ã‚«ãƒ†ã‚´ãƒªã‚’ç´°åˆ†åŒ–ã—ã¦ãã ã•ã„")
                        st.info("ã‚¿ãƒ–3ã§ã€ŒZigzaggingç²’åº¦èª¿æ•´ã€ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    else:
        st.info("ğŸ‘† ã€Œè¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦å¯è¦–åŒ–ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹å§‹ã—ã¦ãã ã•ã„")


def tab6_network_visualization():
    """ã‚¿ãƒ–6: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼ˆ3D/2Dï¼‰"""
    st.header("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—6: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–")
    
    nodes = SessionManager.get_nodes()
    
    if not nodes or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–3ã§ãƒãƒ¼ãƒ‰ã‚’2ã¤ä»¥ä¸Šå®šç¾©ã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    3D/2Dç©ºé–“ã§ãƒãƒ¼ãƒ‰é–“ã®é–¢ä¿‚æ€§ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
    """)
    
    # éš£æ¥è¡Œåˆ—ã®ç¢ºèªï¼ˆã‚¹ãƒ†ãƒƒãƒ—5ã§ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    if "adjacency_matrix" not in st.session_state or st.session_state.adjacency_matrix is None:
        if "adj_matrix_df" in st.session_state and st.session_state.adj_matrix_df is not None:
            # DataFrameã‹ã‚‰å¤‰æ›
            st.session_state.adjacency_matrix = st.session_state.adj_matrix_df.values
            st.info("âœ… ã‚¹ãƒ†ãƒƒãƒ—5ã§ç”Ÿæˆã•ã‚ŒãŸéš£æ¥è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚")
        else:
            # ãƒ‡ãƒ¢ç”¨ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿
            n = len(nodes)
            demo_matrix = np.random.randint(-5, 6, size=(n, n))
            np.fill_diagonal(demo_matrix, 0)
            st.session_state.adjacency_matrix = demo_matrix
            st.warning("âš ï¸ ãƒ‡ãƒ¢ç”¨ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚ã‚¿ãƒ–4ã§è©•ä¾¡ã‚’å®Ÿè¡Œã—ã€ã‚¿ãƒ–5ã§éš£æ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success("âœ… ã‚¹ãƒ†ãƒƒãƒ—5ã§ç”Ÿæˆã•ã‚ŒãŸéš£æ¥è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚")
    
    viz_tab1, viz_tab2 = st.tabs(["ğŸ® 3Då¯è¦–åŒ–", "ğŸ“Š 2Då¯è¦–åŒ–"])
    
    with viz_tab1:
        st.info("ğŸ’¡ 3Dç©ºé–“ã§ãƒãƒ¼ãƒ‰é–“ã®é–¢ä¿‚æ€§ã‚’å¯è¦–åŒ–ã—ã¾ã™ï¼ˆè¦: éš£æ¥è¡Œåˆ—ãƒ‡ãƒ¼ã‚¿ï¼‰")
        
        if st.session_state.adjacency_matrix is not None:
            from utils.networkmaps_bridge import convert_pim_to_networkmaps
            from components.networkmaps_viewer import networkmaps_3d_viewer
            
            col_viewer, col_controls = st.columns([3, 1])
            
            with col_controls:
                st.subheader("è¡¨ç¤ºè¨­å®š")
                
                scale = st.slider(
                    "ç©ºé–“ã®ã‚¹ã‚±ãƒ¼ãƒ«",
                    min_value=5.0,
                    max_value=20.0,
                    value=10.0,
                    step=1.0,
                    help="ãƒãƒ¼ãƒ‰é–“ã®è·é›¢ã‚’èª¿æ•´ã—ã¾ã™"
                )
                
                camera_mode = st.radio(
                    "ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰",
                    options=["3d", "2d"],
                    format_func=lambda x: "3Dè¦–ç‚¹" if x == "3d" else "2Dä¿¯ç°",
                    help="è¦–ç‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™"
                )
                
                st.divider()
                st.caption("ğŸ’¡ æ“ä½œæ–¹æ³•")
                st.markdown("""
                **ãƒã‚¦ã‚¹æ“ä½œ:**
                - ğŸ–±ï¸ å·¦ãƒ‰ãƒ©ãƒƒã‚°: å›è»¢
                - ğŸ–±ï¸ ãƒ›ã‚¤ãƒ¼ãƒ«: ã‚ºãƒ¼ãƒ 
                - ğŸ–±ï¸ å³ãƒ‰ãƒ©ãƒƒã‚°: ãƒ‘ãƒ³
                - ğŸ–±ï¸ ã‚¯ãƒªãƒƒã‚¯: ãƒãƒ¼ãƒ‰é¸æŠ
                """)
        
            with col_viewer:
                try:
                    diagram_data = convert_pim_to_networkmaps(
                        nodes=nodes,
                        adjacency_matrix=st.session_state.adjacency_matrix,
                        categories=SessionManager.get_functional_categories(),
                        idef0_data=SessionManager.get_all_idef0_nodes(),
                        evaluations=st.session_state.get('evaluations', []),
                        scale=scale
                    )
                    
                    selected_node = networkmaps_3d_viewer(
                        diagram_data=diagram_data,
                        height=700,
                        enable_interaction=True,
                        camera_mode=camera_mode,
                        key="pim_network_3d_viewer"
                    )
                    
                    if selected_node:
                        st.success(f"**é¸æŠãƒãƒ¼ãƒ‰:** {selected_node['node_name']}")
                        
                        st.markdown("### ğŸ” è©³ç´°æƒ…å ±")
                        with st.container():
                            node_idx = nodes.index(selected_node['node_name'])
                            
                            st.markdown("**ã“ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®å½±éŸ¿:**")
                            outgoing = []
                            for j, target in enumerate(nodes):
                                score = st.session_state.adjacency_matrix[node_idx, j]
                                if score != 0:
                                    outgoing.append(f"â†’ {target}: **{score:+.1f}**")
                            
                            if outgoing:
                                for item in outgoing:
                                    st.markdown(item)
                            else:
                                st.caption("å½±éŸ¿ãªã—")
                            
                            st.divider()
                            
                            st.markdown("**ã“ã®ãƒãƒ¼ãƒ‰ã¸ã®å½±éŸ¿:**")
                            incoming = []
                            for i, source in enumerate(nodes):
                                score = st.session_state.adjacency_matrix[i, node_idx]
                                if score != 0:
                                    incoming.append(f"{source} â†’: **{score:+.1f}**")
                            
                            if incoming:
                                for item in incoming:
                                    st.markdown(item)
                            else:
                                st.caption("å½±éŸ¿ãªã—")
                
                except Exception as e:
                    st.error(f"3Då¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.caption("**ã‚¨ãƒ©ãƒ¼è©³ç´°:**")
                    st.code(str(e), language="python")
    
    with viz_tab2:
        st.info("ğŸ’¡ 2Dã‚°ãƒ©ãƒ•ã§ãƒãƒ¼ãƒ‰é–“ã®é–¢ä¿‚æ€§ã‚’å¯è¦–åŒ–ã—ã¾ã™ï¼ˆCytoscape.jsï¼‰")
        
        if st.session_state.adjacency_matrix is not None:
            from utils.cytoscape_bridge import convert_pim_to_cytoscape
            from components.cytoscape_viewer import cytoscape_2d_viewer
            
            col_viewer2d, col_controls2d = st.columns([3, 1])
            
            with col_controls2d:
                st.subheader("è¡¨ç¤ºè¨­å®š")
                
                threshold = st.slider(
                    "ã‚¹ã‚³ã‚¢é–¾å€¤",
                    min_value=0.0,
                    max_value=9.0,
                    value=2.0,
                    step=0.5,
                    help="ã“ã®å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤ã‚¨ãƒƒã‚¸ã®ã¿è¡¨ç¤º"
                )
                
                layout = st.selectbox(
                    "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ",
                    options=["hierarchical", "cose", "breadthfirst", "circle", "grid"],
                    format_func=lambda x: {
                        "hierarchical": "éšå±¤çš„ï¼ˆ3Dæ§‹é€ æº–æ‹ ï¼‰",
                        "cose": "åŠ›å­¦ãƒ¢ãƒ‡ãƒ«",
                        "breadthfirst": "éšå±¤çš„ï¼ˆè‡ªå‹•ï¼‰",
                        "circle": "å††å½¢",
                        "grid": "ã‚°ãƒªãƒƒãƒ‰"
                    }[x],
                    help="ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ "
                )
                
                st.divider()
                st.caption("ğŸ’¡ æ“ä½œæ–¹æ³•")
                st.markdown("""
                **ãƒã‚¦ã‚¹æ“ä½œ:**
                - ğŸ–±ï¸ ãƒ‰ãƒ©ãƒƒã‚°: ãƒ‘ãƒ³
                - ğŸ–±ï¸ ãƒ›ã‚¤ãƒ¼ãƒ«: ã‚ºãƒ¼ãƒ 
                - ğŸ–±ï¸ ã‚¯ãƒªãƒƒã‚¯: ãƒãƒ¼ãƒ‰é¸æŠ
                
                **è‰²ã®æ„å‘³:**
                - ğŸŸ¢ Outputï¼ˆæˆæœç‰©ï¼‰
                - ğŸ”µ Mechanismï¼ˆæ‰‹æ®µï¼‰
                - ğŸŸ  Inputï¼ˆææ–™ãƒ»æƒ…å ±ï¼‰
                """)
            
            with col_viewer2d:
                try:
                    cyto_data = convert_pim_to_cytoscape(
                        nodes=nodes,
                        adjacency_matrix=st.session_state.adjacency_matrix,
                        categories=SessionManager.get_functional_categories(),
                        idef0_data=SessionManager.get_all_idef0_nodes(),
                        threshold=threshold,
                        use_hierarchical_layout=(layout == "hierarchical")
                    )
                    
                    selected_node_2d = cytoscape_2d_viewer(
                        graph_data=cyto_data,
                        layout=layout,
                        height=700,
                        threshold=threshold,
                        key="pim_cytoscape_2d"
                    )
                    
                    if selected_node_2d:
                        st.success(f"**é¸æŠãƒãƒ¼ãƒ‰:** {selected_node_2d['node_name']}")
                
                except Exception as e:
                    st.error(f"2Då¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.caption("**ã‚¨ãƒ©ãƒ¼è©³ç´°:**")
                    st.code(str(e), language="python")


def tab7_network_analysis():
    """ã‚¿ãƒ–7: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æï¼ˆã‚¹ãƒ†ãƒƒãƒ—7ï¼‰"""
    st.header("ğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—7: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ")
    
    adj_matrix_df = st.session_state.get("adj_matrix_df")
    nodes = SessionManager.get_nodes()
    
    if adj_matrix_df is None or nodes is None or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–5ã§éš£æ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã«ã‚ˆã‚Šã€é‡è¦ãªãƒãƒ¼ãƒ‰ã‚’ç‰¹å®šã—ã¾ã™ã€‚
    - **PageRank**: å„ãƒãƒ¼ãƒ‰ã®å½±éŸ¿åŠ›ã‚¹ã‚³ã‚¢
    - **å…¥æ¬¡æ•°ä¸­å¿ƒæ€§**: ä»–ãƒãƒ¼ãƒ‰ã‹ã‚‰å½±éŸ¿ã‚’å—ã‘ã‚‹åº¦åˆã„
    - **å‡ºæ¬¡æ•°ä¸­å¿ƒæ€§**: ä»–ãƒãƒ¼ãƒ‰ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹åº¦åˆã„
    - **åª’ä»‹ä¸­å¿ƒæ€§**: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ãƒãƒ¼ãƒ‰ã‚’æ¤œå‡º
    """)
    
    if st.button("ğŸ”¬ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆã—ã¦åˆ†æ", type="primary", use_container_width=True):
        with st.spinner("ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆãƒ»åˆ†æä¸­..."):
            try:
                import networkx as nx
                
                # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
                adj_matrix = adj_matrix_df.values
                G = nx.from_numpy_array(adj_matrix, create_using=nx.DiGraph)
                
                # ãƒãƒ¼ãƒ‰åã§ãƒªãƒ©ãƒ™ãƒ«
                node_mapping = {i: nodes[i] for i in range(len(nodes))}
                G = nx.relabel_nodes(G, node_mapping)
                
                # åˆ†æçµæœã‚’ä¿å­˜
                st.session_state.network_graph = G
                
                st.success("âœ… ã‚°ãƒ©ãƒ•ã®ç”Ÿæˆã¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.code(str(e), language="python")
                return
    
    # ã‚°ãƒ©ãƒ•ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çµæœã‚’è¡¨ç¤º
    if "network_graph" in st.session_state and st.session_state.network_graph is not None:
        import networkx as nx
        import matplotlib.pyplot as plt
        
        G = st.session_state.network_graph
        
        # 7.1 ã‚°ãƒ©ãƒ•å¯è¦–åŒ–
        st.markdown("---")
        st.subheader("7.1. ã‚°ãƒ©ãƒ•å¯è¦–åŒ–")
        
        col_viz, col_layout = st.columns([3, 1])
        
        with col_layout:
            layout_type = st.selectbox(
                "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ",
                options=["spring", "circular", "kamada_kawai", "shell"],
                format_func=lambda x: {
                    "spring": "Springï¼ˆåŠ›å­¦ãƒ¢ãƒ‡ãƒ«ï¼‰",
                    "circular": "Circularï¼ˆå††å½¢ï¼‰",
                    "kamada_kawai": "Kamada-Kawaiï¼ˆåŠ›å­¦æœ€é©åŒ–ï¼‰",
                    "shell": "Shellï¼ˆåŒå¿ƒå††ï¼‰"
                }[x]
            )
            
            node_size = st.slider("ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º", 100, 3000, 1500)
            font_size = st.slider("ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º", 6, 16, 10)
        
        with col_viz:
            fig, ax = plt.subplots(figsize=(12, 10))
            
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
            if layout_type == "spring":
                pos = nx.spring_layout(G, k=1, iterations=50)
            elif layout_type == "circular":
                pos = nx.circular_layout(G)
            elif layout_type == "kamada_kawai":
                pos = nx.kamada_kawai_layout(G)
            else:
                pos = nx.shell_layout(G)
            
            # ã‚¨ãƒƒã‚¸ã®å¤ªã•ã¨è‰²ã‚’ã‚¹ã‚³ã‚¢ã‹ã‚‰è¨ˆç®—
            edges = G.edges()
            edge_weights = [G[u][v]['weight'] for u, v in edges]
            edge_colors = ['red' if w < 0 else 'blue' for w in edge_weights]
            edge_widths = [abs(w) * 0.3 for w in edge_weights]
            
            # æç”»
            nx.draw_networkx_nodes(G, pos, node_color='lightblue', 
                                  node_size=node_size, alpha=0.9, ax=ax)
            nx.draw_networkx_labels(G, pos, font_size=font_size, 
                                   font_family='sans-serif', ax=ax)
            nx.draw_networkx_edges(G, pos, edge_color=edge_colors, 
                                  width=edge_widths, alpha=0.6, 
                                  arrows=True, arrowsize=20, ax=ax)
            
            ax.set_title("ãƒãƒ¼ãƒ‰é–¢ä¿‚ã‚°ãƒ©ãƒ•", fontsize=14, pad=20)
            ax.axis('off')
            
            st.pyplot(fig)
            plt.close()
        
        # 7.2 ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ
        st.markdown("---")
        st.subheader("7.2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æçµæœ")
        
        # PageRankè¨ˆç®—
        try:
            pagerank = nx.pagerank(G, weight='weight')
        except:
            pagerank = nx.pagerank(G)
        
        # æ¬¡æ•°ä¸­å¿ƒæ€§
        in_degree = dict(G.in_degree(weight='weight'))
        out_degree = dict(G.out_degree(weight='weight'))
        
        # åª’ä»‹ä¸­å¿ƒæ€§
        try:
            betweenness = nx.betweenness_centrality(G, weight='weight')
        except:
            betweenness = nx.betweenness_centrality(G)
        
        # DataFrameã«ã¾ã¨ã‚ã‚‹
        analysis_data = []
        for node in nodes:
            analysis_data.append({
                'ãƒãƒ¼ãƒ‰å': node,
                'PageRank': pagerank.get(node, 0),
                'å…¥æ¬¡æ•°': in_degree.get(node, 0),
                'å‡ºæ¬¡æ•°': out_degree.get(node, 0),
                'åª’ä»‹ä¸­å¿ƒæ€§': betweenness.get(node, 0)
            })
        
        df_analysis = pd.DataFrame(analysis_data)
        
        # ã‚½ãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        sort_by = st.selectbox(
            "ä¸¦ã³æ›¿ãˆåŸºæº–",
            options=['PageRank', 'å…¥æ¬¡æ•°', 'å‡ºæ¬¡æ•°', 'åª’ä»‹ä¸­å¿ƒæ€§'],
            index=0
        )
        
        df_sorted = df_analysis.sort_values(by=sort_by, ascending=False)
        
        st.dataframe(
            df_sorted,
            use_container_width=True,
            hide_index=True
        )
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        col_s1, col_s2, col_s3, col_s4 = st.columns(4)
        with col_s1:
            st.metric("ç·ãƒãƒ¼ãƒ‰æ•°", len(nodes))
        with col_s2:
            st.metric("ç·ã‚¨ãƒƒã‚¸æ•°", G.number_of_edges())
        with col_s3:
            avg_pagerank = sum(pagerank.values()) / len(pagerank)
            st.metric("å¹³å‡PageRank", f"{avg_pagerank:.4f}")
        with col_s4:
            avg_betweenness = sum(betweenness.values()) / len(betweenness)
            st.metric("å¹³å‡åª’ä»‹ä¸­å¿ƒæ€§", f"{avg_betweenness:.4f}")
        
        # 7.3 ç²’åº¦èª¿æ•´ææ¡ˆ
        st.markdown("---")
        st.subheader("7.3. ç²’åº¦èª¿æ•´ææ¡ˆ")
        
        st.markdown("""
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã®çµæœã‹ã‚‰ã€ç´°åˆ†åŒ–ã‚’æ¤œè¨ã™ã¹ããƒãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¾ã™ï¼š
        - **PageRankä¸Šä½**: å½±éŸ¿åŠ›ãŒå¤§ãã„ãƒãƒ¼ãƒ‰ â†’ è©³ç´°ãªåˆ†æä¾¡å€¤ãŒé«˜ã„
        - **åª’ä»‹ä¸­å¿ƒæ€§ä¸Šä½**: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ãƒãƒ¼ãƒ‰ â†’ ç´°åˆ†åŒ–ã§æœ€é©åŒ–ã®ä½™åœ°
        """)
        
        # PageRankä¸Šä½5ãƒãƒ¼ãƒ‰
        top_pagerank = df_analysis.nlargest(5, 'PageRank')
        
        st.markdown("#### ğŸ“ˆ PageRankä¸Šä½ãƒãƒ¼ãƒ‰ï¼ˆé‡è¦ãƒãƒ¼ãƒ‰ï¼‰")
        
        for idx, row in top_pagerank.iterrows():
            node_name = row['ãƒãƒ¼ãƒ‰å']
            pr_score = row['PageRank']
            
            with st.container(border=True):
                col_info, col_btn = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"**{node_name}**")
                    st.caption(f"PageRank: {pr_score:.4f}")
                    
                    if pr_score > avg_pagerank * 2:
                        st.warning("âš ï¸ å¹³å‡ã®2å€ä»¥ä¸Šã®å½±éŸ¿åŠ› â†’ é‡è¦ãƒãƒ¼ãƒ‰ã€ç´°åˆ†åŒ–ã®ä¾¡å€¤ãŒé«˜ã„")
                    elif pr_score > avg_pagerank * 1.5:
                        st.info("ğŸ’¡ å¹³å‡ä»¥ä¸Šã®å½±éŸ¿åŠ› â†’ ç´°åˆ†åŒ–ã‚’æ¤œè¨")
                
                with col_btn:
                    if st.button("ğŸ”„ ç´°åˆ†åŒ–", key=f"refine_pr_{node_name}", use_container_width=True):
                        st.session_state.selected_refinement_node = node_name
                        st.info(f"ğŸ’¡ ã€Œã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ¼ãƒ‰å®šç¾©ã€ã‚¿ãƒ–ã«ç§»å‹•ã—ã¦ã€ã€Œ{node_name}ã€ã‚’å«ã‚€ã‚«ãƒ†ã‚´ãƒªã‚’ç´°åˆ†åŒ–ã—ã¦ãã ã•ã„")
                        st.info("ã‚¿ãƒ–3ã§ã€ŒZigzaggingç²’åº¦èª¿æ•´ã€ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        # åª’ä»‹ä¸­å¿ƒæ€§ä¸Šä½5ãƒãƒ¼ãƒ‰
        st.markdown("#### ğŸ”— åª’ä»‹ä¸­å¿ƒæ€§ä¸Šä½ãƒãƒ¼ãƒ‰ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰")
        
        top_betweenness = df_analysis.nlargest(5, 'åª’ä»‹ä¸­å¿ƒæ€§')
        
        for idx, row in top_betweenness.iterrows():
            node_name = row['ãƒãƒ¼ãƒ‰å']
            btw_score = row['åª’ä»‹ä¸­å¿ƒæ€§']
            
            with st.container(border=True):
                col_info, col_btn = st.columns([3, 1])
                
                with col_info:
                    st.markdown(f"**{node_name}**")
                    st.caption(f"åª’ä»‹ä¸­å¿ƒæ€§: {btw_score:.4f}")
                    
                    if btw_score > avg_betweenness * 2:
                        st.warning("âš ï¸ å¹³å‡ã®2å€ä»¥ä¸Š â†’ ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€æœ€é©åŒ–ã®ä½™åœ°ã‚ã‚Š")
                    elif btw_score > avg_betweenness * 1.5:
                        st.info("ğŸ’¡ å¹³å‡ä»¥ä¸Š â†’ ç´°åˆ†åŒ–ã‚’æ¤œè¨")
                
                with col_btn:
                    if st.button("ğŸ”„ ç´°åˆ†åŒ–", key=f"refine_btw_{node_name}", use_container_width=True):
                        st.session_state.selected_refinement_node = node_name
                        st.info(f"ğŸ’¡ ã€Œã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ¼ãƒ‰å®šç¾©ã€ã‚¿ãƒ–ã«ç§»å‹•ã—ã¦ã€ã€Œ{node_name}ã€ã‚’å«ã‚€ã‚«ãƒ†ã‚´ãƒªã‚’ç´°åˆ†åŒ–ã—ã¦ãã ã•ã„")
                        st.info("ã‚¿ãƒ–3ã§ã€ŒZigzaggingç²’åº¦èª¿æ•´ã€ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    else:
        st.info("ğŸ‘† ã€Œãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆã—ã¦åˆ†æã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹å§‹ã—ã¦ãã ã•ã„")


def tab8_dsm_optimization():
    """ã‚¿ãƒ–8: DSMæœ€é©åŒ–ï¼ˆNSGA-IIï¼‰"""
    st.header("ğŸ® ã‚¹ãƒ†ãƒƒãƒ—8: DSMæœ€é©åŒ–ï¼ˆNSGA-IIï¼‰")
    
    adj_matrix_df = st.session_state.get("adj_matrix_df")
    nodes = SessionManager.get_nodes()
    all_idef0 = SessionManager.get_all_idef0_nodes()
    
    if adj_matrix_df is None or nodes is None or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–5ã§éš£æ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    è¨­è¨ˆæ§‹é€ ãƒãƒˆãƒªã‚¯ã‚¹ï¼ˆDSMï¼‰ã®å¤šç›®çš„æœ€é©åŒ–ã‚’è¡Œã„ã¾ã™ã€‚
    
    **STEP-1**: è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠï¼ˆã‚³ã‚¹ãƒˆ vs è‡ªç”±åº¦ï¼‰  
    **STEP-2**: ä¾å­˜é–¢ä¿‚æ–¹å‘æ±ºå®šï¼ˆèª¿æ•´å›°é›£åº¦ vs ç«¶åˆå›°é›£åº¦ vs ãƒ«ãƒ¼ãƒ—å›°é›£åº¦ï¼‰
    """)
    
    # 8.1 DSMè¨­å®š
    st.markdown("---")
    st.subheader("8.1. DSMè¨­å®š")
    
    from utils.idef0_classifier import classify_node_type, NodeType
    
    # FR/DPåˆ†é¡
    fr_nodes = []
    dp_nodes = []
    for node_name in nodes:
        node_type, _ = classify_node_type(node_name, all_idef0)
        if node_type == NodeType.OUTPUT:
            fr_nodes.append(node_name)
        else:
            dp_nodes.append(node_name)
    
    col_fr, col_dp = st.columns(2)
    with col_fr:
        st.metric("FRï¼ˆæ©Ÿèƒ½è¦æ±‚ï¼‰", len(fr_nodes), help="Outputãƒãƒ¼ãƒ‰")
    with col_dp:
        st.metric("DPï¼ˆè¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰", len(dp_nodes), help="Mechanism + Inputãƒãƒ¼ãƒ‰")
    
    st.info("""
    ğŸ’¡ **FR/DPåˆ†é¡ã«ã¤ã„ã¦**
    - **FRï¼ˆæ©Ÿèƒ½è¦æ±‚ï¼‰**: ãƒ—ãƒ­ã‚»ã‚¹ã®æˆæœç‰©ï¼ˆOutputï¼‰
    - **DPï¼ˆè¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰**: æˆæœç‰©ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ®µã¨ææ–™ï¼ˆMechanism + Inputï¼‰
    """)
    
    param_mode = st.radio(
        "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šæ–¹æ³•",
        options=["llm_auto", "fixed_default", "manual_custom"],
        format_func=lambda x: {
            "llm_auto": "ğŸ¤– LLMã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼ˆæ¨å¥¨ï¼‰",
            "fixed_default": "ğŸ“Š å›ºå®šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤",
            "manual_custom": "âš™ï¸ æ‰‹å‹•ã‚«ã‚¹ã‚¿ãƒ è¨­å®šï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰"
        }[x],
        index=0,
        help="LLMè‡ªå‹•è©•ä¾¡: ãƒ—ãƒ­ã‚»ã‚¹ã®æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©•ä¾¡ | å›ºå®šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Cost=1, Range=1, Importance=1"
    )
    
    # LLMè©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
    if param_mode == "llm_auto":
        st.markdown("""
        **LLMãŒè©•ä¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
        - **Costï¼ˆã‚³ã‚¹ãƒˆï¼‰**: 1-5ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆDPã®ã¿ï¼‰
        - **Rangeï¼ˆå¤‰å‹•ç¯„å›²ï¼‰**: 0.1-2.0ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆDPã®ã¿ï¼‰
        - **Importanceï¼ˆé‡è¦åº¦ï¼‰**: 1-5ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆFRã®ã¿ï¼‰
        - **Structureï¼ˆæ§‹é€ ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰**: è«–ç†çš„ãªã‚°ãƒ«ãƒ¼ãƒ—å
        """)
        
        if st.button("ğŸ¤– ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’LLMã§è©•ä¾¡", type="primary", use_container_width=True):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                from core.llm_client import LLMClient
                
                llm_client = LLMClient()
                
                # ãƒãƒ¼ãƒ‰åˆ†é¡ã‚’ä½œæˆ
                node_classifications = {}
                for node_name in nodes:
                    node_type, _ = classify_node_type(node_name, all_idef0)
                    if node_type == NodeType.OUTPUT:
                        node_classifications[node_name] = "FR"
                    else:
                        node_classifications[node_name] = "DP"
                
                # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                def update_progress(ratio):
                    progress_bar.progress(ratio)
                    status_text.text(f"LLMãŒè©•ä¾¡ä¸­... {int(ratio*100)}%")
                
                # LLMè©•ä¾¡ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
                result = llm_client.evaluate_dsm_parameters(
                    process_name=SessionManager.get_process_name(),
                    process_description=SessionManager.get_process_description(),
                    nodes=nodes,
                    idef0_nodes=all_idef0,
                    node_classifications=node_classifications,
                    batch_size=10,
                    progress_callback=update_progress
                )
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.dsm_llm_params = result
                
                progress_bar.empty()
                status_text.empty()
                st.success("âœ… LLMã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸ")
                
            except Exception as e:
                progress_bar.empty()
                status_text.empty()
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                import traceback
                st.code(traceback.format_exc(), language="python")
        
        # è©•ä¾¡çµæœã®è¡¨ç¤º
        if "dsm_llm_params" in st.session_state and st.session_state.dsm_llm_params:
            result = st.session_state.dsm_llm_params
            params_data = result.get("parameters", {})
            
            with st.expander("ğŸ“Š è©•ä¾¡çµæœ", expanded=True):
                # DataFrameä½œæˆ
                df_data = []
                for node_name in nodes:
                    node_params = params_data.get(node_name, {})
                    node_type, _ = classify_node_type(node_name, all_idef0)
                    
                    row = {
                        "ãƒãƒ¼ãƒ‰å": node_name,
                        "ã‚¿ã‚¤ãƒ—": "FR" if node_type == NodeType.OUTPUT else "DP"
                    }
                    
                    if node_type == NodeType.OUTPUT:
                        row["ã‚³ã‚¹ãƒˆ"] = "-"
                        row["å¤‰å‹•ç¯„å›²"] = "-"
                        row["é‡è¦åº¦"] = f"{node_params.get('importance', '-')}"
                    else:
                        row["ã‚³ã‚¹ãƒˆ"] = f"{node_params.get('cost', '-')}"
                        row["å¤‰å‹•ç¯„å›²"] = f"{node_params.get('range', '-')}"
                        row["é‡è¦åº¦"] = "-"
                    
                    row["æ§‹é€ ã‚°ãƒ«ãƒ¼ãƒ—"] = node_params.get("structure", "-")
                    df_data.append(row)
                
                df_params = pd.DataFrame(df_data)
                st.dataframe(df_params, use_container_width=True, hide_index=True)
                
                st.markdown("**è©•ä¾¡ã®æ ¹æ‹ :**")
                st.write(result.get("reasoning", "æ ¹æ‹ ãŒæä¾›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"))
    
    elif param_mode == "fixed_default":
        st.info("""
        ğŸ“Š **å›ºå®šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤**
        - Cost = 1
        - Range = 1
        - Importance = 1
        - Structure = ã‚«ãƒ†ã‚´ãƒªå
        """)
    
    else:  # manual_custom
        st.warning("âš ï¸ ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä¸Šç´šè€…å‘ã‘ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¾ãŸã¯LLMè©•ä¾¡ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    
    # 8.2 STEP-1å®Ÿè¡Œ
    st.markdown("---")
    st.subheader("8.2. STEP-1: è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠ")
    
    st.markdown("""
    ã©ã®è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã™ã¹ãã‹ã‚’æ±ºå®šã—ã¾ã™ã€‚
    - **ç›®çš„1**: ã‚³ã‚¹ãƒˆæœ€å°åŒ–ï¼ˆåŒä¸€æ§‹é€ å†…ã®æœ€å¤§ã‚³ã‚¹ãƒˆã®åˆè¨ˆï¼‰
    - **ç›®çš„2**: è¨­è¨ˆè‡ªç”±åº¦æœ€å¤§åŒ–ï¼ˆå„FRã®èª¿æ•´èƒ½åŠ›æ¯”ã®ç·å’Œï¼‰
    """)
    
    # è»½é‡ãƒ¢ãƒ¼ãƒ‰
    lightweight_mode = st.checkbox(
        "âš¡ è»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰",
        value=True,
        help="å€‹ä½“æ•°ã¨ä¸–ä»£æ•°ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’é˜²ãã¾ã™"
    )
    
    if lightweight_mode:
        default_pop, default_gen = 100, 50
    else:
        default_pop, default_gen = 200, 100
    
    col_p1, col_p2 = st.columns(2)
    with col_p1:
        step1_pop = st.slider("å€‹ä½“æ•°", 50, 500, default_pop, 50, key="step1_pop")
    with col_p2:
        step1_gen = st.slider("ä¸–ä»£æ•°", 20, 200, default_gen, 10, key="step1_gen")
    
    # ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ï¼ˆãƒœã‚¿ãƒ³ã®å¤–ã§æº–å‚™ï¼‰
    llm_params = st.session_state.get("dsm_llm_params") if param_mode == "llm_auto" else None
    
    if st.button("ğŸš€ STEP-1ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        from utils.dsm_optimizer import PIMDSMData, PIMStep1NSGA2
        import time
        
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        
        try:
            start_time = time.time()
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
            dsm_data = PIMDSMData(
                adj_matrix_df=adj_matrix_df,
                nodes=nodes,
                idef0_nodes=all_idef0,
                param_mode=param_mode,
                llm_params=llm_params,
                custom_params=None
            )
            
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            def progress_callback(gen: int, pareto_size: int):
                progress_pct = gen / step1_gen
                progress_placeholder.progress(
                    progress_pct,
                    text=f"ä¸–ä»£ {gen}/{step1_gen} (ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£: {pareto_size}å€‹)"
                )
            
            # STEP-1å®Ÿè¡Œï¼ˆåŒæœŸï¼‰
            step1 = PIMStep1NSGA2(dsm_data)
            pareto_front = step1.run(
                n_pop=step1_pop,
                n_gen=step1_gen,
                checkpoint_id=None,
                save_every=10,
                progress_callback=progress_callback
            )
            
            elapsed = time.time() - start_time
            
            # çµæœã‚’ãƒªã‚¹ãƒˆåŒ–
            step1_results = []
            for ind in pareto_front:
                cost, freedom_inv = ind.fitness.values
                removed_indices = [i for i, val in enumerate(ind) if val == 1]
                removed_nodes = [dsm_data.reordered_nodes[i] for i in removed_indices]
                step1_results.append({
                    'individual': list(ind),
                    'cost': cost,
                    'freedom_inv': freedom_inv,
                    'freedom': 1/freedom_inv if freedom_inv != float('inf') else 0,
                    'removed_count': len(removed_nodes),
                    'removed_nodes': removed_nodes
                })
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state.dsm_data = dsm_data
            st.session_state.step1_results = step1_results
            
            progress_placeholder.empty()
            status_placeholder.success(f"âœ… STEP-1å®Œäº†: {len(pareto_front)}å€‹ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£ã‚’ç™ºè¦‹ï¼ˆ{elapsed:.1f}ç§’ï¼‰")
            
        except Exception as e:
            progress_placeholder.empty()
            status_placeholder.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            st.code(traceback.format_exc(), language="python")
    
    # STEP-1çµæœã®å¯è¦–åŒ–
    if "step1_results" in st.session_state and st.session_state.step1_results:
        results = st.session_state.step1_results
        
        st.markdown("#### ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆï¼ˆ2Dï¼‰")
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æ•£å¸ƒå›³
        fig, ax = plt.subplots(figsize=(10, 6))
        costs = [r['cost'] for r in results]
        freedoms = [r['freedom'] for r in results]
        
        scatter = ax.scatter(costs, freedoms, c=range(len(results)), cmap='viridis', s=100, alpha=0.7)
        ax.set_xlabel('ã‚³ã‚¹ãƒˆï¼ˆæœ€å°åŒ–ï¼‰', fontsize=12)
        ax.set_ylabel('è¨­è¨ˆè‡ªç”±åº¦ï¼ˆæœ€å¤§åŒ–ï¼‰', fontsize=12)
        ax.set_title('STEP-1 ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ', fontsize=14)
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='è§£ç•ªå·')
        
        st.pyplot(fig)
        plt.close()
        
        # è§£é¸æŠ
        st.markdown("#### è§£ã®é¸æŠ")
        
        # DataFrameè¡¨ç¤º
        df_results = pd.DataFrame([{
            'è§£ç•ªå·': i,
            'ã‚³ã‚¹ãƒˆ': f"{r['cost']:.2f}",
            'è¨­è¨ˆè‡ªç”±åº¦': f"{r['freedom']:.4f}",
            'å‰Šé™¤DPæ•°': r['removed_count']
        } for i, r in enumerate(results)])
        
        st.dataframe(df_results, use_container_width=True, hide_index=True)
        
        selected_idx = st.selectbox(
            "STEP-2ã«ä½¿ç”¨ã™ã‚‹è§£ã‚’é¸æŠ",
            options=list(range(len(results))),
            format_func=lambda i: f"è§£{i}: ã‚³ã‚¹ãƒˆ={results[i]['cost']:.2f}, è‡ªç”±åº¦={results[i]['freedom']:.4f}"
        )
        
        if selected_idx is not None:
            selected = results[selected_idx]
            
            with st.expander(f"ğŸ“Š è§£{selected_idx}ã®è©³ç´°", expanded=True):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ã‚³ã‚¹ãƒˆ", f"{selected['cost']:.2f}")
                with col2:
                    st.metric("è¨­è¨ˆè‡ªç”±åº¦", f"{selected['freedom']:.4f}")
                with col3:
                    st.metric("å‰Šé™¤DPæ•°", selected['removed_count'])
                
                if selected['removed_nodes']:
                    st.markdown("**å‰Šé™¤ã•ã‚Œã‚‹è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**")
                    for node in selected['removed_nodes']:
                        st.caption(f"- {node}")
                else:
                    st.info("ã™ã¹ã¦ã®è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã¾ã™")
            
            # é¸æŠã‚’ä¿å­˜
            st.session_state.step1_selected_idx = selected_idx
    
    # 8.3 STEP-2å®Ÿè¡Œ
    if "step1_selected_idx" in st.session_state:
        st.markdown("---")
        st.subheader("8.3. STEP-2: ä¾å­˜é–¢ä¿‚æ–¹å‘æ±ºå®š")
        
        st.markdown("""
        æ®‹ã£ãŸè¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ä¾å­˜é–¢ä¿‚ã®æ–¹å‘ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚
        - **ç›®çš„1**: èª¿æ•´å›°é›£åº¦æœ€å°åŒ–ï¼ˆÎ±ãƒ‘ã‚¿ãƒ¼ãƒ³ + Î³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        - **ç›®çš„2**: ç«¶åˆå›°é›£åº¦æœ€å°åŒ–ï¼ˆåˆ—ã¸ã®è¤‡æ•°å½±éŸ¿ã®ç›¸ä¹—åŠ¹æœï¼‰
        - **ç›®çš„3**: ãƒ«ãƒ¼ãƒ—å›°é›£åº¦æœ€å°åŒ–ï¼ˆé–‰è·¯ã®ç´¯ç©å½±éŸ¿ï¼‰
        """)
        
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼ˆSTEP-2ï¼‰
        lightweight_mode_s2 = st.checkbox(
            "âš¡ è»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰",
            value=True,
            help="å€‹ä½“æ•°ã¨ä¸–ä»£æ•°ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’é˜²ãã¾ã™",
            key="lightweight_s2"
        )
        
        if lightweight_mode_s2:
            default_pop_s2, default_gen_s2 = 100, 30
        else:
            default_pop_s2, default_gen_s2 = 200, 50
        
        col_p3, col_p4 = st.columns(2)
        with col_p3:
            step2_pop = st.slider("å€‹ä½“æ•°", 50, 500, default_pop_s2, 50, key="step2_pop")
        with col_p4:
            step2_gen = st.slider("ä¸–ä»£æ•°", 20, 200, default_gen_s2, 10, key="step2_gen")
        
        if st.button("ğŸš€ STEP-2ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            from utils.dsm_optimizer import PIMStep2NSGA2
            import time
            
            progress_placeholder = st.empty()
            status_placeholder = st.empty()
            
            # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            status_placeholder.info(f"ğŸš€ NSGA-IIæœ€é©åŒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆ{step2_pop}å€‹ä½“ Ã— {step2_gen}ä¸–ä»£ï¼‰...")
            
            with st.spinner("æœ€é©åŒ–å®Ÿè¡Œä¸­... é€²æ—ã¯ä¸‹ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§ç¢ºèªã§ãã¾ã™"):
                try:
                    start_time = time.time()
                    gen_times = []
                    
                    dsm_data = st.session_state.dsm_data
                    selected = st.session_state.step1_results[st.session_state.step1_selected_idx]
                    removed_indices = [i for i, val in enumerate(selected['individual']) if val == 1]
                    
                    # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    def progress_callback(gen: int, pareto_size: int):
                        progress_pct = gen / step2_gen
                        
                        # æ¨å®šæ®‹ã‚Šæ™‚é–“è¨ˆç®—
                        if gen > 0:
                            elapsed = time.time() - start_time
                            avg_time_per_gen = elapsed / gen
                            remaining_gens = step2_gen - gen
                            eta_seconds = avg_time_per_gen * remaining_gens
                            eta_min = int(eta_seconds // 60)
                            eta_sec = int(eta_seconds % 60)
                            eta_text = f" | æ¨å®šæ®‹ã‚Šæ™‚é–“: {eta_min}åˆ†{eta_sec}ç§’"
                        else:
                            eta_text = ""
                        
                        progress_placeholder.progress(
                            progress_pct,
                            text=f"ä¸–ä»£ {gen}/{step2_gen} (ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£: {pareto_size}å€‹){eta_text}"
                        )
                    
                    # STEP-2å®Ÿè¡Œï¼ˆåŒæœŸï¼‰
                    step2 = PIMStep2NSGA2(dsm_data, removed_indices)
                    pareto_front = step2.run(
                        n_pop=step2_pop,
                        n_gen=step2_gen,
                        checkpoint_id=None,
                        save_every=1,
                        progress_callback=progress_callback
                    )
                    
                    elapsed = time.time() - start_time
                    
                    # çµæœã‚’ãƒªã‚¹ãƒˆåŒ–
                    step2_results = []
                    for ind in pareto_front:
                        adj, conf, loop = ind.fitness.values
                        step2_results.append({
                            'matrix': ind[0].copy(),
                            'adjustment': adj,
                            'conflict': conf,
                            'loop': loop
                        })
                    
                    st.session_state.step2_results = step2_results
                    st.session_state.step2_package = step2.pkg
                    
                    progress_placeholder.empty()
                    elapsed_min = int(elapsed // 60)
                    elapsed_sec = int(elapsed % 60)
                    status_placeholder.success(f"âœ… STEP-2å®Œäº†: {len(pareto_front)}å€‹ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£ã‚’ç™ºè¦‹ï¼ˆ{elapsed_min}åˆ†{elapsed_sec}ç§’ï¼‰")
                    
                except Exception as e:
                    progress_placeholder.empty()
                    status_placeholder.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc(), language="python")
        
        # STEP-2çµæœã®å¯è¦–åŒ–
        if "step2_results" in st.session_state and st.session_state.step2_results:
            results2 = st.session_state.step2_results
            
            st.markdown("#### ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆï¼ˆ3Dï¼‰")
            
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # 3Dæ•£å¸ƒå›³
            from mpl_toolkits.mplot3d import Axes3D
            
            fig = plt.figure(figsize=(12, 8))
            ax = fig.add_subplot(111, projection='3d')
            
            adjs = [r['adjustment'] for r in results2]
            confs = [r['conflict'] for r in results2]
            loops = [r['loop'] for r in results2]
            
            scatter = ax.scatter(adjs, confs, loops, c=range(len(results2)), cmap='plasma', s=100, alpha=0.7)
            ax.set_xlabel('èª¿æ•´å›°é›£åº¦', fontsize=10)
            ax.set_ylabel('ç«¶åˆå›°é›£åº¦', fontsize=10)
            ax.set_zlabel('ãƒ«ãƒ¼ãƒ—å›°é›£åº¦', fontsize=10)
            ax.set_title('STEP-2 ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ', fontsize=14)
            plt.colorbar(scatter, ax=ax, label='è§£ç•ªå·', shrink=0.5)
            
            st.pyplot(fig)
            plt.close()
            
            # è§£é¸æŠ
            st.markdown("#### è§£ã®é¸æŠ")
            
            df_results2 = pd.DataFrame([{
                'è§£ç•ªå·': i,
                'èª¿æ•´å›°é›£åº¦': f"{r['adjustment']:.2f}",
                'ç«¶åˆå›°é›£åº¦': f"{r['conflict']:.2f}",
                'ãƒ«ãƒ¼ãƒ—å›°é›£åº¦': f"{r['loop']:.2f}"
            } for i, r in enumerate(results2)])
            
            st.dataframe(df_results2, use_container_width=True, hide_index=True)
            
            selected_idx2 = st.selectbox(
                "æœ€çµ‚è§£ã‚’é¸æŠ",
                options=list(range(len(results2))),
                format_func=lambda i: f"è§£{i}: èª¿æ•´={results2[i]['adjustment']:.2f}, ç«¶åˆ={results2[i]['conflict']:.2f}, ãƒ«ãƒ¼ãƒ—={results2[i]['loop']:.2f}"
            )
            
            if selected_idx2 is not None:
                selected2 = results2[selected_idx2]
                pkg = st.session_state.step2_package
                
                with st.expander(f"ğŸ“Š è§£{selected_idx2}ã®è©³ç´°", expanded=True):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("èª¿æ•´å›°é›£åº¦", f"{selected2['adjustment']:.2f}")
                    with col2:
                        st.metric("ç«¶åˆå›°é›£åº¦", f"{selected2['conflict']:.2f}")
                    with col3:
                        st.metric("ãƒ«ãƒ¼ãƒ—å›°é›£åº¦", f"{selected2['loop']:.2f}")
                    
                    st.markdown("**æœ€é©åŒ–ã•ã‚ŒãŸDSM:**")
                    
                    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
                    optimized_matrix = selected2['matrix']
                    node_names = [pkg['node_name'][0][i] for i in range(pkg['matrix_size'])]
                    
                    df_optimized = pd.DataFrame(
                        optimized_matrix,
                        index=node_names,
                        columns=node_names
                    )
                    
                    fig, ax = plt.subplots(figsize=(12, 10))
                    
                    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
                    plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
                    plt.rcParams['axes.unicode_minus'] = False
                    
                    sns.heatmap(
                        df_optimized,
                        annot=True,
                        fmt='.0f',
                        cmap='coolwarm',
                        center=0,
                        vmin=-9,
                        vmax=9,
                        linewidths=0.5,
                        cbar_kws={'label': 'å½±éŸ¿ã‚¹ã‚³ã‚¢'},
                        ax=ax
                    )
                    ax.set_title('æœ€é©åŒ–ã•ã‚ŒãŸDSM', fontsize=14, pad=20)
                    
                    st.pyplot(fig)
                    plt.close()
                
                # é¸æŠã‚’ä¿å­˜
                st.session_state.step2_selected_idx = selected_idx2
                st.session_state.optimized_dsm = selected2['matrix']
    
    # 8.4 STEP-3: ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–
    if "step2_selected_idx" in st.session_state and "optimized_dsm" in st.session_state:
        st.markdown("---")
        st.subheader("8.4. STEP-3: ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–")
        
        with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=True):
            st.markdown("""
            **ä½•ãŒã‚ã‹ã‚‹ã‹:**
            - ã©ã®è¦ç´ ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã¹ãã‹ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œå‡ºï¼‰
            - ã©ã®é †ç•ªã§è¨­è¨ˆã™ã¹ãã‹ï¼ˆãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‰
            - ã©ã“ã§æ‰‹æˆ»ã‚ŠãŒç™ºç”Ÿã™ã‚‹ã‹ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ï¼‰
            
            **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
            - ãƒãƒ¼ãƒ ç·¨æˆã®å‚è€ƒã«ã™ã‚‹ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½ã§åˆ†æ‹…ï¼‰
            - ä½œæ¥­é †åºã‚’æ±ºå®šã™ã‚‹ï¼ˆãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¾“ã†ï¼‰
            - æ‰‹æˆ»ã‚Šã‚’äº‹å‰ã«èªè­˜ã™ã‚‹ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®‡æ‰€ã®ç‰¹å®šï¼‰
            
            **çµæœã®è¦‹æ–¹:**
            - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: å¯†ã«çµåˆã—ãŸãƒãƒ¼ãƒ‰ç¾¤
            - ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹: ä¾å­˜é–¢ä¿‚ã«åŸºã¥ãæœ€é©ãªè¨­è¨ˆé †åº
            - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡: æ‰‹æˆ»ã‚Šã®åº¦åˆã„ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
            """)
        
        st.info("â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: <1åˆ†")
        
        with st.expander("âš™ï¸ è©³ç´°è¨­å®š", expanded=False):
            n_modules = st.slider(
                "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°",
                min_value=2,
                max_value=min(10, len(st.session_state.optimized_dsm) // 2),
                value=None,
                help="Noneã®å ´åˆã¯è‡ªå‹•æ±ºå®šï¼ˆâˆš(N/2)å€‹ï¼‰"
            )
        
        if st.button("ğŸš€ ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            with st.spinner("åˆ†æä¸­..."):
                try:
                    from utils.dsm_partitioning import DSMPartitioner
                    import time
                    
                    start_time = time.time()
                    
                    optimized_matrix = st.session_state.optimized_dsm
                    pkg = st.session_state.step2_package
                    node_names = [pkg['node_name'][0][i] for i in range(pkg['matrix_size'])]
                    
                    partitioner = DSMPartitioner(optimized_matrix, node_names)
                    
                    analysis_result = partitioner.full_analysis(n_clusters=n_modules)
                    
                    st.session_state.partitioning_result = analysis_result
                    
                    elapsed = time.time() - start_time
                    
                    st.success(f"âœ… ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°å®Œäº†ï¼ˆ{elapsed:.2f}ç§’ï¼‰")
                    
                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc(), language="python")
                    return
        
        if "partitioning_result" in st.session_state:
            result = st.session_state.partitioning_result
            
            st.markdown("### åˆ†æçµæœ")
            
            # 8.4.1 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±
            with st.expander("ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±", expanded=True):
                col_m1, col_m2, col_m3 = st.columns(3)
                with col_m1:
                    st.metric("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°", result['modules']['n_modules'])
                with col_m2:
                    st.metric("ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢", f"{result['modularity_score']:.3f}",
                             help="é«˜ã„ã»ã©è‰¯ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ï¼ˆ-1ï½1ï¼‰")
                with col_m3:
                    st.metric("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡", f"{result['feedback_loops']['feedback_ratio']:.1%}",
                             help="ä½ã„ã»ã©æ‰‹æˆ»ã‚ŠãŒå°‘ãªã„")
                
                st.markdown("**å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¡ãƒ³ãƒãƒ¼:**")
                for module_id, members in result['module_members'].items():
                    with st.expander(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«{module_id}ï¼ˆ{len(members)}ãƒãƒ¼ãƒ‰ï¼‰"):
                        for member in members:
                            st.caption(f"- {member}")
            
            # 8.4.2 ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
            with st.expander("ğŸ“‹ ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆè¨­è¨ˆé †åºï¼‰", expanded=True):
                st.markdown("**æ¨å¥¨ã•ã‚Œã‚‹è¨­è¨ˆé †åº:**")
                sequence_nodes = result['design_sequence']['reordered_nodes']
                for i, node in enumerate(sequence_nodes, 1):
                    st.caption(f"{i}. {node}")
            
            # 8.4.3 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
            with st.expander("ğŸ” ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ï¼ˆæ‰‹æˆ»ã‚Šç®‡æ‰€ï¼‰", expanded=True):
                col_f1, col_f2, col_f3 = st.columns(3)
                with col_f1:
                    st.metric("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰", result['feedback_loops']['feedforward_count'])
                with col_f2:
                    st.metric("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆæ‰‹æˆ»ã‚Šï¼‰", result['feedback_loops']['feedback_count'])
                with col_f3:
                    st.metric("å¯¾è§’è¦ç´ ", result['feedback_loops']['diagonal_count'])
                
                if result['feedback_loops']['feedback_elements']:
                    st.markdown("**æ‰‹æˆ»ã‚ŠãŒç™ºç”Ÿã™ã‚‹ç®‡æ‰€:**")
                    feedback_df = pd.DataFrame([
                        {
                            "From": elem['from'],
                            "To": elem['to'],
                            "å½±éŸ¿ã‚¹ã‚³ã‚¢": elem['value']
                        }
                        for elem in result['feedback_loops']['feedback_elements'][:20]
                    ])
                    st.dataframe(feedback_df, use_container_width=True, hide_index=True)
                else:
                    st.success("âœ… æ‰‹æˆ»ã‚ŠãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆç†æƒ³çš„ãªè¨­è¨ˆé †åºï¼‰")
            
            # 8.4.4 ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æ¸ˆã¿DSMãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            with st.expander("ğŸ“Š ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æ¸ˆã¿DSMãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", expanded=True):
                reordered_matrix = result['design_sequence']['reordered_matrix']
                reordered_nodes = result['design_sequence']['reordered_nodes']
                
                df_partitioned = pd.DataFrame(
                    reordered_matrix,
                    index=reordered_nodes,
                    columns=reordered_nodes
                )
                
                fig, ax = plt.subplots(figsize=(14, 12))
                
                plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                
                sns.heatmap(
                    df_partitioned,
                    annot=True,
                    fmt='.0f',
                    cmap='coolwarm',
                    center=0,
                    vmin=-9,
                    vmax=9,
                    linewidths=0.5,
                    cbar_kws={'label': 'å½±éŸ¿ã‚¹ã‚³ã‚¢'},
                    ax=ax
                )
                ax.set_title('ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æ¸ˆã¿DSMï¼ˆãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é †ï¼‰', fontsize=14, pad=20)
                ax.set_xlabel('To Node (å½±éŸ¿ã‚’å—ã‘ã‚‹)', fontsize=12)
                ax.set_ylabel('From Node (å½±éŸ¿ã‚’ä¸ãˆã‚‹)', fontsize=12)
                
                st.pyplot(fig)
                plt.close()
    
    else:
        st.info("ğŸ‘† ã¾ãšSTEP-1ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")


def tab9_advanced_analytics():
    """ã‚¿ãƒ–9: é«˜åº¦ãªåˆ†æï¼ˆã‚¹ãƒ†ãƒƒãƒ—9ï¼‰"""
    st.header("ğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—9: é«˜åº¦ãªåˆ†æ")
    
    adj_matrix_df = st.session_state.get("adj_matrix_df")
    nodes = SessionManager.get_nodes()
    all_idef0 = SessionManager.get_all_idef0_nodes()
    
    if adj_matrix_df is None or nodes is None or len(nodes) < 2:
        st.warning("âš ï¸ å…ˆã«ã‚¿ãƒ–5ã§éš£æ¥è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
        return
    
    st.markdown("""
    ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€çŸ¥è­˜ãŒãªãã¦ã‚‚ä½¿ãˆã‚‹é«˜åº¦ãªåˆ†æãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
    å„æ‰‹æ³•ã§ã€Œä½•ãŒã‚ã‹ã‚‹ã‹ã€ã€Œã©ã†ä½¿ãˆã°ã„ã„ã‹ã€ã‚’å¹³æ˜“ã«èª¬æ˜ã—ã¾ã™ã€‚
    
    **7ã¤ã®åˆ†ææ‰‹æ³•:**
    1. å”åŠ›è²¢çŒ®åº¦åˆ†æï¼ˆShapley Valueï¼‰
    2. æƒ…å ±ãƒ•ãƒ­ãƒ¼åˆ†æï¼ˆTransfer Entropyï¼‰
    3. çµ±è¨ˆçš„æ¤œå®šï¼ˆBootstrapæ³•ï¼‰
    4. ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–ï¼ˆBayesian Inferenceï¼‰
    5. å› æœæ¨è«–ï¼ˆPearl's Causal Inferenceï¼‰
    6. æ½œåœ¨æ§‹é€ ç™ºè¦‹ï¼ˆGraph Embeddingï¼‰
    7. æ„Ÿåº¦åˆ†æï¼ˆFisher Informationï¼‰
    """)
    
    st.info("ğŸ’¡ å„åˆ†æã«ã¯è¨ˆç®—æ™‚é–“ã®è¦‹ç©ã‚‚ã‚ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚èˆˆå‘³ã®ã‚ã‚‹åˆ†æã‹ã‚‰é †ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    # 9.1 Shapley Value
    st.markdown("---")
    st.subheader("9.1. å”åŠ›è²¢çŒ®åº¦åˆ†æï¼ˆShapley Valueï¼‰â­ æ¨å¥¨")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        å„ãƒãƒ¼ãƒ‰ã®ã€ŒçœŸã®è²¢çŒ®åº¦ã€ã‚’å…¬å¹³ã«è©•ä¾¡ã—ã¾ã™ã€‚
        ã€Œã“ã®ãƒãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ãŸã‚‰å…¨ä½“æ€§èƒ½ãŒã©ã‚Œã ã‘ä¸‹ãŒã‚‹ã‹ã€ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - æŠ•è³‡å„ªå…ˆé †ä½ã®æ±ºå®šï¼ˆè²¢çŒ®åº¦ãŒé«˜ã„å·¥ç¨‹ã‚’å„ªå…ˆæ”¹å–„ï¼‰
        - è¦‹ãˆã«ãã„ã€Œç¸ã®ä¸‹ã®åŠ›æŒã¡ã€ã®ç™ºè¦‹
        - ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æ ¹æ‹ ä½œæˆ
        
        **çµæœã®è¦‹æ–¹:**
        - Shapleyå€¤ãŒé«˜ã„ = å…¨ä½“ã¸ã®è²¢çŒ®ãŒå¤§ãã„
        - ä¸Šä½10ãƒãƒ¼ãƒ‰ã‚’é‡ç‚¹ç®¡ç†å¯¾è±¡ã¨ã™ã‚‹
        - è² ã®å€¤ = å‰Šé™¤ã™ã‚‹ã¨å…¨ä½“ãŒæ”¹å–„ã™ã‚‹å¯èƒ½æ€§ï¼ˆè¦å†æ¤œè¨ï¼‰
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 2-5åˆ†ï¼ˆ{len(nodes)}ãƒãƒ¼ãƒ‰ã€ã‚µãƒ³ãƒ—ãƒ«æ•°1000ï¼‰")
    
    col_settings, col_execute = st.columns([2, 1])
    
    with col_settings:
        n_samples = st.slider(
            "ã‚µãƒ³ãƒ—ãƒ«æ•°",
            min_value=100,
            max_value=5000,
            value=1000,
            step=100,
            help="å¤šã„ã»ã©ç²¾åº¦å‘ä¸Šã€è¨ˆç®—æ™‚é–“å¢—åŠ "
        )
        
        value_function = st.selectbox(
            "ä¾¡å€¤é–¢æ•°",
            options=["pagerank_sum", "efficiency", "connectivity"],
            format_func=lambda x: {
                "pagerank_sum": "PageRankåˆè¨ˆï¼ˆæ¨å¥¨ï¼‰",
                "efficiency": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹ç‡æ€§",
                "connectivity": "æ¥ç¶šæ€§"
            }[x],
            help="ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¾¡å€¤ã‚’ã©ã†è©•ä¾¡ã™ã‚‹ã‹"
        )
    
    with col_execute:
        st.write("")
        st.write("")
        execute_shapley = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", key="shapley_btn", type="primary", use_container_width=True)
    
    if execute_shapley:
        try:
            with st.spinner("Shapley Valueè¨ˆç®—ä¸­..."):
                from utils.shapley_analysis import ShapleyAnalyzer
                from utils.analytics_progress import AnalyticsProgressTracker, create_simple_callback
                
                # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
                tracker = AnalyticsProgressTracker("Shapley Valueåˆ†æ", total_steps=n_samples)
                
                # ãƒãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
                categories_list = SessionManager.get_functional_categories()
                all_idef0 = SessionManager.get_all_idef0_nodes()
                node_categories = {}
                for category in categories_list:
                    if category in all_idef0:
                        idef0_dict = all_idef0[category]
                        for node_type in ['outputs', 'mechanisms', 'inputs']:
                            if node_type in idef0_dict:
                                for node_name in idef0_dict[node_type]:
                                    node_categories[node_name] = category
                
                # Shapleyåˆ†æå®Ÿè¡Œ
                analyzer = ShapleyAnalyzer(
                    adjacency_matrix=st.session_state.adjacency_matrix,
                    node_names=nodes,
                    node_categories=node_categories,
                    value_function=value_function
                )
                
                # ã‚·ãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
                progress_callback = create_simple_callback(tracker)
                
                result = analyzer.compute_shapley_values(
                    n_samples=n_samples,
                    progress_callback=progress_callback
                )
                
                # çµæœã‚’ä¿å­˜
                if "advanced_analytics_results" not in st.session_state:
                    st.session_state.advanced_analytics_results = {}
                
                st.session_state.advanced_analytics_results["shapley"] = {
                    "result": result,
                    "parameters": {
                        "n_samples": n_samples,
                        "value_function": value_function
                    },
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                # å®Œäº†å‡¦ç†
                tracker.complete(result.computation_time)
        except Exception as e:
            if 'tracker' in locals():
                tracker.error(str(e))
            st.error(f"âŒ Shapley Valueåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    # çµæœè¡¨ç¤º
    if "advanced_analytics_results" in st.session_state and "shapley" in st.session_state.advanced_analytics_results:
        result_data = st.session_state.advanced_analytics_results["shapley"]
        result = result_data["result"]
        
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ†æçµæœ")
        
        # è§£é‡ˆæ–‡
        with st.expander("ğŸ’¡ çµæœã®è§£é‡ˆ", expanded=True):
            st.markdown(result.interpretation)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        with col_m1:
            st.metric("ç·ãƒãƒ¼ãƒ‰æ•°", len(result.shapley_values))
        with col_m2:
            st.metric("å…¨ä½“ä¾¡å€¤", f"{result.total_value:.4f}")
        with col_m3:
            st.metric("è¨ˆç®—æ™‚é–“", f"{result.computation_time:.1f}ç§’")
        with col_m4:
            top_value = result.top_contributors[0][1] if result.top_contributors else 0
            st.metric("æœ€å¤§è²¢çŒ®åº¦", f"{top_value:.4f}")
        
        # ä¸Šä½è²¢çŒ®è€…è¡¨
        st.markdown("### ğŸ† è²¢çŒ®åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½20ï¼‰")
        top_20 = result.top_contributors[:20]
        df_top = pd.DataFrame([
            {
                "é †ä½": i+1,
                "ãƒãƒ¼ãƒ‰å": name,
                "Shapleyå€¤": value,
                "è²¢çŒ®ç‡%": (value / result.total_value * 100) if result.total_value > 0 else 0
            }
            for i, (name, value) in enumerate(top_20)
        ])
        st.dataframe(df_top, use_container_width=True, hide_index=True)
        
        # å¯è¦–åŒ–
        import matplotlib.pyplot as plt
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        col_viz1, col_viz2 = st.columns(2)
        
        with col_viz1:
            st.markdown("### ğŸ“Š è²¢çŒ®åº¦åˆ†å¸ƒï¼ˆä¸Šä½15ï¼‰")
            top_15 = result.top_contributors[:15]
            
            fig, ax = plt.subplots(figsize=(8, 6))
            names = [name for name, _ in top_15]
            values = [value for _, value in top_15]
            
            colors = ['#2ecc71' if v > 0 else '#e74c3c' for v in values]
            ax.barh(range(len(names)), values, color=colors, alpha=0.8)
            ax.set_yticks(range(len(names)))
            ax.set_yticklabels(names)
            ax.set_xlabel('Shapley Value')
            ax.set_title('Top 15 Contributors')
            ax.invert_yaxis()
            ax.grid(axis='x', alpha=0.3)
            
            st.pyplot(fig)
            plt.close()
        
        with col_viz2:
            st.markdown("### ğŸ“ˆ ç´¯ç©è²¢çŒ®åº¦")
            
            fig, ax = plt.subplots(figsize=(8, 6))
            x = [n for n, _ in result.cumulative_contribution]
            y = [pct for _, pct in result.cumulative_contribution]
            
            ax.plot(x, y, marker='o', linewidth=2, markersize=4, color='#3498db')
            ax.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='80%ãƒ©ã‚¤ãƒ³')
            ax.set_xlabel('Top N Nodes')
            ax.set_ylabel('Cumulative Contribution (%)')
            ax.set_title('Cumulative Contribution Curve')
            ax.legend()
            ax.grid(alpha=0.3)
            
            st.pyplot(fig)
            plt.close()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è²¢çŒ®åº¦
        if result.category_contributions:
            st.markdown("### ğŸ“¦ ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡è²¢çŒ®åº¦")
            df_cat = pd.DataFrame([
                {"ã‚«ãƒ†ã‚´ãƒª": cat, "å¹³å‡Shapleyå€¤": value}
                for cat, value in sorted(result.category_contributions.items(), key=lambda x: x[1], reverse=True)
            ])
            st.dataframe(df_cat, use_container_width=True, hide_index=True)
        
        # 7. é€£æºå®‰å®šæ€§åˆ†æ
        st.markdown("### ğŸ”— é€£æºå®‰å®šæ€§åˆ†æ")
        st.markdown("""
        **ç›®çš„:** Shapleyå€¤ä¸Šä½ãƒãƒ¼ãƒ‰åŒå£«ã‚’é€£æºã•ã›ã‚‹ã“ã¨ã§ã€ç›¸ä¹—åŠ¹æœã‚’æœ€å¤§åŒ–
        
        ä¸Šä½25%ã®ãƒãƒ¼ãƒ‰é–“ã®æ¥ç¶šå¼·åº¦ã‚’åˆ†æã—ã€å¯†çµåˆãƒšã‚¢ã‚’ç‰¹å®šã€‚
        ã“ã‚Œã‚‰ã®é€£æºã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã§ã€å…¨ä½“æ€§èƒ½ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚
        """)
        
        if st.button("ğŸ”— é€£æºå®‰å®šæ€§ã‚’åˆ†æ", key="coalition_stability_btn"):
            with st.spinner("é€£æºå®‰å®šæ€§ã‚’è¨ˆç®—ä¸­..."):
                from utils.shapley_analysis import compute_shapley_coalition_stability
                
                stability_result = compute_shapley_coalition_stability(
                    shapley_values=result.shapley_values,
                    adjacency_matrix=st.session_state.adjacency_matrix,
                    node_names=nodes
                )
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.advanced_analytics_results["shapley"]["stability"] = stability_result
                
                st.success(f"âœ… é€£æºå®‰å®šæ€§åˆ†æå®Œäº†ï¼ˆä¸Šä½{len(stability_result['top_contributors'])}ãƒãƒ¼ãƒ‰åˆ†æï¼‰")
        
        # çµæœè¡¨ç¤º
        if "stability" in st.session_state.advanced_analytics_results["shapley"]:
            stability_result = st.session_state.advanced_analytics_results["shapley"]["stability"]
            
            # æ¨å¥¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.info(stability_result["recommendation"])
            
            col_stab1, col_stab2 = st.columns([1, 1])
            
            with col_stab1:
                st.markdown("#### ğŸ† ä¸Šä½è²¢çŒ®è€…ï¼ˆTop 25%ï¼‰")
                top_nodes = stability_result["top_contributors"]
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
                df_top_nodes = pd.DataFrame([
                    {
                        "é †ä½": i+1,
                        "ãƒãƒ¼ãƒ‰å": node,
                        "Shapleyå€¤": result.shapley_values[node]
                    }
                    for i, node in enumerate(top_nodes)
                ])
                st.dataframe(df_top_nodes, use_container_width=True, hide_index=True)
            
            with col_stab2:
                st.markdown("#### ğŸ¤ å¯†çµåˆãƒšã‚¢ï¼ˆTop 10ï¼‰")
                dense_connections = stability_result["dense_connections"]
                
                if dense_connections:
                    df_dense = pd.DataFrame([
                        {
                            "é †ä½": i+1,
                            "ãƒãƒ¼ãƒ‰1": node1,
                            "ãƒãƒ¼ãƒ‰2": node2,
                            "æ¥ç¶šå¼·åº¦": strength
                        }
                        for i, (node1, node2, strength) in enumerate(dense_connections)
                    ])
                    st.dataframe(df_dense, use_container_width=True, hide_index=True)
                else:
                    st.warning("ä¸Šä½ãƒãƒ¼ãƒ‰é–“ã«æ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆç–ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰")
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³å¯è¦–åŒ–
            if dense_connections:
                st.markdown("#### ğŸŒ é€£æºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³")
                
                import networkx as nx
                
                fig, ax = plt.subplots(figsize=(12, 8))
                
                # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
                G = nx.Graph()
                
                # ä¸Šä½ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
                top_nodes = stability_result["top_contributors"]
                for node in top_nodes:
                    G.add_node(node, shapley=result.shapley_values[node])
                
                # å¯†çµåˆã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
                for node1, node2, strength in dense_connections:
                    G.add_edge(node1, node2, weight=strength)
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—ï¼ˆspring layoutï¼‰
                pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
                
                # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºï¼ˆShapleyå€¤ã«æ¯”ä¾‹ï¼‰
                node_sizes = [result.shapley_values[node] * 3000 for node in G.nodes()]
                
                # ãƒãƒ¼ãƒ‰è‰²ï¼ˆShapleyå€¤ã§ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                shapley_vals = [result.shapley_values[node] for node in G.nodes()]
                
                # ã‚¨ãƒƒã‚¸å¹…ï¼ˆæ¥ç¶šå¼·åº¦ã«æ¯”ä¾‹ï¼‰
                edge_widths = [G[u][v]['weight'] * 0.5 for u, v in G.edges()]
                
                # æç”»
                nx.draw_networkx_nodes(
                    G, pos, 
                    node_size=node_sizes,
                    node_color=shapley_vals,
                    cmap=plt.cm.YlGnBu,
                    alpha=0.8,
                    ax=ax
                )
                
                nx.draw_networkx_edges(
                    G, pos,
                    width=edge_widths,
                    alpha=0.6,
                    edge_color='gray',
                    ax=ax
                )
                
                nx.draw_networkx_labels(
                    G, pos,
                    font_size=9,
                    font_weight='bold',
                    ax=ax
                )
                
                ax.set_title('Coalition Stability Network (Top Contributors)', fontsize=14, fontweight='bold')
                ax.axis('off')
                
                # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
                sm = plt.cm.ScalarMappable(
                    cmap=plt.cm.YlGnBu,
                    norm=plt.Normalize(vmin=min(shapley_vals), vmax=max(shapley_vals))
                )
                sm.set_array([])
                cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)
                cbar.set_label('Shapley Value', rotation=270, labelpad=20)
                
                st.pyplot(fig)
                plt.close()
    
    # 9.2 Transfer Entropy
    st.markdown("---")
    st.subheader("9.2. æƒ…å ±ãƒ•ãƒ­ãƒ¼åˆ†æï¼ˆTransfer Entropyï¼‰â­ æ¨å¥¨")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        ã€Œèª°ãŒèª°ã«ä½•bitæƒ…å ±ã‚’ä¼ãˆã¦ã„ã‚‹ã‹ã€ã‚’å®šé‡åŒ–ã—ã¾ã™ã€‚
        å˜ãªã‚‹ç›¸é–¢ã§ã¯ãªãã€å› æœçš„ãªæƒ…å ±ã®æµã‚Œã‚’æ¤œå‡ºã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - çœŸã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®šï¼ˆæƒ…å ±ãŒé›†ä¸­ãƒ»é®æ–­ã•ã‚Œã‚‹ç®‡æ‰€ï¼‰
        - é–“æ¥çš„ãªå½±éŸ¿çµŒè·¯ã®ç™ºè¦‹
        - ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆã®æ”¹å–„
        
        **çµæœã®è¦‹æ–¹:**
        - Transfer Entropy ãŒé«˜ã„ = å¼·ã„å› æœçš„å½±éŸ¿
        - 0ã«è¿‘ã„ = è¦‹ã‹ã‘ã®ç›¸é–¢ã®ã¿ï¼ˆå®Ÿéš›ã«ã¯å½±éŸ¿ã—ã¦ã„ãªã„ï¼‰
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 1-3åˆ†ï¼ˆ{len(nodes)}ãƒãƒ¼ãƒ‰ï¼‰")
    
    col_settings_te, col_execute_te = st.columns([2, 1])
    
    with col_settings_te:
        n_walks = st.slider(
            "ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯å›æ•°",
            min_value=500,
            max_value=5000,
            value=1000,
            step=100,
            help="å¤šã„ã»ã©ç²¾åº¦å‘ä¸Šã€è¨ˆç®—æ™‚é–“å¢—åŠ "
        )
        
        walk_length = st.slider(
            "ã‚¦ã‚©ãƒ¼ã‚¯é•·",
            min_value=20,
            max_value=100,
            value=50,
            step=10,
            help="æ™‚ç³»åˆ—ã®é•·ã•"
        )
        
        n_bins = st.slider(
            "é›¢æ•£åŒ–ãƒ“ãƒ³æ•°",
            min_value=2,
            max_value=5,
            value=3,
            step=1,
            help="ä½ã„=ç²—ã„åˆ†é¡ã€é«˜ã„=ç´°ã‹ã„åˆ†é¡"
        )
    
    with col_execute_te:
        st.write("")
        st.write("")
        execute_te = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", key="te_btn", type="primary", use_container_width=True)
    
    if execute_te:
        try:
            with st.spinner("Transfer Entropyè¨ˆç®—ä¸­..."):
                from utils.information_theory_analysis import TransferEntropyAnalyzer
                from utils.analytics_progress import AnalyticsProgressTracker
                
                # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
                tracker_te = AnalyticsProgressTracker("Transfer Entropyåˆ†æ", total_steps=100)
                
                # progress_callbackã‚’å®šç¾©ï¼ˆmessage, pctå½¢å¼ï¼‰
                def progress_callback_te(message, pct):
                    tracker_te.update(int(pct * 100), message)
                
                analyzer_te = TransferEntropyAnalyzer(
                    adjacency_matrix=st.session_state.adjacency_matrix,
                    node_names=nodes,
                    n_walks=n_walks,
                    walk_length=walk_length,
                    n_bins=n_bins
                )
                
                result_te = analyzer_te.compute_transfer_entropy(
                    progress_callback=progress_callback_te
                )
                
                if "advanced_analytics_results" not in st.session_state:
                    st.session_state.advanced_analytics_results = {}
                
                st.session_state.advanced_analytics_results["transfer_entropy"] = {
                    "result": result_te,
                    "parameters": {
                        "n_walks": n_walks,
                        "walk_length": walk_length,
                        "n_bins": n_bins
                    },
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                # å®Œäº†å‡¦ç†
                tracker_te.complete(result_te.computation_time)
        except Exception as e:
            if 'tracker_te' in locals():
                tracker_te.error(str(e))
            st.error(f"âŒ Transfer Entropyåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    if "advanced_analytics_results" in st.session_state and "transfer_entropy" in st.session_state.advanced_analytics_results:
        result_data_te = st.session_state.advanced_analytics_results["transfer_entropy"]
        result_te = result_data_te["result"]
        
        st.markdown("---")
        st.subheader("ğŸ“¡ åˆ†æçµæœ")
        
        with st.expander("ğŸ’¡ çµæœã®è§£é‡ˆ", expanded=True):
            st.markdown(result_te.interpretation)
        
        col_m1_te, col_m2_te, col_m3_te, col_m4_te = st.columns(4)
        with col_m1_te:
            st.metric("ç·ãƒãƒ¼ãƒ‰æ•°", len(nodes))
        with col_m2_te:
            avg_te = result_te.te_matrix[result_te.te_matrix > 0].mean() if (result_te.te_matrix > 0).any() else 0
            st.metric("å¹³å‡TE", f"{avg_te:.3f} bits")
        with col_m3_te:
            st.metric("è¨ˆç®—æ™‚é–“", f"{result_te.computation_time:.1f}ç§’")
        with col_m4_te:
            st.metric("æœ‰æ„ãƒ•ãƒ­ãƒ¼æ•°", len(result_te.significant_flows))
        
        st.markdown("### ğŸ” æœ‰æ„ãªæƒ…å ±ãƒ•ãƒ­ãƒ¼ï¼ˆä¸Šä½20ï¼‰")
        top_20_te = result_te.significant_flows[:20]
        df_top_te = pd.DataFrame([
            {
                "é †ä½": i+1,
                "From": source,
                "To": target,
                "TE (bits)": te_value
            }
            for i, (source, target, te_value) in enumerate(top_20_te)
        ])
        st.dataframe(df_top_te, use_container_width=True, hide_index=True)
        
        import matplotlib.pyplot as plt
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        col_viz1_te, col_viz2_te = st.columns(2)
        
        with col_viz1_te:
            st.markdown("### ğŸ“Š TEè¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
            
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(result_te.te_matrix, ax=ax, cmap='Blues',
                       xticklabels=nodes, yticklabels=nodes,
                       cbar_kws={'label': 'Transfer Entropy (bits)'})
            ax.set_title('Transfer Entropy Matrix')
            ax.set_xlabel('To Node')
            ax.set_ylabel('From Node')
            
            st.pyplot(fig)
            plt.close()
        
        with col_viz2_te:
            st.markdown("### ğŸ“ˆ æƒ…å ±æµå…¥/æµå‡ºé‡")
            
            inflow_vals = [result_te.info_inflow.get(node, 0) for node in nodes[:15]]
            outflow_vals = [result_te.info_outflow.get(node, 0) for node in nodes[:15]]
            
            fig, ax = plt.subplots(figsize=(10, 8))
            x = np.arange(len(nodes[:15]))
            width = 0.35
            
            ax.barh(x - width/2, inflow_vals, width, label='æµå…¥é‡', color='#3498db')
            ax.barh(x + width/2, outflow_vals, width, label='æµå‡ºé‡', color='#e74c3c')
            
            ax.set_yticks(x)
            ax.set_yticklabels(nodes[:15])
            ax.set_xlabel('Information Flow (bits)')
            ax.set_title('Top 15 Nodes: Inflow/Outflow')
            ax.legend()
            ax.invert_yaxis()
            
            st.pyplot(fig)
            plt.close()
        
        st.markdown("### ğŸ” å…ƒã®éš£æ¥è¡Œåˆ—ã¨ã®æ¯”è¼ƒ")
        st.markdown("å…ƒã®è©•ä¾¡ã‚¹ã‚³ã‚¢ã¨ Transfer Entropy ã®å·®ç•°ã‚’åˆ†æ")
        
        comparison_filtered = result_te.comparison_with_original[
            result_te.comparison_with_original["åˆ¤å®š"] != "âœ… ä¸€è‡´"
        ].head(20)
        
        if len(comparison_filtered) > 0:
            st.dataframe(comparison_filtered, use_container_width=True, hide_index=True)
        else:
            st.info("å…ƒã®è©•ä¾¡ã‚¹ã‚³ã‚¢ã¨Transfer Entropyã¯æ¦‚ã­ä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚")
        
        if result_te.bottleneck_nodes:
            st.markdown("### ğŸš§ æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãƒãƒ¼ãƒ‰")
            st.markdown("å¤šãã®æƒ…å ±ãŒé›†ä¸­ãƒ»çµŒç”±ã™ã‚‹é‡è¦ãªä¸­ç¶™ç‚¹:")
            for node in result_te.bottleneck_nodes:
                st.markdown(f"- **{node}**")
    
    # 9.3 Bootstrapçµ±è¨ˆæ¤œå®š
    st.markdown("---")
    st.subheader("9.3. çµ±è¨ˆçš„æ¤œå®šï¼ˆBootstrapæ³•ï¼‰")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        ã€Œã“ã®çµæœã¯å¶ç„¶ã§ã¯ãªã„ã€ã¨ã„ã†çµ±è¨ˆçš„æ ¹æ‹ ã‚’æä¾›ã—ã¾ã™ã€‚
        å…¨ã¦ã®æŒ‡æ¨™ã«ä¿¡é ¼åŒºé–“ã¨æœ‰æ„æ€§æ¤œå®šã‚’é©ç”¨ã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - åˆ†æçµæœã®ä¿¡é ¼æ€§è©•ä¾¡
        - çµŒå–¶å±¤ã¸ã®èª¬æ˜è³‡æ–™ï¼ˆçµ±è¨ˆçš„æ ¹æ‹ ä»˜ãï¼‰
        - å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é ‘å¥ãªåˆ†æ
        
        **çµæœã®è¦‹æ–¹:**
        - på€¤ < 0.05 = çµ±è¨ˆçš„ã«æœ‰æ„ï¼ˆ95%ä¿¡é ¼ï¼‰
        - ä¿¡é ¼åŒºé–“ãŒ0ã‚’ã¾ãŸãŒãªã„ = æœ‰æ„ãªå·®ãŒã‚ã‚‹
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 2-4åˆ†ï¼ˆãƒªã‚µãƒ³ãƒ—ãƒ«1000å›ï¼‰")
    
    col_settings_bs, col_execute_bs = st.columns([2, 1])
    
    with col_settings_bs:
        n_bootstrap = st.slider(
            "ãƒªã‚µãƒ³ãƒ—ãƒ«å›æ•°",
            min_value=100,
            max_value=5000,
            value=1000,
            step=100,
            help="å¤šã„ã»ã©ç²¾åº¦å‘ä¸Šã€è¨ˆç®—æ™‚é–“å¢—åŠ "
        )
        
        alpha = st.slider(
            "æœ‰æ„æ°´æº–",
            min_value=0.01,
            max_value=0.10,
            value=0.05,
            step=0.01,
            help="0.05 = 95%ä¿¡é ¼åŒºé–“"
        )
    
    with col_execute_bs:
        st.write("")
        st.write("")
        execute_bs = st.button("ğŸš€ æ¤œå®šå®Ÿè¡Œ", key="bootstrap_btn", type="primary", use_container_width=True)
    
    if execute_bs:
        try:
            with st.spinner("Bootstrapçµ±è¨ˆæ¤œå®šä¸­..."):
                from utils.statistical_testing import BootstrapTester
                from utils.analytics_progress import AnalyticsProgressTracker
                
                # é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã‚’åˆæœŸåŒ–
                tracker_bs = AnalyticsProgressTracker("Bootstrapçµ±è¨ˆæ¤œå®š", total_steps=100)
                
                # progress_callbackã‚’å®šç¾©ï¼ˆmessage, pctå½¢å¼ï¼‰
                def progress_callback_bs(message, pct):
                    tracker_bs.update(int(pct * 100), message)
                
                categories_list = SessionManager.get_functional_categories()
                all_idef0 = SessionManager.get_all_idef0_nodes()
                node_groups_bs = {}
                for category in categories_list:
                    if category in all_idef0:
                        idef0_dict = all_idef0[category]
                        for node_type in ['outputs', 'mechanisms', 'inputs']:
                            if node_type in idef0_dict:
                                for node_name in idef0_dict[node_type]:
                                    node_groups_bs[node_name] = category
                
                tester = BootstrapTester(
                    adjacency_matrix=st.session_state.adjacency_matrix,
                    node_names=nodes,
                    node_groups=node_groups_bs,
                    n_bootstrap=n_bootstrap,
                    alpha=alpha
                )
                
                result_bs = tester.run_comprehensive_bootstrap_analysis(
                    metric_name="PageRank",
                    progress_callback=progress_callback_bs
                )
                
                if "advanced_analytics_results" not in st.session_state:
                    st.session_state.advanced_analytics_results = {}
                
                st.session_state.advanced_analytics_results["bootstrap"] = {
                    "result": result_bs,
                    "parameters": {
                        "n_bootstrap": n_bootstrap,
                        "alpha": alpha
                    },
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                # å®Œäº†å‡¦ç†
                tracker_bs.complete(result_bs.computation_time)
        except Exception as e:
            if 'tracker_bs' in locals():
                tracker_bs.error(str(e))
            st.error(f"âŒ Bootstrapçµ±è¨ˆæ¤œå®šã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    if "advanced_analytics_results" in st.session_state and "bootstrap" in st.session_state.advanced_analytics_results:
        result_data_bs = st.session_state.advanced_analytics_results["bootstrap"]
        result_bs = result_data_bs["result"]
        
        st.markdown("---")
        st.subheader("ğŸ“‹ æ¤œå®šçµæœ")
        
        with st.expander("ğŸ’¡ çµæœã®è§£é‡ˆ", expanded=True):
            st.markdown(result_bs.interpretation)
        
        col_m1_bs, col_m2_bs, col_m3_bs, col_m4_bs = st.columns(4)
        with col_m1_bs:
            st.metric("ç·ãƒãƒ¼ãƒ‰æ•°", len(result_bs.node_ci))
        with col_m2_bs:
            st.metric("å®‰å®š", len(result_bs.stable_findings))
        with col_m3_bs:
            st.metric("ä¸å®‰å®š", len(result_bs.unstable_findings))
        with col_m4_bs:
            st.metric("ãƒªã‚µãƒ³ãƒ—ãƒ«æ•°", result_bs.n_bootstrap)
        
        st.markdown(f"### ğŸ“Š {result_bs.metric_name}ã®ä¿¡é ¼åŒºé–“ï¼ˆä¸Šä½15ï¼‰")
        
        top_15_ci = sorted(result_bs.node_ci.items(), key=lambda x: x[1][0], reverse=True)[:15]
        
        df_ci = pd.DataFrame([
            {
                "é †ä½": i+1,
                "ãƒãƒ¼ãƒ‰å": node,
                "å€¤": ci[0],
                "ä¸‹é™": ci[1],
                "ä¸Šé™": ci[2],
                "ç›¸å¯¾èª¤å·®%": ((ci[2] - ci[1]) / (2 * abs(ci[0])) * 100) if abs(ci[0]) > 1e-6 else 0
            }
            for i, (node, ci) in enumerate(top_15_ci)
        ])
        st.dataframe(df_ci, use_container_width=True, hide_index=True)
        
        import matplotlib.pyplot as plt
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        col_viz1_bs, col_viz2_bs = st.columns(2)
        
        with col_viz1_bs:
            st.markdown("ğŸ“Š ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ä»˜ãæ£’ã‚°ãƒ©ãƒ•")
            
            fig, ax = plt.subplots(figsize=(10, 8))
            
            names = [node for node, _ in top_15_ci]
            values = [ci[0] for _, ci in top_15_ci]
            lower_errors = [ci[0] - ci[1] for _, ci in top_15_ci]
            upper_errors = [ci[2] - ci[0] for _, ci in top_15_ci]
            
            ax.barh(range(len(names)), values, 
                   xerr=[lower_errors, upper_errors],
                   capsize=5, alpha=0.8, color='#3498db')
            ax.set_yticks(range(len(names)))
            ax.set_yticklabels(names)
            ax.set_xlabel(f'{result_bs.metric_name} ({(1-result_bs.alpha)*100:.0f}% CI)')
            ax.set_title(f'Top 15 {result_bs.metric_name} with Confidence Intervals')
            ax.invert_yaxis()
            ax.grid(axis='x', alpha=0.3)
            
            st.pyplot(fig)
            plt.close()
        
        with col_viz2_bs:
            st.markdown("ğŸ“‰ å®‰å®šæ€§ã‚¹ã‚³ã‚¢")
            
            from utils.statistical_testing import compute_stability_score
            stability_df = compute_stability_score(result_bs.node_ci)
            
            top_20_stability = stability_df.head(20)
            
            fig, ax = plt.subplots(figsize=(10, 8))
            
            rel_errors = top_20_stability["ç›¸å¯¾èª¤å·®"].values
            node_names_stab = top_20_stability["ãƒãƒ¼ãƒ‰å"].values
            judgments = top_20_stability["åˆ¤å®š"].values
            
            colors = ['green' if 'å®‰å®š' in j else 'orange' if 'ã‚„ã‚„' in j else 'red' for j in judgments]
            
            ax.barh(range(len(node_names_stab)), rel_errors, color=colors, alpha=0.8)
            ax.axvline(0.2, color='green', linestyle='--', linewidth=2, label='å®‰å®š(<20%)')
            ax.axvline(0.5, color='orange', linestyle='--', linewidth=2, label='ã‚„ã‚„ä¸å®‰å®š(<50%)')
            ax.set_yticks(range(len(node_names_stab)))
            ax.set_yticklabels(node_names_stab)
            ax.set_xlabel('Relative Error')
            ax.set_title('Stability Assessment (lower=more stable)')
            ax.legend()
            ax.invert_yaxis()
            
            st.pyplot(fig)
            plt.close()
        
        if len(result_bs.group_comparison) > 0:
            st.markdown("### ğŸ” ã‚°ãƒ«ãƒ¼ãƒ—é–“æ¯”è¼ƒï¼ˆPermutationæ¤œå®šï¼‰")
            st.dataframe(result_bs.group_comparison, use_container_width=True, hide_index=True)
            
            significant = result_bs.group_comparison[result_bs.group_comparison["æœ‰æ„æ€§"] == "âœ… æœ‰æ„"]
            if len(significant) > 0:
                st.success(f"âœ… {len(significant)}çµ„ã®ãƒšã‚¢ã§çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆp<{result_bs.alpha}ï¼‰")
            else:
                st.info("ã‚°ãƒ«ãƒ¼ãƒ—é–“ã«çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    # 9.4 Bayesian Inference
    st.markdown("---")
    st.subheader("9.4. ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–ï¼ˆBayesian Inferenceï¼‰")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        LLMè©•ä¾¡ã®ã€Œä¿¡é ¼æ€§ã€ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚
        ã€Œã“ã®ã‚¹ã‚³ã‚¢ã¯ 3.5Â±0.8ã€ã®ã‚ˆã†ã«ä¸ç¢ºå®Ÿæ€§ã‚’æ˜ç¤ºã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - å†è©•ä¾¡ãŒå¿…è¦ãªãƒãƒ¼ãƒ‰ã®ç‰¹å®šï¼ˆä¿¡é ¼åŒºé–“ãŒåºƒã„ç®‡æ‰€ï¼‰
        - æ„æ€æ±ºå®šã®ãƒªã‚¹ã‚¯è©•ä¾¡
        - ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸã‚·ãƒŠãƒªã‚ªåˆ†æ
        
        **çµæœã®è¦‹æ–¹:**
        - ä¿¡é ¼åŒºé–“ãŒç‹­ã„ = è©•ä¾¡ãŒå®‰å®šã—ã¦ã„ã‚‹
        - ä¿¡é ¼åŒºé–“ãŒåºƒã„ = å†è©•ä¾¡æ¨å¥¨
        
        **æŠ€è¡“èƒŒæ™¯:**
        Bootstrap-based Bayesian Approximationï¼ˆç°¡æ˜“ç‰ˆï¼‰ã‚’ä½¿ç”¨ã€‚
        å…±å½¹äº‹å‰åˆ†å¸ƒã«ã‚ˆã‚Šè§£æçš„ã«äº‹å¾Œåˆ†å¸ƒã‚’è¨ˆç®—ï¼ˆMCMCä¸è¦ï¼‰ã€‚
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 1-2åˆ†ï¼ˆBootstrap {len(nodes)}ãƒãƒ¼ãƒ‰ï¼‰")
    
    col_settings_bi, col_execute_bi = st.columns([2, 1])
    
    with col_settings_bi:
        st.markdown("**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š**")
        
        col_param1_bi, col_param2_bi = st.columns(2)
        
        with col_param1_bi:
            n_bootstrap_bi = st.slider(
                "Bootstrapã‚µãƒ³ãƒ—ãƒ«æ•°",
                min_value=500,
                max_value=2000,
                value=1000,
                step=100,
                help="å¤šã„ã»ã©ç²¾åº¦å‘ä¸Šï¼ˆè¨ˆç®—æ™‚é–“å¢—åŠ ï¼‰"
            )
        
        with col_param2_bi:
            credible_level_str = st.selectbox(
                "ä¿¡ç”¨åŒºé–“ãƒ¬ãƒ™ãƒ«",
                ["90%", "95%", "99%"],
                index=1,
                help="95%æ¨å¥¨ï¼ˆçœŸã®å€¤ãŒåŒºé–“å†…ã«ã‚ã‚‹ç¢ºç‡ï¼‰"
            )
            credible_level_bi = float(credible_level_str.replace("%", "")) / 100.0
    
    with col_execute_bi:
        st.markdown("**å®Ÿè¡Œ**")
        if st.button("ğŸš€ Bayesianæ¨è«–ã‚’å®Ÿè¡Œ", key="bayesian_btn", use_container_width=True):
            from utils.bayesian_analysis import BayesianAnalyzer
            from utils.analytics_progress import AnalyticsProgressTracker
            
            tracker = AnalyticsProgressTracker("Bayesian Inferenceåˆ†æ", total_steps=100)
            
            try:
                analyzer = BayesianAnalyzer(
                    adjacency_matrix=adjacency_matrix,
                    node_names=nodes,
                    n_bootstrap=n_bootstrap_bi,
                    credible_level=credible_level_bi,
                    prior_type='weak_informative'
                )
                
                result_bi = analyzer.compute_bayesian_inference(
                    progress_callback=tracker.update
                )
                
                tracker.complete(result_bi.computation_time)
                
                if "advanced_analytics_results" not in st.session_state:
                    st.session_state.advanced_analytics_results = {}
                
                st.session_state.advanced_analytics_results["bayesian_inference"] = {
                    "result": result_bi,
                    "parameters": {
                        "n_bootstrap": n_bootstrap_bi,
                        "credible_level": credible_level_bi,
                        "prior_type": "weak_informative"
                    },
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                st.success(f"âœ… Bayesian Inferenceåˆ†æå®Œäº†ï¼ï¼ˆ{result_bi.computation_time:.1f}ç§’ï¼‰")
                st.rerun()
            
            except Exception as e:
                tracker.error(str(e))
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    if "advanced_analytics_results" in st.session_state and "bayesian_inference" in st.session_state.advanced_analytics_results:
        result_bi = st.session_state.advanced_analytics_results["bayesian_inference"]["result"]
        
        st.markdown("### ğŸ’¡ çµæœã®è§£é‡ˆ")
        st.markdown(result_bi.interpretation)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        
        col_metric1_bi, col_metric2_bi, col_metric3_bi, col_metric4_bi = st.columns(4)
        
        with col_metric1_bi:
            st.metric("ç·ã‚¨ãƒƒã‚¸æ•°", result_bi.n_edges)
        
        with col_metric2_bi:
            avg_uncertainty = np.mean(list(result_bi.uncertainty_scores.values())) if result_bi.uncertainty_scores else 0
            st.metric("å¹³å‡ä¸ç¢ºå®Ÿæ€§", f"{avg_uncertainty:.3f}")
        
        with col_metric3_bi:
            n_high_uncertainty = sum(1 for score in result_bi.uncertainty_scores.values() if score > 0.5)
            st.metric("é«˜ä¸ç¢ºå®Ÿæ€§ã‚¨ãƒƒã‚¸", n_high_uncertainty)
        
        with col_metric4_bi:
            st.metric("è¨ˆç®—æ™‚é–“", f"{result_bi.computation_time:.1f}ç§’")
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ å¯è¦–åŒ–")
        
        col_viz1_bi, col_viz2_bi = st.columns(2)
        
        with col_viz1_bi:
            st.markdown("ğŸ“Š ä¸ç¢ºå®Ÿæ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½20ã‚¨ãƒƒã‚¸ï¼‰")
            
            import matplotlib.pyplot as plt
            
            plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            top_20_uncertainty = result_bi.high_uncertainty_edges[:20]
            
            if top_20_uncertainty:
                fig, ax = plt.subplots(figsize=(12, 8))
                
                edge_labels = [f"{s}â†’{t}" for s, t, _ in top_20_uncertainty]
                uncertainty_values = [score for _, _, score in top_20_uncertainty]
                
                y_pos = np.arange(len(edge_labels))
                
                colors = ['red' if u > 0.7 else 'orange' if u > 0.5 else 'yellow' for u in uncertainty_values]
                
                ax.barh(y_pos, uncertainty_values, color=colors, alpha=0.7)
                ax.set_yticks(y_pos)
                ax.set_yticklabels(edge_labels)
                ax.set_xlabel('Uncertainty Score')
                ax.set_title('Top 20 High-Uncertainty Edges')
                ax.axvline(0.5, color='orange', linestyle='--', linewidth=2, label='High (>0.5)')
                ax.axvline(0.7, color='red', linestyle='--', linewidth=2, label='Very High (>0.7)')
                ax.legend()
                ax.invert_yaxis()
                ax.grid(axis='x', alpha=0.3)
                
                st.pyplot(fig)
                plt.close()
        
        with col_viz2_bi:
            st.markdown("ğŸ“‹ ä¿¡ç”¨åŒºé–“ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸Šä½20ã‚¨ãƒƒã‚¸ï¼‰")
            
            credible_pct = int(result_bi.credible_level * 100)
            
            ci_data = []
            for source, target, _ in result_bi.high_uncertainty_edges[:20]:
                edge = (source, target)
                if edge in result_bi.credible_intervals:
                    mean_val, lower, upper = result_bi.credible_intervals[edge]
                    uncertainty = result_bi.uncertainty_scores.get(edge, 0)
                    
                    if uncertainty > 0.7:
                        status = "âŒ éå¸¸ã«ä¸å®‰å®š"
                    elif uncertainty > 0.5:
                        status = "âš ï¸ ä¸å®‰å®š"
                    elif uncertainty > 0.3:
                        status = "âš¡ ã‚„ã‚„ä¸å®‰å®š"
                    else:
                        status = "âœ… å®‰å®š"
                    
                    ci_data.append({
                        "From": source,
                        "To": target,
                        "äº‹å¾Œå¹³å‡": f"{mean_val:.2f}",
                        f"ä¸‹é™{credible_pct}%": f"{lower:.2f}",
                        f"ä¸Šé™{credible_pct}%": f"{upper:.2f}",
                        "ä¸ç¢ºå®Ÿæ€§": f"{uncertainty:.3f}",
                        "åˆ¤å®š": status
                    })
            
            ci_df = pd.DataFrame(ci_data)
            st.dataframe(ci_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š äº‹å¾Œåˆ†å¸ƒã®å¯è¦–åŒ–ï¼ˆä¸Šä½10ã‚¨ãƒƒã‚¸ï¼‰")
        
        if len(result_bi.high_uncertainty_edges) > 0:
            top_10_edges = result_bi.high_uncertainty_edges[:10]
            
            n_rows = (len(top_10_edges) + 1) // 2
            fig, axes = plt.subplots(n_rows, 2, figsize=(14, 4 * n_rows))
            
            if n_rows == 1:
                axes = axes.reshape(1, -1)
            
            for idx, (source, target, _) in enumerate(top_10_edges):
                row = idx // 2
                col = idx % 2
                ax = axes[row, col]
                
                edge = (source, target)
                if edge in result_bi.credible_intervals:
                    mean_val, lower, upper = result_bi.credible_intervals[edge]
                    std_val = result_bi.posterior_std.get(edge, 1.0)
                    
                    x = np.linspace(mean_val - 4*std_val, mean_val + 4*std_val, 200)
                    y = stats.norm.pdf(x, mean_val, std_val)
                    
                    ax.plot(x, y, 'b-', linewidth=2, label='Posterior')
                    ax.axvline(mean_val, color='green', linestyle='-', linewidth=2, label=f'Mean: {mean_val:.2f}')
                    ax.axvline(lower, color='orange', linestyle='--', linewidth=1.5, label=f'CI: [{lower:.2f}, {upper:.2f}]')
                    ax.axvline(upper, color='orange', linestyle='--', linewidth=1.5)
                    ax.fill_between(x, y, where=(x >= lower) & (x <= upper), alpha=0.3, color='orange')
                    
                    ax.set_title(f"{source} â†’ {target}")
                    ax.set_xlabel("Score")
                    ax.set_ylabel("Density")
                    ax.legend(fontsize=8)
                    ax.grid(alpha=0.3)
            
            for idx in range(len(top_10_edges), n_rows * 2):
                row = idx // 2
                col = idx % 2
                fig.delaxes(axes[row, col])
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    # 9.5 Causal Inference
    st.markdown("---")
    st.subheader("9.5. å› æœæ¨è«–ï¼ˆPearl's Causal Inferenceï¼‰")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        ã€Œã‚‚ã—ã“ã®ãƒãƒ¼ãƒ‰ã‚’æ”¹å–„ã—ãŸã‚‰ã€å…¨ä½“ãŒã©ã†å¤‰ã‚ã‚‹ã‹ã€ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
        ç›¸é–¢ã§ã¯ãªãå› æœé–¢ä¿‚ã‚’æ¨å®šã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        - æŠ•è³‡åŠ¹æœã®äº‹å‰äºˆæ¸¬
        - åäº‹å®Ÿåˆ†æï¼ˆã€Œã‚‚ã—ã‚ã®æ™‚...ã€ï¼‰
        - å› æœçµŒè·¯ã®å¯è¦–åŒ–
        - äº¤çµ¡å› å­ã®æ¤œå‡º
        
        **çµæœã®è¦‹æ–¹:**
        - ä»‹å…¥åŠ¹æœ: do(X=æ”¹å–„) â†’ Y ãŒ 15%å‘ä¸Š
        - ç›´æ¥åŠ¹æœ vs é–“æ¥åŠ¹æœã®æ¯”è¼ƒ
        - å› æœçµŒè·¯ã®ç‰¹å®š
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 3-7åˆ†ï¼ˆ{len(nodes)}ãƒãƒ¼ãƒ‰ï¼‰")
    
    col_settings_ci, col_execute_ci = st.columns([2, 1])
    
    with col_settings_ci:
        intervention_node = st.selectbox(
            "ä»‹å…¥å¯¾è±¡ãƒãƒ¼ãƒ‰",
            options=nodes,
            help="ã“ã®ãƒãƒ¼ãƒ‰ã«ä»‹å…¥ï¼ˆæ”¹å–„ï¼‰ã—ãŸå ´åˆã®åŠ¹æœã‚’åˆ†æ"
        )
        
        intervention_strength = st.slider(
            "ä»‹å…¥ã®å¼·ã•",
            min_value=0.5,
            max_value=2.0,
            value=1.5,
            step=0.1,
            help="1.0=ç¾çŠ¶ã€1.5=50%æ”¹å–„ã€0.5=50%åŠ£åŒ–"
        )
        
        max_path_length = st.slider(
            "æœ€å¤§çµŒè·¯é•·",
            min_value=2,
            max_value=6,
            value=4,
            help="åˆ†æã™ã‚‹å› æœçµŒè·¯ã®æœ€å¤§é•·"
        )
    
    with col_execute_ci:
        st.write("")
        st.write("")
        execute_ci = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", key="ci_btn", type="primary", use_container_width=True)
    
    if execute_ci:
        try:
            with st.spinner("å› æœæ¨è«–åˆ†æä¸­..."):
                from utils.causal_inference import CausalInferenceAnalyzer
                from utils.analytics_progress import AnalyticsProgressTracker
                
                tracker_ci = AnalyticsProgressTracker("å› æœæ¨è«–åˆ†æ", total_steps=100)
                
                def progress_callback_ci(message, pct):
                    tracker_ci.update(int(pct * 100), message)
                
                analyzer_ci = CausalInferenceAnalyzer(
                    adjacency_matrix=st.session_state.adjacency_matrix,
                    node_names=nodes,
                    max_path_length=max_path_length
                )
                
                result_ci = analyzer_ci.compute_causal_inference(
                    intervention_node=intervention_node,
                    intervention_strength=intervention_strength,
                    progress_callback=progress_callback_ci
                )
                
                if "advanced_analytics_results" not in st.session_state:
                    st.session_state.advanced_analytics_results = {}
                
                st.session_state.advanced_analytics_results["causal_inference"] = {
                    "result": result_ci,
                    "parameters": {
                        "intervention_node": intervention_node,
                        "intervention_strength": intervention_strength,
                        "max_path_length": max_path_length
                    },
                    "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                tracker_ci.complete(result_ci.computation_time)
        except Exception as e:
            if 'tracker_ci' in locals():
                tracker_ci.error(str(e))
            st.error(f"âŒ å› æœæ¨è«–åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    if "advanced_analytics_results" in st.session_state and "causal_inference" in st.session_state.advanced_analytics_results:
        result_data_ci = st.session_state.advanced_analytics_results["causal_inference"]
        result_ci = result_data_ci["result"]
        
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ†æçµæœ")
        
        st.markdown(result_ci.interpretation)
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ç›´æ¥åŠ¹æœ", len(result_ci.direct_effects))
        col2.metric("é–“æ¥åŠ¹æœ", len(result_ci.indirect_effects))
        col3.metric("äº¤çµ¡å› å­", len(result_ci.confounders))
        col4.metric("è¨ˆç®—æ™‚é–“", f"{result_ci.computation_time:.1f}ç§’")
        
        st.markdown("### ğŸ¯ ä»‹å…¥åŠ¹æœ")
        intervention_node_param = result_data_ci["parameters"]["intervention_node"]
        intervention_effects = result_ci.intervention_effects.get(intervention_node_param, {})
        
        if intervention_effects:
            import matplotlib.pyplot as plt
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            effects_df = pd.DataFrame([
                {"ãƒãƒ¼ãƒ‰": node, "å› æœåŠ¹æœ": effect}
                for node, effect in sorted(intervention_effects.items(), 
                                          key=lambda x: abs(x[1]), reverse=True)[:15]
            ])
            
            fig, ax = plt.subplots(figsize=(10, 6))
            colors = ['red' if x < 0 else 'green' for x in effects_df["å› æœåŠ¹æœ"]]
            ax.barh(effects_df["ãƒãƒ¼ãƒ‰"], effects_df["å› æœåŠ¹æœ"], color=colors, alpha=0.7)
            ax.set_xlabel("å› æœåŠ¹æœ")
            ax.set_title(f"do({intervention_node_param}) ã®æ³¢åŠåŠ¹æœ")
            ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
            st.pyplot(fig)
            plt.close()
        
        st.markdown("### ğŸ›¤ï¸ å› æœçµŒè·¯ï¼ˆä¸Šä½5ãƒšã‚¢ï¼‰")
        
        top_pairs = sorted(result_ci.total_effects.items(), 
                          key=lambda x: abs(x[1]), reverse=True)[:5]
        
        for (source, target), effect in top_pairs:
            paths = result_ci.causal_paths.get((source, target), [])
            if paths:
                st.markdown(f"**{source} â†’ {target}** (ç·åŠ¹æœ: {effect:.4f})")
                for i, path in enumerate(paths[:3], 1):
                    path_str = " â†’ ".join(path)
                    st.caption(f"çµŒè·¯{i}: {path_str}")
        
        if result_ci.confounders:
            st.markdown("### âš ï¸ äº¤çµ¡å› å­")
            confounders_df = pd.DataFrame([
                {
                    "From": source,
                    "To": target,
                    "äº¤çµ¡å› å­": ", ".join(conf_list)
                }
                for source, target, conf_list in result_ci.confounders[:10]
            ])
            st.dataframe(confounders_df, use_container_width=True, hide_index=True)
        
        st.markdown("### ğŸ† æœ€é©ãªä»‹å…¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆä¸Šä½10ï¼‰")
        if result_ci.top_intervention_targets:
            targets_df = pd.DataFrame([
                {"é †ä½": i+1, "ãƒãƒ¼ãƒ‰": node, "ç·å½±éŸ¿åŠ›": impact}
                for i, (node, impact) in enumerate(result_ci.top_intervention_targets[:10])
            ])
            st.dataframe(targets_df, use_container_width=True, hide_index=True)
    
    # 9.6 Graph Embedding
    st.markdown("---")
    st.subheader("9.6. æ½œåœ¨æ§‹é€ ç™ºè¦‹ï¼ˆGraph Embedding + Community Detectionï¼‰")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        è¡¨é¢çš„ãªæ¥ç¶šã‚’è¶…ãˆãŸã€Œæœ¬è³ªçš„ãªé¡ä¼¼æ€§ã€ã‚’ç™ºè¦‹ã—ã¾ã™ã€‚
        æ©Ÿèƒ½çš„ãªã‚°ãƒ«ãƒ¼ãƒ—ã‚’è‡ªå‹•æ¤œå‡ºã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - ã‚«ãƒ†ã‚´ãƒªã‚’è¶…ãˆãŸè‡ªç„¶ãªã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘
        - é¡ä¼¼ãƒãƒ¼ãƒ‰ã®çµ±åˆãƒ»æ•´ç†
        - 2Då¯è¦–åŒ–ã§ç›´æ„Ÿçš„ç†è§£
        
        **çµæœã®è¦‹æ–¹:**
        - è¿‘ãã«é…ç½®ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ = æ©Ÿèƒ½çš„ã«é¡ä¼¼
        - åŒã˜è‰²ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ = å”åŠ›é–¢ä¿‚ãŒå¼·ã„
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: 1-2åˆ†ï¼ˆ{len(nodes)}ãƒãƒ¼ãƒ‰ï¼‰")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    col_settings_ge, col_execute_ge = st.columns([2, 1])
    
    with col_settings_ge:
        embedding_dim = st.select_slider(
            "åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°",
            options=[16, 32, 64, 128],
            value=64,
            help="ãƒãƒ¼ãƒ‰ã‚’è¡¨ç¾ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ï¼ˆå¤§ãã„ã»ã©è©³ç´°ã ãŒè¨ˆç®—æ™‚é–“å¢—ï¼‰"
        )
        
        col_walk_len, col_walk_num = st.columns(2)
        with col_walk_len:
            walk_length = st.selectbox(
                "ã‚¦ã‚©ãƒ¼ã‚¯é•·",
                options=[10, 20, 30],
                index=1,
                help="ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®æœ€å¤§é•·"
            )
        with col_walk_num:
            num_walks = st.selectbox(
                "ã‚¦ã‚©ãƒ¼ã‚¯å›æ•°",
                options=[50, 100, 200, 500],
                index=1,
                help="å„ãƒãƒ¼ãƒ‰ã‹ã‚‰é–‹å§‹ã™ã‚‹ã‚¦ã‚©ãƒ¼ã‚¯æ•°"
            )
        
        reduction_method = st.selectbox(
            "2DåŒ–æ‰‹æ³•",
            options=["mds", "spectral"],
            format_func=lambda x: "MDSï¼ˆå¤šæ¬¡å…ƒå°ºåº¦æ³•ï¼‰" if x == "mds" else "Spectral Embedding",
            help="é«˜æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿ã‚’2Dã«åœ§ç¸®ã™ã‚‹æ‰‹æ³•"
        )
    
    with col_execute_ge:
        st.write("")  # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
        st.write("")
        execute_ge = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", key="embedding_execute_btn", use_container_width=True)
    
    # å®Ÿè¡Œ
    if execute_ge:
        try:
            from utils.graph_embedding import GraphEmbeddingAnalyzer
            from utils.analytics_progress import AnalyticsProgressTracker, create_simple_callback
            
            tracker_ge = AnalyticsProgressTracker("Graph Embeddingåˆ†æ", total_steps=100)
            
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            def progress_callback_ge(message: str, pct: float):
                tracker_ge.progress_text.text(message)
                tracker_ge.progress_bar.progress(pct)
            
            analyzer_ge = GraphEmbeddingAnalyzer(
                adjacency_matrix=st.session_state.adjacency_matrix,
                node_names=nodes,
                embedding_dim=embedding_dim,
                walk_length=walk_length,
                num_walks=num_walks,
                reduction_method=reduction_method
            )
            
            result_ge = analyzer_ge.compute_graph_embedding(progress_callback=progress_callback_ge)
            tracker_ge.complete(result_ge.computation_time)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            if "advanced_analytics_results" not in st.session_state:
                st.session_state.advanced_analytics_results = {}
            
            st.session_state.advanced_analytics_results["graph_embedding"] = {
                "result": result_ge,
                "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
                "parameters": {
                    "embedding_dim": embedding_dim,
                    "walk_length": walk_length,
                    "num_walks": num_walks,
                    "reduction_method": reduction_method
                }
            }
        except Exception as e:
            if 'tracker_ge' in locals():
                tracker_ge.error(str(e))
            st.error(f"âŒ Graph Embeddingåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    # çµæœè¡¨ç¤º
    if "advanced_analytics_results" in st.session_state and \
       "graph_embedding" in st.session_state.advanced_analytics_results:
        
        ge_data = st.session_state.advanced_analytics_results["graph_embedding"]
        result_ge = ge_data["result"]
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æçµæœ")
        
        # 1. è§£é‡ˆæ–‡
        with st.expander("ğŸ’¡ çµæœã®è§£é‡ˆ", expanded=True):
            st.markdown(result_ge.interpretation)
        
        # 2. ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        st.markdown("#### åŸºæœ¬çµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ•°", result_ge.n_communities)
        col2.metric("Modularity", f"{result_ge.modularity:.3f}")
        col3.metric("åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ", result_ge.embedding_dim)
        col4.metric("è¨ˆç®—æ™‚é–“", f"{result_ge.computation_time:.1f}ç§’")
        
        # 3. 2Dæ•£å¸ƒå›³ï¼ˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£åˆ¥è‰²åˆ†ã‘ï¼‰
        st.markdown("#### 2Då¯è¦–åŒ–ï¼ˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£åˆ¥ï¼‰")
        
        import matplotlib.pyplot as plt
        import matplotlib.colors as mcolors
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
        unique_communities = sorted(set(result_ge.communities.values()))
        colors = plt.cm.tab20(np.linspace(0, 1, len(unique_communities)))
        community_colors = {comm_id: colors[i] for i, comm_id in enumerate(unique_communities)}
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        for node in nodes:
            x, y = result_ge.node_positions_2d[node]
            comm_id = result_ge.communities[node]
            ax.scatter(x, y, c=[community_colors[comm_id]], s=200, alpha=0.7, edgecolors='black', linewidths=1.5)
            ax.annotate(node, (x, y), fontsize=9, ha='center', va='center')
        
        ax.set_xlabel("æ¬¡å…ƒ1", fontsize=12)
        ax.set_ylabel("æ¬¡å…ƒ2", fontsize=12)
        ax.set_title(f"Graph Embedding 2Då¯è¦–åŒ–ï¼ˆ{result_ge.n_communities}ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼‰", fontsize=14)
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)
        plt.close()
        
        # 4. ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è©³ç´°
        st.markdown("#### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è©³ç´°")
        
        # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã”ã¨ã«ãƒ¡ãƒ³ãƒãƒ¼ã‚’æ•´ç†
        community_members = {}
        for node, comm_id in result_ge.communities.items():
            if comm_id not in community_members:
                community_members[comm_id] = []
            community_members[comm_id].append(node)
        
        # å„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æƒ…å ±ã‚’è¡¨ç¤º
        comm_data = []
        for comm_id in sorted(community_members.keys()):
            members = community_members[comm_id]
            label = result_ge.community_labels.get(comm_id, f"ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£{comm_id+1}")
            comm_data.append({
                "ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ID": comm_id + 1,
                "åå‰": label,
                "ãƒãƒ¼ãƒ‰æ•°": len(members),
                "ãƒ¡ãƒ³ãƒãƒ¼": ", ".join(members)
            })
        
        comm_df = pd.DataFrame(comm_data)
        st.dataframe(comm_df, use_container_width=True, hide_index=True)
        
        # 5. é¡ä¼¼ãƒãƒ¼ãƒ‰ãƒšã‚¢
        st.markdown("#### é¡ä¼¼ãƒãƒ¼ãƒ‰ãƒšã‚¢ï¼ˆä¸Šä½20çµ„ï¼‰")
        
        similar_data = []
        for node1, node2, sim in result_ge.top_similar_pairs[:20]:
            similar_data.append({
                "ãƒãƒ¼ãƒ‰1": node1,
                "ãƒãƒ¼ãƒ‰2": node2,
                "é¡ä¼¼åº¦": f"{sim:.4f}"
            })
        
        similar_df = pd.DataFrame(similar_data)
        st.dataframe(similar_df, use_container_width=True, hide_index=True)
        
        # æ³¨æ„äº‹é …
        st.info("""
        **ğŸ’¡ æ´»ç”¨ã®ãƒ’ãƒ³ãƒˆ:**
        - åŒã˜ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å†…ã®ãƒãƒ¼ãƒ‰ã¯æ©Ÿèƒ½çš„ã«å¯†æ¥ã«é–¢ä¿‚ã—ã¦ã„ã¾ã™
        - é¡ä¼¼åº¦ãŒé«˜ã„ãƒãƒ¼ãƒ‰ãƒšã‚¢ã¯ã€çµ±åˆã‚„æ•´ç†ã®å€™è£œã¨ãªã‚Šã¾ã™
        - 2Då¯è¦–åŒ–ã§é›¢ã‚ŒãŸä½ç½®ã«ã‚ã‚‹ãƒãƒ¼ãƒ‰ã¯ã€æ©Ÿèƒ½çš„ã«ç‹¬ç«‹ã—ã¦ã„ã¾ã™
        """)
    else:
        st.info("ğŸ‘† ä¸Šã®ã€ŒğŸš€ åˆ†æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€Graph Embeddingåˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
    
    # 9.7 Fisher Information
    st.markdown("---")
    st.subheader("9.7. æ„Ÿåº¦åˆ†æï¼ˆFisher Information Matrixï¼‰")
    
    with st.expander("ğŸ’¡ ã“ã®åˆ†æã«ã¤ã„ã¦", expanded=False):
        st.markdown("""
        **ä½•ãŒã‚ã‹ã‚‹ã‹:**
        
        ã€Œã©ã®ã‚¹ã‚³ã‚¢ãŒä¸æ­£ç¢ºã ã¨å…¨ä½“ãŒå¤§ããæ­ªã‚€ã‹ã€ã‚’ç‰¹å®šã—ã¾ã™ã€‚
        æ¨å®šç²¾åº¦ã®ç†è«–é™ç•Œã‚’è¨ˆç®—ã—ã¾ã™ã€‚
        
        **ã©ã†ä½¿ãˆã°ã„ã„ã‹:**
        - å†è©•ä¾¡ã®å„ªå…ˆé †ä½æ±ºå®šï¼ˆæ„Ÿåº¦ãŒé«˜ã„ãƒãƒ¼ãƒ‰ã‚’å„ªå…ˆï¼‰
        - æœ€é©å®Ÿé¨“è¨ˆç”»ï¼ˆã©ã“ã‚’ç²¾å¯†ã«æ¸¬å®šã™ã¹ãã‹ï¼‰
        - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šã®ä¿¡é ¼æ€§è©•ä¾¡
        
        **çµæœã®è¦‹æ–¹:**
        - Fisheræƒ…å ±é‡ãŒé«˜ã„ = ãã®ãƒãƒ¼ãƒ‰ãŒå…¨ä½“ã«å¤§ããå½±éŸ¿
        - CramÃ©r-Raoä¸‹é™ = æ¨å®šç²¾åº¦ã®ç†è«–é™ç•Œ
        """)
    
    st.info(f"â±ï¸ æ¨å®šè¨ˆç®—æ™‚é–“: <1åˆ†ï¼ˆ{len(nodes)}ãƒãƒ¼ãƒ‰ï¼‰")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    col_settings_fi, col_execute_fi = st.columns([2, 1])
    
    with col_settings_fi:
        noise_variance_fi = st.slider(
            "ãƒã‚¤ã‚ºåˆ†æ•£ï¼ˆÏƒÂ²ï¼‰",
            min_value=0.1,
            max_value=5.0,
            value=1.0,
            step=0.1,
            help="è¦³æ¸¬ãƒã‚¤ã‚ºã®åˆ†æ•£ã‚’ä»®å®šã—ã¾ã™ï¼ˆå¤§ãã„ã»ã©ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ï¼‰"
        )
        
        top_k_fi = st.slider(
            "è¡¨ç¤ºã™ã‚‹ä¸Šä½ã‚¨ãƒƒã‚¸æ•°",
            min_value=10,
            max_value=50,
            value=20,
            step=5,
            help="æ„Ÿåº¦ãŒé«˜ã„ã‚¨ãƒƒã‚¸ã‚’ä½•çµ„è¡¨ç¤ºã™ã‚‹ã‹"
        )
    
    with col_execute_fi:
        st.write("")  # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
        st.write("")
        execute_fi = st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", key="fisher_execute_btn", use_container_width=True)
    
    # å®Ÿè¡Œ
    if execute_fi:
        try:
            from utils.fisher_information import FisherInformationAnalyzer
            from utils.analytics_progress import AnalyticsProgressTracker
            
            tracker_fi = AnalyticsProgressTracker("Fisher Informationåˆ†æ", total_steps=100)
            
            # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            def progress_callback_fi(message: str, pct: float):
                tracker_fi.progress_text.text(message)
                tracker_fi.progress_bar.progress(pct)
            
            analyzer_fi = FisherInformationAnalyzer(
                adjacency_matrix=st.session_state.adjacency_matrix,
                node_names=nodes,
                noise_variance=noise_variance_fi
            )
            
            result_fi = analyzer_fi.compute_fisher_information(progress_callback=progress_callback_fi)
            tracker_fi.complete(result_fi.computation_time)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            if "advanced_analytics_results" not in st.session_state:
                st.session_state.advanced_analytics_results = {}
            
            st.session_state.advanced_analytics_results["fisher_information"] = {
                "result": result_fi,
                "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
                "parameters": {
                    "noise_variance": noise_variance_fi,
                    "top_k": top_k_fi
                }
            }
        except Exception as e:
            if 'tracker_fi' in locals():
                tracker_fi.error(str(e))
            st.error(f"âŒ Fisher Informationåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                import traceback
                st.code(traceback.format_exc(), language="python")
    
    # çµæœè¡¨ç¤º
    if "advanced_analytics_results" in st.session_state and \
       "fisher_information" in st.session_state.advanced_analytics_results:
        
        fi_data = st.session_state.advanced_analytics_results["fisher_information"]
        result_fi = fi_data["result"]
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æçµæœ")
        
        # 1. è§£é‡ˆæ–‡
        with st.expander("ğŸ’¡ çµæœã®è§£é‡ˆ", expanded=True):
            st.markdown(result_fi.interpretation)
        
        # 2. ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        st.markdown("#### åŸºæœ¬çµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ç·ã‚¨ãƒƒã‚¸æ•°", result_fi.n_edges)
        col2.metric("æ¡ä»¶æ•°", f"{result_fi.condition_number:.2f}")
        col3.metric("å®ŸåŠ¹ãƒ©ãƒ³ã‚¯", result_fi.effective_rank)
        col4.metric("è¨ˆç®—æ™‚é–“", f"{result_fi.computation_time:.1f}ç§’")
        
        # 3. æ„Ÿåº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        st.markdown("#### æ„Ÿåº¦ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½20ï¼‰")
        
        import matplotlib.pyplot as plt
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        top_edges = result_fi.top_sensitive_edges[:20]
        edge_labels = [f"{s}â†’{t}" for s, t, _ in top_edges]
        sensitivities = [score for _, _, score in top_edges]
        
        y_pos = np.arange(len(edge_labels))
        ax.barh(y_pos, sensitivities, color='steelblue', alpha=0.7)
        ax.set_yticks(y_pos)
        ax.set_yticklabels(edge_labels, fontsize=9)
        ax.set_xlabel("æ„Ÿåº¦ã‚¹ã‚³ã‚¢", fontsize=12)
        ax.set_title("Fisheræƒ…å ±é‡ï¼ˆæ„Ÿåº¦ï¼‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°", fontsize=14)
        ax.grid(True, alpha=0.3, axis='x')
        
        st.pyplot(fig)
        plt.close()
        
        # 4. CramÃ©r-Raoä¸‹é™ãƒ†ãƒ¼ãƒ–ãƒ«
        st.markdown("#### CramÃ©r-Raoä¸‹é™ï¼ˆæ¨å®šç²¾åº¦é™ç•Œã€ä¸Šä½20ï¼‰")
        
        # CRä¸‹é™ã‚’é™é †ã‚½ãƒ¼ãƒˆï¼ˆå¤§ãã„ = æ¨å®šãŒå›°é›£ï¼‰
        cr_sorted = sorted(
            result_fi.cramer_rao_bounds.items(),
            key=lambda x: x[1],
            reverse=True
        )[:20]
        
        cr_data = []
        for (source, target), bound in cr_sorted:
            cr_data.append({
                "From": source,
                "To": target,
                "CRä¸‹é™": f"{bound:.6f}",
                "æ¨å®šé›£æ˜“åº¦": "é«˜" if bound > np.mean(list(result_fi.cramer_rao_bounds.values())) else "ä¸­"
            })
        
        cr_df = pd.DataFrame(cr_data)
        st.dataframe(cr_df, use_container_width=True, hide_index=True)
        
        # 5. å›ºæœ‰å€¤åˆ†å¸ƒ
        st.markdown("#### å›ºæœ‰å€¤åˆ†å¸ƒï¼ˆScree Plotï¼‰")
        
        fig2, ax2 = plt.subplots(figsize=(10, 5))
        
        eigenvalues = result_fi.eigenvalues
        ax2.plot(range(1, len(eigenvalues) + 1), eigenvalues, 'o-', color='darkblue', linewidth=2, markersize=6)
        ax2.set_xlabel("å›ºæœ‰å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", fontsize=12)
        ax2.set_ylabel("å›ºæœ‰å€¤", fontsize=12)
        ax2.set_title("Fisheræƒ…å ±è¡Œåˆ—ã®å›ºæœ‰å€¤åˆ†å¸ƒ", fontsize=14)
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')  # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«
        
        st.pyplot(fig2)
        plt.close()
        
        # æ³¨æ„äº‹é …
        st.info("""
        **ğŸ’¡ æ´»ç”¨ã®ãƒ’ãƒ³ãƒˆ:**
        - æ„Ÿåº¦ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã‚¨ãƒƒã‚¸ã¯ã€å†è©•ä¾¡ã®å„ªå…ˆé †ä½ãŒé«˜ã„ã§ã™
        - CRä¸‹é™ãŒå¤§ãã„ã‚¨ãƒƒã‚¸ã¯ã€æ¨å®šãŒæœ¬è³ªçš„ã«å›°é›£ã§ã™ï¼ˆè¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰
        - æ¡ä»¶æ•°ãŒå¤§ãã„å ´åˆã¯ã€å¤šé‡å…±ç·šæ€§ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
        """)
    else:
        st.info("ğŸ‘† ä¸Šã®ã€ŒğŸš€ åˆ†æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€Fisher Informationåˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    st.set_page_config(
        page_title=settings.APP_TITLE,
        page_icon="ğŸ­",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    
    SessionManager.initialize()
    
    st.title(f"{settings.APP_TITLE} - ã‚¿ãƒ–å½¢å¼UI")
    
    render_sidebar()
    
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([
        "ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ—ãƒ­ã‚»ã‚¹å®šç¾©",
        "ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—2: æ©Ÿèƒ½ã‚«ãƒ†ã‚´ãƒª",
        "ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ¼ãƒ‰å®šç¾©",
        "âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—4: ãƒãƒ¼ãƒ‰å½±éŸ¿è©•ä¾¡",
        "ğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: è¡Œåˆ—åˆ†æ",
        "ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—6: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–",
        "ğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—7: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ",
        "ğŸ® ã‚¹ãƒ†ãƒƒãƒ—8: DSMæœ€é©åŒ–",
        "ğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—9: é«˜åº¦ãªåˆ†æ"
    ])
    
    with tab1:
        tab1_process_definition()
    
    with tab2:
        tab2_functional_categories()
    
    with tab3:
        tab3_node_definition()
    
    with tab4:
        tab4_node_evaluation()
    
    with tab5:
        tab5_matrix_analysis()
    
    with tab6:
        tab6_network_visualization()
    
    with tab7:
        tab7_network_analysis()
    
    with tab8:
        tab8_dsm_optimization()
    
    with tab9:
        tab9_advanced_analytics()


if __name__ == "__main__":
    main()
